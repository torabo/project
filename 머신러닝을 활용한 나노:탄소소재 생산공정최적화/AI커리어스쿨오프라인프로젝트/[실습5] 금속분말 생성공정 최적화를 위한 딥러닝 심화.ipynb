{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a79cd7d",
   "metadata": {},
   "source": [
    "# [실습5] 금속분말 생성공정 최적화를 위한 딥러닝 심화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3739d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aefe31",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "---\n",
    "- 모델의 일반화에 대해 이해합니다.\n",
    "- 일반화를 위한 방법들을 배워봅니다.\n",
    "- 조기 종료 방법을 배워봅니다.\n",
    "- 가중치 규제 방법을 배워봅니다.\n",
    "- 앙상블 모델을 배워봅니다.\n",
    "- 정규화를 배워봅니다.\n",
    "- 데이터 증강 기법을 배워봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ea455",
   "metadata": {},
   "source": [
    "## 실습 목차\n",
    "---\n",
    "1. **일반화를 위한 방법들:** 일반화를 위한 여러 방법들을 사용해보고 성능을 비교합니다.\n",
    "\n",
    "2. **조기 종료:** 조기 종료 방법을 수행해보고, 성능을 비교해봅니다,\n",
    "\n",
    "3. **가중치 규제:** 가중치 규제 방법을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "4. **앙상블 모델:** 앙상블 모델을 구현해봅니다.\n",
    "\n",
    "5. **Dropout:** Dropout을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "6. **정규화:** 정규화를 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "7. **데이터 증강 기법:** 데이터 증강기법을 수행해보고, 성능을 비교해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181e4b6",
   "metadata": {},
   "source": [
    "## 실습 개요\n",
    "---\n",
    "\n",
    "이번 실습에서는 다양한 일반화를 위한 방법들을 수행해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95ff88",
   "metadata": {},
   "source": [
    "## 1. 일반화를 위한 방법들\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 일반화 방법들을 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c4f16",
   "metadata": {},
   "source": [
    "### 1.1 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158a490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 04:04:43.460016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-11 04:04:43.572357: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-11 04:04:43.604160: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 04:04:44.840085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-02-11 04:04:44.840166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-02-11 04:04:44.840174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import json\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a4e6e",
   "metadata": {},
   "source": [
    "### 1.2 데이터셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d768436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = {\n",
    "    \"train_X\": np.load(\"./Data/train_data_stage1_X.npy\"),\n",
    "    \"train_y\": np.load(\"./Data/train_data_stage1_y.npy\"),\n",
    "    \"valid_X\": np.load(\"./Data/valid_data_stage1_X.npy\"),\n",
    "    \"valid_y\": np.load(\"./Data/valid_data_stage1_y.npy\"),\n",
    "    \"test_X\": np.load(\"./Data/test_data_stage1_X.npy\"),\n",
    "    \"test_y\": np.load(\"./Data/test_data_stage1_y.npy\"),\n",
    "}\n",
    "\n",
    "stage2 = {\n",
    "    \"train_X\": np.load(\"./Data/train_data_stage2_X.npy\"),\n",
    "    \"train_y\": np.load(\"./Data/train_data_stage2_y.npy\"),\n",
    "    \"valid_X\": np.load(\"./Data/valid_data_stage2_X.npy\"),\n",
    "    \"valid_y\": np.load(\"./Data/valid_data_stage2_y.npy\"),\n",
    "    \"test_X\": np.load(\"./Data/test_data_stage2_X.npy\"),\n",
    "    \"test_y\": np.load(\"./Data/test_data_stage2_y.npy\"),\n",
    "}\n",
    "\n",
    "columns = json.load(open(\"./Data/valid_columns.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6bdf6",
   "metadata": {},
   "source": [
    "### 1.3 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72e707",
   "metadata": {},
   "source": [
    "### 1.3.1 Stage1 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37ccb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값 평균: [  11.85294587  205.74478705  951.00255435 1242.437388     72.01273285\n",
      "   72.01162996   70.34571071   11.07603585  408.95062376   81.47648118\n",
      "   75.96962985   12.79330524  566.38390195  202.65058918   68.99620414\n",
      "   69.10054828   73.3958155    13.89662164  226.12474952   76.81680896\n",
      "   59.99898793    9.08815439  205.71384206  425.06943434  202.26546402\n",
      "   78.00841235   78.00453278  345.11532917   13.26721071  246.73680272\n",
      "   74.14375402   65.00868711  108.96768422   84.98831262   80.00354672\n",
      "   15.32405834   23.84402174]\n",
      "출력값 평균: [12.89768652 13.69662267  8.00480187 11.36113325 21.31940678 32.87843839\n",
      "  0.12721732  1.34725458  1.09990652 19.8051213   7.68305334  1.4919701\n",
      "  1.20588607  2.89104562 10.02515553]\n"
     ]
    }
   ],
   "source": [
    "stage1_X_mean = stage1[\"train_X\"].mean(axis=0)\n",
    "stage1_y_mean = stage1[\"train_y\"].mean(axis=0)\n",
    "print(\"입력값 평균:\", stage1_X_mean)\n",
    "print(\"출력값 평균:\", stage1_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c4ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값 표준편차: [5.10993143e-01 1.16806618e+01 1.27620111e+02 9.77321235e+01\n",
      " 6.23396785e-02 4.06238919e-01 5.49867530e+00 6.36170724e-01\n",
      " 2.05368437e+01 9.21642493e-01 2.06429784e+00 1.07360805e-01\n",
      " 1.83380514e+01 1.48381842e+01 5.44970706e-02 1.06721153e-01\n",
      " 3.94100055e-01 2.91335938e-02 3.06908107e+00 8.30358591e-01\n",
      " 1.61971729e-01 3.95092636e-01 1.63223059e+01 9.53699574e+00\n",
      " 1.58921785e+01 7.73526529e-02 1.14547773e-01 9.05396328e+00\n",
      " 4.34061012e-01 6.10492128e+00 2.05042127e+00 6.27961350e-02\n",
      " 5.59761035e+00 1.85637963e+01 1.18126539e-01 1.18770739e+00\n",
      " 3.72221796e-01]\n",
      "출력값 표준편차: [0.9270819  0.85503751 6.90580271 1.03664992 2.14313701 3.882343\n",
      " 0.57606676 1.13060617 1.41265541 4.68687927 1.07824517 2.54294205\n",
      " 0.66114934 0.92884134 7.38778856]\n"
     ]
    }
   ],
   "source": [
    "stage1_X_std = stage1[\"train_X\"].std(axis=0)\n",
    "stage1_y_std = stage1[\"train_y\"].std(axis=0)\n",
    "print(\"입력값 표준편차:\", stage1_X_std)\n",
    "print(\"출력값 표준편차:\", stage1_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7bf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage1[\"train_X\"] = (stage1[\"train_X\"] - stage1_X_mean) / stage1_X_std\n",
    "stage1[\"train_y\"] = (stage1[\"train_y\"] - stage1_y_mean) / stage1_y_std\n",
    "# 검증용 데이터 표준화\n",
    "stage1[\"valid_X\"] = (stage1[\"valid_X\"] - stage1_X_mean) / stage1_X_std\n",
    "stage1[\"valid_y\"] = (stage1[\"valid_y\"] - stage1_y_mean) / stage1_y_std\n",
    "# 테스트 데이터 표준화\n",
    "stage1[\"test_X\"] = (stage1[\"test_X\"] - stage1_X_mean) / stage1_X_std\n",
    "stage1[\"test_y\"] = (stage1[\"test_y\"] - stage1_y_mean) / stage1_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb611df",
   "metadata": {},
   "source": [
    "### 1.3.2 Stage2 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cddb89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값 평균: [1.28976865e+01 1.36966227e+01 8.00480187e+00 1.13611333e+01\n",
      " 2.13194068e+01 3.28784384e+01 1.27217323e-01 1.34725458e+00\n",
      " 1.09990652e+00 1.98051213e+01 7.68305334e+00 1.49197010e+00\n",
      " 1.20588607e+00 2.89104562e+00 1.00251555e+01 3.60122933e+02\n",
      " 3.60136275e+02 1.72294333e+01 3.22627969e+02 3.09786854e+02\n",
      " 1.87200947e+02 3.09998282e+02 2.89997582e+02 2.69681649e+02\n",
      " 2.42661246e+02 2.44994629e+02 6.34195390e+01 1.54046742e+02\n",
      " 1.53240583e+01 2.38440217e+01]\n",
      "출력값 평균: [11.69212911  6.25614828 10.2499656  19.33555126  2.87697932  2.7475277\n",
      "  0.53310706  2.91750962 18.38898671 11.61424043  7.53420311  3.54181714\n",
      "  7.51699723]\n"
     ]
    }
   ],
   "source": [
    "stage2_X_mean = stage2[\"train_X\"].mean(axis=0)\n",
    "stage2_y_mean = stage2[\"train_y\"].mean(axis=0)\n",
    "print(\"입력값 평균:\", stage2_X_mean)\n",
    "print(\"출력값 평균:\", stage2_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97164d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값 표준편차: [ 0.9270819   0.85503751  6.90580271  1.03664992  2.14313701  3.882343\n",
      "  0.57606676  1.13060617  1.41265541  4.68687927  1.07824517  2.54294205\n",
      "  0.66114934  0.92884134  7.38778856  1.9209727   2.64895901  0.94209921\n",
      "  3.61537985  2.74078134 23.41676809  0.03961971  0.05202987  1.01853204\n",
      "  1.59098238  0.10771334  0.39587306  9.90869048  1.18770739  0.3722218 ]\n",
      "출력값 표준편차: [3.62230517 1.60057596 2.30753588 4.62537631 9.09270122 0.37574164\n",
      " 0.20467783 0.49744294 4.97294003 7.62127826 1.64901449 0.45450424\n",
      " 2.0723342 ]\n"
     ]
    }
   ],
   "source": [
    "stage2_X_std = stage2[\"train_X\"].std(axis=0)\n",
    "stage2_y_std = stage2[\"train_y\"].std(axis=0)\n",
    "print(\"입력값 표준편차:\", stage2_X_std)\n",
    "print(\"출력값 표준편차:\", stage2_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773d3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage2[\"train_X\"] = (stage2[\"train_X\"] - stage2_X_mean) / stage2_X_std\n",
    "stage2[\"train_y\"] = (stage2[\"train_y\"] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 검증용 데이터 표준화\n",
    "stage2[\"valid_X\"] = (stage2[\"valid_X\"] - stage2_X_mean) / stage2_X_std\n",
    "stage2[\"valid_y\"] = (stage2[\"valid_y\"] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 테스트 데이터 표준화\n",
    "stage2[\"test_X\"] = (stage2[\"test_X\"] - stage2_X_mean) / stage2_X_std\n",
    "stage2[\"test_y\"] = (stage2[\"test_y\"] - stage2_y_mean) / stage2_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe9648",
   "metadata": {},
   "source": [
    "### 1.4 학습 데이터 수에 따른 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ffed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use = [0.01, 0.1, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02669797",
   "metadata": {},
   "source": [
    "학습데이터의 1%, 10%, 50%, 100% 를 사용한 모델의 성능을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a927d936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 04:04:49.998520: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-02-11 04:04:49.998571: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-02-11 04:04:49.998622: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ff1ac66610d6): /proc/driver/nvidia/version does not exist\n",
      "2025-02-11 04:04:49.999115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score (학습데이터 수: 90): 0.102912\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score (학습데이터 수: 901): 0.310822\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score (학습데이터 수: 4508): 0.344990\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score (학습데이터 수: 9016): 0.349326\n"
     ]
    }
   ],
   "source": [
    "for ratio in data_use:\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    # 모델 정의\n",
    "    MLP_model = tf.keras.Sequential(\n",
    "        [\n",
    "            Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.SGD(),\n",
    "    )\n",
    "\n",
    "    # 학습 데이터 개수\n",
    "    total_data = len(stage1[\"train_X\"])\n",
    "    len_data = int(total_data * ratio)\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(\n",
    "        stage1[\"train_X\"][:len_data],\n",
    "        stage1[\"train_y\"][:len_data],\n",
    "        epochs=10 * int(1 / ratio),\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "    )\n",
    "    pred = MLP_model.predict(stage1[\"test_X\"])\n",
    "    r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "    print(\"R2 score (학습데이터 수: %d): %f\" % (len_data, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe7ed8",
   "metadata": {},
   "source": [
    "학습데이터가 많을수록 모델의 성능이 좋은 것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86a977",
   "metadata": {},
   "source": [
    "## 2. Early stop\n",
    "검증용 데이터를 이용하여 모델이 과적합 되기 전에 학습을 중지해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a9f23",
   "metadata": {},
   "source": [
    "### 2.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f532fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53169c5c",
   "metadata": {},
   "source": [
    "### 2.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37dbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780c845",
   "metadata": {},
   "source": [
    "### 2.3 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345f048",
   "metadata": {},
   "source": [
    "먼저, early stop 을 사용하지 않을 모델부터 학습합니다. 실습시간을 고려하여 전체 학습데이터 중 1000개만 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "843194f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1507 - val_loss: 1.0349 - 772ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0744 - val_loss: 0.9810 - 236ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0332 - val_loss: 0.9454 - 243ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0035 - val_loss: 0.9184 - 213ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9804 - val_loss: 0.8975 - 261ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9617 - val_loss: 0.8800 - 238ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9463 - val_loss: 0.8665 - 245ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9335 - val_loss: 0.8546 - 242ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9221 - val_loss: 0.8442 - 244ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9117 - val_loss: 0.8359 - 232ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9025 - val_loss: 0.8293 - 215ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.8938 - val_loss: 0.8221 - 251ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8860 - val_loss: 0.8147 - 268ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8781 - val_loss: 0.8081 - 234ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8709 - val_loss: 0.8033 - 198ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8636 - val_loss: 0.7962 - 195ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8568 - val_loss: 0.7910 - 201ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8501 - val_loss: 0.7852 - 231ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8433 - val_loss: 0.7799 - 229ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8368 - val_loss: 0.7752 - 242ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8309 - val_loss: 0.7710 - 260ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8241 - val_loss: 0.7660 - 244ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8187 - val_loss: 0.7620 - 225ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8126 - val_loss: 0.7595 - 226ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8068 - val_loss: 0.7544 - 219ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8015 - val_loss: 0.7515 - 236ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.7956 - val_loss: 0.7466 - 242ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7898 - val_loss: 0.7443 - 262ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7838 - val_loss: 0.7408 - 254ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7780 - val_loss: 0.7376 - 240ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7730 - val_loss: 0.7332 - 241ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7671 - val_loss: 0.7300 - 253ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7612 - val_loss: 0.7282 - 245ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7557 - val_loss: 0.7265 - 263ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7501 - val_loss: 0.7220 - 256ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7442 - val_loss: 0.7210 - 339ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7390 - val_loss: 0.7169 - 280ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7333 - val_loss: 0.7144 - 255ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7281 - val_loss: 0.7128 - 270ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7226 - val_loss: 0.7114 - 251ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7169 - val_loss: 0.7083 - 242ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7112 - val_loss: 0.7064 - 275ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7052 - val_loss: 0.7061 - 287ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7012 - val_loss: 0.7045 - 243ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.6954 - val_loss: 0.7024 - 245ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6908 - val_loss: 0.6994 - 253ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6837 - val_loss: 0.6992 - 314ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6793 - val_loss: 0.6990 - 271ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6735 - val_loss: 0.6940 - 307ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6667 - val_loss: 0.6940 - 225ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6623 - val_loss: 0.6921 - 222ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6566 - val_loss: 0.6908 - 245ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6489 - val_loss: 0.6947 - 242ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6447 - val_loss: 0.6873 - 235ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6373 - val_loss: 0.6955 - 257ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6824 - 232ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6264 - val_loss: 0.6835 - 244ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6179 - val_loss: 0.7058 - 267ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6849 - 321ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6065 - val_loss: 0.6803 - 243ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5997 - val_loss: 0.6778 - 236ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5953 - val_loss: 0.6779 - 246ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5846 - val_loss: 0.6756 - 245ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5794 - val_loss: 0.6761 - 228ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5773 - val_loss: 0.6747 - 220ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5649 - val_loss: 0.6711 - 238ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5615 - val_loss: 0.6712 - 215ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5507 - val_loss: 0.6682 - 229ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5469 - val_loss: 0.6835 - 234ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5426 - val_loss: 0.6781 - 243ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5331 - val_loss: 0.6650 - 243ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5207 - val_loss: 0.6628 - 238ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5208 - val_loss: 0.6608 - 240ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5140 - val_loss: 0.6577 - 229ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5053 - val_loss: 0.6560 - 232ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.4951 - val_loss: 0.6518 - 197ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.4899 - val_loss: 0.6540 - 209ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.4842 - val_loss: 0.6492 - 237ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.4802 - val_loss: 0.6471 - 253ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4698 - val_loss: 0.6463 - 262ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4631 - val_loss: 0.6449 - 251ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4602 - val_loss: 0.6467 - 227ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4511 - val_loss: 0.6469 - 232ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4501 - val_loss: 0.6387 - 250ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4442 - val_loss: 0.6517 - 272ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4396 - val_loss: 0.6345 - 266ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4279 - val_loss: 0.6387 - 254ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4237 - val_loss: 0.6357 - 247ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.6284 - 267ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4154 - val_loss: 0.6281 - 255ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.6486 - 223ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4052 - val_loss: 0.6222 - 226ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3979 - val_loss: 0.6224 - 235ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3995 - val_loss: 0.6162 - 243ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3877 - val_loss: 0.6151 - 246ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3863 - val_loss: 0.6377 - 271ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.6254 - 263ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3773 - val_loss: 0.6236 - 231ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3755 - val_loss: 0.6526 - 222ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3725 - val_loss: 0.6185 - 245ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = MLP_model.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d12f25",
   "metadata": {},
   "source": [
    "다음으로, early stop을 사용할 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11ce72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1866 - val_loss: 1.0613 - 765ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0999 - val_loss: 1.0135 - 218ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0586 - val_loss: 0.9781 - 213ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0258 - val_loss: 0.9481 - 220ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9976 - val_loss: 0.9221 - 242ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9741 - val_loss: 0.9011 - 223ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9556 - val_loss: 0.8849 - 215ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9415 - val_loss: 0.8719 - 228ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9302 - val_loss: 0.8614 - 220ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9203 - val_loss: 0.8527 - 234ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9112 - val_loss: 0.8460 - 244ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.9031 - val_loss: 0.8387 - 221ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8951 - val_loss: 0.8318 - 231ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8872 - val_loss: 0.8246 - 227ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8795 - val_loss: 0.8199 - 252ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8723 - val_loss: 0.8129 - 244ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8653 - val_loss: 0.8082 - 213ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8582 - val_loss: 0.8021 - 233ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8520 - val_loss: 0.7972 - 234ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8453 - val_loss: 0.7928 - 234ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8396 - val_loss: 0.7883 - 208ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8329 - val_loss: 0.7836 - 242ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8268 - val_loss: 0.7792 - 219ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8207 - val_loss: 0.7768 - 238ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8146 - val_loss: 0.7723 - 223ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8086 - val_loss: 0.7683 - 244ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.8030 - val_loss: 0.7644 - 229ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7962 - val_loss: 0.7614 - 214ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7910 - val_loss: 0.7579 - 219ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7843 - val_loss: 0.7551 - 225ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7794 - val_loss: 0.7525 - 238ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7731 - val_loss: 0.7490 - 223ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7678 - val_loss: 0.7485 - 225ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7617 - val_loss: 0.7487 - 198ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7560 - val_loss: 0.7429 - 234ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7503 - val_loss: 0.7401 - 239ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7456 - val_loss: 0.7389 - 250ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7396 - val_loss: 0.7350 - 263ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7342 - val_loss: 0.7363 - 266ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7302 - val_loss: 0.7334 - 234ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7236 - val_loss: 0.7306 - 253ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7191 - val_loss: 0.7313 - 262ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7130 - val_loss: 0.7286 - 279ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7100 - val_loss: 0.7291 - 274ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.7045 - val_loss: 0.7273 - 246ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6989 - val_loss: 0.7237 - 221ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6939 - val_loss: 0.7235 - 237ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6899 - val_loss: 0.7266 - 221ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6851 - val_loss: 0.7211 - 225ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6775 - val_loss: 0.7195 - 209ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6739 - val_loss: 0.7196 - 221ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6696 - val_loss: 0.7188 - 244ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6615 - val_loss: 0.7264 - 222ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6580 - val_loss: 0.7168 - 250ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6508 - val_loss: 0.7259 - 232ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6485 - val_loss: 0.7114 - 230ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6410 - val_loss: 0.7165 - 232ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6340 - val_loss: 0.7466 - 218ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6316 - val_loss: 0.7184 - 230ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6227 - val_loss: 0.7123 - 225ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.6177 - val_loss: 0.7124 - 250ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.6143 - val_loss: 0.7124 - 213ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.6041 - val_loss: 0.7087 - 229ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.6001 - val_loss: 0.7077 - 222ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5980 - val_loss: 0.7139 - 234ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5866 - val_loss: 0.7030 - 231ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5832 - val_loss: 0.7048 - 249ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5755 - val_loss: 0.6987 - 216ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5711 - val_loss: 0.7131 - 237ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5641 - val_loss: 0.7408 - 228ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5590 - val_loss: 0.6965 - 241ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5424 - val_loss: 0.6873 - 234ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5451 - val_loss: 0.6818 - 214ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5371 - val_loss: 0.6875 - 211ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5289 - val_loss: 0.6772 - 224ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.5199 - val_loss: 0.6779 - 229ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.5129 - val_loss: 0.6764 - 238ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.5090 - val_loss: 0.6735 - 234ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.5029 - val_loss: 0.6699 - 211ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4932 - val_loss: 0.6699 - 209ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4840 - val_loss: 0.6628 - 231ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4823 - val_loss: 0.6571 - 214ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4707 - val_loss: 0.6767 - 227ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4693 - val_loss: 0.6540 - 229ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4620 - val_loss: 0.6772 - 262ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4554 - val_loss: 0.6548 - 235ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4424 - val_loss: 0.6482 - 263ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4382 - val_loss: 0.6448 - 210ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4259 - val_loss: 0.6415 - 220ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4308 - val_loss: 0.6361 - 212ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4226 - val_loss: 0.6740 - 240ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4174 - val_loss: 0.6392 - 211ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.4069 - val_loss: 0.6294 - 233ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.4098 - val_loss: 0.6245 - 228ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3965 - val_loss: 0.6216 - 269ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3935 - val_loss: 0.6559 - 268ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3884 - val_loss: 0.6227 - 244ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3825 - val_loss: 0.6179 - 241ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3795 - val_loss: 0.6787 - 235ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3760 - val_loss: 0.6153 - 226ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "history_es = MLP_model_es.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729497c",
   "metadata": {},
   "source": [
    "### 2.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da3897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53a9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.360375\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8faf4ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_es.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933d1d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.346507\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e83d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train w/o EarlyStop\")\n",
    "plt.plot(history_es.history[\"loss\"], label=\"train w/ EarlyStop\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"valid w/o EarlyStop\")\n",
    "plt.plot(history_es.history[\"val_loss\"], label=\"valid w/ EarlyStop\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b63009",
   "metadata": {},
   "source": [
    "Stage1 검증용 데이터셋을 이용하여 early stop 하였을 때는 모델의 성능이 오히려 더 낮습니다.\n",
    "\n",
    "다만, 로그를 확인해보면 두 경우 모두 100 epoch 전부 학습이 완료되었고, 실제로는 Early stop이 발생하지 않았기 때문에 Early stop이 악영향을 미쳤다고 보기는 어렵습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb45d0",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Early stop 을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6750ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cd92eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd2a2ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9541 - val_loss: 1.0259 - 754ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8548 - val_loss: 0.9025 - 217ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7624 - val_loss: 0.7810 - 214ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6853 - val_loss: 0.7091 - 243ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6595 - 229ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.6022 - val_loss: 0.6400 - 217ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5806 - val_loss: 0.6226 - 221ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5656 - val_loss: 0.6089 - 218ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5534 - val_loss: 0.5993 - 227ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5418 - val_loss: 0.5877 - 232ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5330 - val_loss: 0.5843 - 222ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5254 - val_loss: 0.5745 - 265ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5190 - val_loss: 0.5719 - 275ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5117 - val_loss: 0.5729 - 216ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5069 - val_loss: 0.5590 - 231ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.5010 - val_loss: 0.5655 - 233ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4965 - val_loss: 0.5537 - 223ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4918 - val_loss: 0.5482 - 242ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4874 - val_loss: 0.5491 - 215ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4834 - val_loss: 0.5500 - 237ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4812 - val_loss: 0.5419 - 271ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4754 - val_loss: 0.5394 - 227ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4732 - val_loss: 0.5315 - 236ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4699 - val_loss: 0.5272 - 218ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4676 - val_loss: 0.5287 - 214ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4638 - val_loss: 0.5288 - 231ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4620 - val_loss: 0.5250 - 225ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4579 - val_loss: 0.5210 - 243ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4568 - val_loss: 0.5156 - 204ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4544 - val_loss: 0.5200 - 219ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4521 - val_loss: 0.5242 - 228ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4503 - val_loss: 0.5184 - 243ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4484 - val_loss: 0.5198 - 230ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4479 - val_loss: 0.5104 - 253ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4432 - val_loss: 0.5157 - 229ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4426 - val_loss: 0.5088 - 239ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4409 - val_loss: 0.5098 - 218ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4397 - val_loss: 0.5104 - 235ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4385 - val_loss: 0.5023 - 250ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4358 - val_loss: 0.5064 - 226ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4353 - val_loss: 0.5138 - 263ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4348 - val_loss: 0.5018 - 238ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4317 - val_loss: 0.5010 - 255ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4311 - val_loss: 0.5034 - 253ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4303 - val_loss: 0.4977 - 256ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4276 - val_loss: 0.4989 - 236ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4270 - val_loss: 0.4971 - 235ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4252 - val_loss: 0.5006 - 274ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4242 - val_loss: 0.4993 - 246ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4236 - val_loss: 0.4929 - 255ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4217 - val_loss: 0.4948 - 222ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4206 - val_loss: 0.4955 - 266ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4201 - val_loss: 0.4895 - 242ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4189 - val_loss: 0.4933 - 217ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4173 - val_loss: 0.4892 - 214ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4163 - val_loss: 0.4872 - 253ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4150 - val_loss: 0.4830 - 226ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.4888 - 223ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4130 - val_loss: 0.4855 - 238ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4126 - val_loss: 0.4847 - 210ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.4853 - 213ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4104 - val_loss: 0.4876 - 219ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4090 - val_loss: 0.4820 - 216ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4082 - val_loss: 0.4813 - 219ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4076 - val_loss: 0.4881 - 234ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4062 - val_loss: 0.4823 - 238ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4045 - val_loss: 0.4860 - 221ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4033 - val_loss: 0.4862 - 237ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4035 - val_loss: 0.4833 - 232ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4023 - val_loss: 0.4845 - 228ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4014 - val_loss: 0.4777 - 247ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3997 - val_loss: 0.4766 - 241ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3986 - val_loss: 0.4768 - 235ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3987 - val_loss: 0.4755 - 233ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4732 - 217ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3959 - val_loss: 0.4789 - 244ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3939 - val_loss: 0.4745 - 258ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3940 - val_loss: 0.4768 - 237ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3935 - val_loss: 0.4739 - 232ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3911 - val_loss: 0.4755 - 223ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3916 - val_loss: 0.4775 - 220ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3908 - val_loss: 0.4764 - 235ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3904 - val_loss: 0.4729 - 224ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3884 - val_loss: 0.4728 - 220ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3878 - val_loss: 0.4690 - 218ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4720 - 224ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3857 - val_loss: 0.4718 - 211ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3852 - val_loss: 0.4774 - 217ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3844 - val_loss: 0.4702 - 237ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3833 - val_loss: 0.4763 - 216ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3831 - val_loss: 0.4730 - 202ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3817 - val_loss: 0.4700 - 220ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3798 - val_loss: 0.4674 - 207ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3803 - val_loss: 0.4700 - 245ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3785 - val_loss: 0.4714 - 222ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3777 - val_loss: 0.4646 - 229ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3767 - val_loss: 0.4763 - 211ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3758 - val_loss: 0.4676 - 226ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3744 - val_loss: 0.4692 - 238ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3751 - val_loss: 0.4693 - 241ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Early stop 을 적용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e777a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9788 - val_loss: 1.0196 - 757ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8233 - val_loss: 0.8521 - 227ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7090 - val_loss: 0.7288 - 210ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6431 - val_loss: 0.6751 - 245ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6066 - val_loss: 0.6382 - 276ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.5849 - val_loss: 0.6227 - 268ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5685 - val_loss: 0.6095 - 230ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5552 - val_loss: 0.5982 - 240ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5448 - val_loss: 0.5902 - 219ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5340 - val_loss: 0.5820 - 238ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5260 - val_loss: 0.5725 - 230ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5186 - val_loss: 0.5680 - 237ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5115 - val_loss: 0.5639 - 206ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5047 - val_loss: 0.5657 - 227ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5001 - val_loss: 0.5530 - 253ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.4946 - val_loss: 0.5570 - 241ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4900 - val_loss: 0.5487 - 262ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4856 - val_loss: 0.5426 - 296ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4825 - val_loss: 0.5436 - 277ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4782 - val_loss: 0.5431 - 229ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4763 - val_loss: 0.5360 - 299ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4711 - val_loss: 0.5326 - 223ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4691 - val_loss: 0.5261 - 239ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4658 - val_loss: 0.5222 - 236ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4635 - val_loss: 0.5237 - 223ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4608 - val_loss: 0.5250 - 315ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4587 - val_loss: 0.5206 - 274ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4546 - val_loss: 0.5179 - 294ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4541 - val_loss: 0.5139 - 231ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4516 - val_loss: 0.5168 - 252ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4499 - val_loss: 0.5194 - 235ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4480 - val_loss: 0.5143 - 232ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4461 - val_loss: 0.5170 - 217ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4456 - val_loss: 0.5094 - 225ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4417 - val_loss: 0.5136 - 230ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4409 - val_loss: 0.5087 - 226ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4395 - val_loss: 0.5064 - 244ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4379 - val_loss: 0.5086 - 220ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4372 - val_loss: 0.5019 - 230ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4346 - val_loss: 0.5086 - 228ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4340 - val_loss: 0.5110 - 220ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4334 - val_loss: 0.5008 - 236ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4298 - val_loss: 0.5011 - 260ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4297 - val_loss: 0.5007 - 329ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4287 - val_loss: 0.4991 - 246ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4260 - val_loss: 0.4988 - 258ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4258 - val_loss: 0.4968 - 255ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4241 - val_loss: 0.4979 - 208ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4231 - val_loss: 0.4969 - 232ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4219 - val_loss: 0.4930 - 235ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4205 - val_loss: 0.4933 - 240ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4189 - val_loss: 0.4955 - 250ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4185 - val_loss: 0.4887 - 236ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4175 - val_loss: 0.4892 - 229ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4158 - val_loss: 0.4883 - 264ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4150 - val_loss: 0.4861 - 300ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4136 - val_loss: 0.4833 - 248ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4127 - val_loss: 0.4874 - 245ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4110 - val_loss: 0.4849 - 296ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4107 - val_loss: 0.4837 - 252ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4085 - val_loss: 0.4858 - 238ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4090 - val_loss: 0.4867 - 271ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4073 - val_loss: 0.4816 - 223ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4066 - val_loss: 0.4785 - 228ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4055 - val_loss: 0.4875 - 233ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4042 - val_loss: 0.4817 - 230ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4026 - val_loss: 0.4861 - 231ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4016 - val_loss: 0.4869 - 212ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4018 - val_loss: 0.4831 - 231ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4004 - val_loss: 0.4828 - 232ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.3990 - val_loss: 0.4756 - 206ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3975 - val_loss: 0.4757 - 229ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4758 - 217ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4726 - 208ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3943 - val_loss: 0.4701 - 213ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3940 - val_loss: 0.4744 - 227ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3916 - val_loss: 0.4734 - 208ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3917 - val_loss: 0.4736 - 223ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3914 - val_loss: 0.4711 - 219ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3891 - val_loss: 0.4737 - 249ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3897 - val_loss: 0.4738 - 267ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3887 - val_loss: 0.4714 - 246ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4699 - 280ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3868 - val_loss: 0.4699 - 261ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3862 - val_loss: 0.4666 - 213ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3853 - val_loss: 0.4689 - 219ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3837 - val_loss: 0.4677 - 259ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3828 - val_loss: 0.4754 - 257ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3825 - val_loss: 0.4658 - 226ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3814 - val_loss: 0.4699 - 218ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3807 - val_loss: 0.4695 - 219ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3796 - val_loss: 0.4653 - 210ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3782 - val_loss: 0.4664 - 211ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3784 - val_loss: 0.4674 - 230ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3769 - val_loss: 0.4659 - 166ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3759 - val_loss: 0.4608 - 170ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3752 - val_loss: 0.4681 - 171ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3740 - val_loss: 0.4631 - 169ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3724 - val_loss: 0.4632 - 160ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3727 - val_loss: 0.4667 - 167ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 다음으로, Early stop 을 적용할 모델을 학습합니다.\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "history_es = MLP_model_es.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e72dc1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score: 0.517047\n"
     ]
    }
   ],
   "source": [
    "# Early stop 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c56649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score: 0.530186\n"
     ]
    }
   ],
   "source": [
    "# Early stop 을 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_es.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f852d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAACMHElEQVR4nOzdd3xT9f7H8ddJ2iRN0r1pSwdlF8qesrwgQxEQERVlKFwV50V+ClfcV71XEcGJC3CAIspSEYUqiAiyh7bssrtLd5s0yfn9EQjUMlpoG8bn+bjnUXJyxvekvfbd71RUVVURQgghhHATjbsLIIQQQohrm4QRIYQQQriVhBEhhBBCuJWEESGEEEK4lYQRIYQQQriVhBEhhBBCuJWEESGEEEK4lYQRIYQQQriVh7sLUBUOh4Pjx4/j7e2NoijuLo4QQgghqkBVVQoLC6lXrx4azbnrP66IMHL8+HGioqLcXQwhhBBCXIQjR44QGRl5zveviDDi7e0NOB/Gx8fHzaURQgghRFUUFBQQFRXl+j1+LldEGDnVNOPj4yNhRAghhLjCXKiLhXRgFUIIIYRbSRgRQgghhFtJGBFCCCGEW10RfUaEEOJqoKoqNpsNu93u7qIIUSO0Wi0eHh6XPO2GhBEhhKgDVquVtLQ0SkpK3F0UIWqU0WgkPDwcnU530deQMCKEELXM4XCQmpqKVqulXr166HQ6mcBRXPFUVcVqtZKVlUVqaioNGzY878Rm5yNhRAghapnVasXhcBAVFYXRaHR3cYSoMV5eXnh6enLo0CGsVisGg+GiriMdWIUQoo5c7F+NQlzOauLnWv6fIYQQQgi3kjAihBBCCLeSMCKEEKLOxMTEMH36dHcX47Iin4mEESGEEOfRs2dPHnvssRq73saNG/nnP/9ZY9erqk8++YTrrrvuos+PiYlBUZRK23//+98aLGXVZGVl8cADD1C/fn30ej1hYWH07duXtWvXuo5RFIXFixfXedku1jU9mubz5M85WHCQO5vcSZxfnLuLI4QQVyRVVbHb7Xh4XPhXSnBwcB2UqLIlS5Zw8803X9I1XnjhBcaNG1dh34VWoz0fq9V6UXNzDB06FKvVyieffEJcXBwZGRkkJSWRk5Nz0WVxt2u6ZuSH1B+Yv3s+qQWp7i6KEOIao6oqJVZbnW+qqla5jKNHj2b16tXMmDHDVRNw8OBBVq1ahaIo/PDDD7Rt2xa9Xs9vv/3G/v37GTRoEKGhoZjNZtq3b8/KlSsrXPPvTRKKovDRRx8xZMgQjEYjDRs2ZOnSpecs09tvv01CQoLr9eLFi1EUhZkzZ7r29e7dmylTprhel5WV8dNPP7nCyIkTJxg5ciT+/v4YjUb69+/P3r17L/h5eHt7ExYWVmEzmUwA2O127r33XmJjY/Hy8qJx48bMmDGj0uc5ePBgXnrpJerVq0fjxo0r3eOee+7hpptuqrCvvLyckJAQPv74Y/Ly8lizZg3/+9//6NWrF9HR0XTo0IHJkye7ni8mJgaAIUOGoCiK6zXAe++9R4MGDdDpdDRu3JjPPvuswr0UReG9996jf//+eHl5ERcXx9dff33Bz+ZSXdM1I756XwAKLAVuLokQ4lpTWm6n2TM/1vl9k1/oi1FXtf/0z5gxgz179pCQkMALL7wAOGs2Dh48CMCkSZOYOnUqcXFx+Pv7c+TIEQYMGMBLL72EXq/n008/ZeDAgezevZv69euf8z7PP/88r776Kq+99hpvvfUWI0aM4NChQwQEBFQ6tkePHjzyyCNkZWURHBzM6tWrCQoKYtWqVdx///2Ul5ezbt06Jk2a5DonKSmJiIgImjRpAjhDwd69e1m6dCk+Pj48+eSTDBgwgOTkZDw9Pav6UVbgcDiIjIxkwYIFBAYG8vvvv/PPf/6T8PBwbrvttgpl8fHxYcWKFWe9ztixY+nevTtpaWmEh4cD8N1331FSUsLw4cMxGAyYzWYWL15Mp06d0Ov1la6xceNGQkJCmD17Nv369UOr1QKwaNEiHn30UaZPn07v3r357rvvGDNmDJGRkfTq1ct1/tNPP81///tfZsyYwWeffcbtt9/Ozp07adq06UV9NlVxTdeMxB+x0XGXg5L0Y+4uihBCXHZ8fX3R6XQYjUZXTcCpX2zgbLbo06cPDRo0ICAggMTERO677z4SEhJo2LAhL774Ig0aNDhvTQc4w8Edd9xBfHw8L7/8MkVFRWzYsOGsxyYkJBAQEMDq1asBWLVqFY8//rjr9YYNGygvL6dLly6uc85sojkVQj766CO6detGYmIic+fO5dixYxfsY/Hkk09iNpsrbGvWrAHA09OT559/nnbt2hEbG8uIESMYM2YMX331VYVrmEwmPvroI5o3b07z5s0r3aNLly6Vaixmz57NsGHDMJvNeHh4MGfOHD755BP8/Pzo2rUr//73v9mxY4fr+FNNYX5+foSFhbleT506ldGjRzN+/HgaNWrEhAkTuOWWW5g6dWqFMgwbNoyxY8fSqFEjXnzxRdq1a8dbb7113s/mUl3TNSOdvkqmf6qDLXH7oZu7SyOEuJZ4eWpJfqGvW+5bU9q1a1fhdVFREc899xzff/89aWlp2Gw2SktLOXz48Hmv07JlS9e/TSYTPj4+ZGZmnvVYRVHo3r07q1atonfv3iQnJzN+/HheffVVdu3axerVq2nfvr1rpltVVfn2229doSAlJQUPDw86duzoumZgYCCNGzcmJSXlvOX8v//7P0aPHl1hX0REhOvf77zzDrNmzeLw4cOUlpZitVpp1apVheNbtGhxwX4iY8eO5YMPPuCJJ54gIyODH374gZ9//tn1/tChQ7nxxhtZs2YN69ev54cffuDVV1/lo48+qlS+M6WkpFTqPNy1a9dKzUmdO3eu9Hrbtm3nLfOluqbDCCYvAKyFee4thxDimqMoSpWbSy5Xp/pLnDJx4kRWrFjB1KlTiY+Px8vLi1tvvRWr1Xre6/y9aURRFBwOxzmP79mzJx988AFr1qyhdevW+Pj4uALK6tWr6dGjh+vYDRs2YLPZKtSUXKygoCDi4+PP+t6XX37JxIkTef311+ncuTPe3t689tpr/PHHHxWO+/tndjYjR45k0qRJrFu3jt9//53Y2Fi6dav4F7PBYKBPnz706dOHp59+mrFjx/Lss8+eN4xczq7pZhrlZHIuLyp0c0mEEOLypNPpsNvtVTp27dq1jB49miFDhtCiRQvCwsJc/UtqUo8ePUhOTmbBggX07NkTcAaUlStXsnbtWtc+cDbR3Hjjja7mpaZNm2Kz2SqEhJycHHbv3k2zZs0uukxr166lS5cujB8/ntatWxMfH8/+/fsv6lqBgYEMHjyY2bNnM2fOHMaMGXPBc5o1a0ZxcbHrtaenZ6XvW9OmTSsM/z1V7r8/9/r16yu9rs3+InCN14xozc4hWY6iIjeXRAghLk8xMTH88ccfHDx4ELPZfNZOpac0bNiQhQsXMnDgQBRF4emnnz5vDcfFatmyJf7+/sybN4/vvvsOcIaRiRMnoigKXbt2dR27dOlSV+fbU2UcNGgQ48aN4/3338fb25tJkyYRERHBoEGDznvfwsJC0tPTK+wzGo34+PjQsGFDPv30U3788UdiY2P57LPP2LhxI7GxsRf1jGPHjuWmm27CbrczatQo1/6cnByGDRvGPffcQ8uWLfH29mbTpk28+uqrFcofExNDUlISXbt2Ra/X4+/vz//93/9x22230bp1a3r37s23337LwoULK414WrBgAe3ateO6665j7ty5bNiwgY8//viinqOqrumaEU9vHwDUM9KkEEKI0yZOnIhWq6VZs2YEBweft//HtGnT8Pf3p0uXLgwcOJC+ffvSpk2bGi+Toih069YNRVFcE5m1bNkSHx8f2rVr52oK2b9/P/v27aNv34p9c2bPnk3btm256aab6Ny5M6qqsmzZsguOpHnmmWcIDw+vsD3xxBMA3Hfffdxyyy0MHz6cjh07kpOTw/jx4y/6GXv37k14eDh9+/alXr16rv1ms5mOHTvyxhtv0L17dxISEnj66acZN24cb7/9tuu4119/nRUrVhAVFUXr1q0BGDx4MDNmzGDq1Kk0b96c999/n9mzZ1eoSQLn6KYvv/ySli1b8umnn/LFF19cUq1RVShqdQadu0lBQQG+vr7k5+fj4+NTY9dN/s+/UT5fxC+dTYyfvanGriuEEGcqKysjNTWV2NjYi15iXVTftGnTWLlyJcuWLXN3UaqtqKiIiIgIZs+ezS233FJn91UUhUWLFjF48OAqn3O+n++q/v6+pptp9D5+WAFticXdRRFCCFHDIiMjmTx5sruLUS0Oh4Ps7Gxef/11/Pz8LnnW2CtFtZtpfv31VwYOHEi9evWqPPf9qlWraNOmDXq9nvj4eObMmXMRRa15Xr6BAHha7FjsEkiEEOJqctttt1UahXK5O3z4MKGhocybN49Zs2ZVaYr9q0G1n7K4uJjExETuueeeKlUdpaamcuONN3L//fczd+5ckpKSGDt2rKstzJ2MPoHkA14WyLfkE2IMcWt5hBBCXNtiYmKqNWV/TXPXvasdRvr370///v2rfPzMmTOJjY3l9ddfB5xDi3777TfeeOMNt4cRjdnZycnLqkoYEUIIIdyk1kfTrFu3jt69e1fY17dvX9atW3fOcywWCwUFBRW22qA1m4HTNSNCCCGEqHu1HkbS09MJDQ2tsC80NJSCggJKS0vPes4rr7yCr6+va4uKiqqVsmlMp2pGJIwIIYQQ7nJZzjMyefJk8vPzXduRI0dq5T6aUzUjVsi3ShgRQggh3KHWu+mGhYWRkZFRYV9GRgY+Pj54eXmd9Ry9Xn/WZZFrmqtmxAJ5ZSdq/X5CCCGEqKzWa0Y6d+5MUlJShX0rVqyotCqgO2hMzpoRrQqFhbluLo0QQlz9YmJimD59uruLUWfmzJmDn5+fu4tx2at2GCkqKmLbtm2u5YRTU1PZtm2ba4rgyZMnM3LkSNfx999/PwcOHOCJJ55g165dvPvuu3z11Vf861//qpknuAQa4+mamZL8HDeWRAghLk89e/bkscceq7Hrbdy4sdIy9nXhk08+cU0d/3dz5sxBUZRKm7tmy120aBGdOnXC19cXb29vmjdvXuF78Nxzz9GqVSu3lK22VLuZZtOmTfTq1cv1esKECQCMGjWKOXPmkJaWVmHtgtjYWL7//nv+9a9/MWPGDCIjI/noo4/cPqwXQNFosHvp0JZaKSuQmhEhhLgYqqpit9urNEFXcHBwHZSosiVLlpx3NlMfHx92795dYZ+iKJd0z/Ly8mqfk5SUxPDhw3nppZe4+eabURSF5ORkVqxYcUllueypV4D8/HwVUPPz82v82ju6dFSTGzdRJ304rMavLYQQqqqqpaWlanJyslpaWuruolTLqFGjVKDClpqaqv7yyy8qoC5btkxt06aN6unpqf7yyy/qvn371JtvvlkNCQlRTSaT2q5dO3XFihUVrhkdHa2+8cYbrteA+uGHH6qDBw9Wvby81Pj4eHXJkiXnLNNbb72lNm/e3PV60aJFKqC+9957rn3/+Mc/1Keeesr1urS0VDWZTGpKSspZrzl79mzV19f3vJ/FDz/8oHbt2lX19fVVAwIC1BtvvFHdt2+f6/3U1FQVUL/88ku1e/fuql6vV2fPnl3h2qmpqaqiKOrGjRsrXPuNN95Q69evr9rtdvXRRx9Ve/bsec5yzJ49u9L3ZPbs2aqqquqhQ4fUm2++WTWZTKq3t7c6bNgwNT093XXus88+qyYmJqozZ85UIyMjVS8vL3XYsGFqXl7eeZ/9Qs73813V39+X5WiauqSYjABYC2U0jRCiDqkqWIvrfqvGDJszZsygc+fOjBs3jrS0NNLS0ipMtTBp0iT++9//kpKSQsuWLSkqKmLAgAEkJSWxdetW+vXrx8CBA8+70i84V4m97bbb2LFjBwMGDGDEiBHk5p69trpHjx4kJyeTlZUFwOrVqwkKCmLVqlWAszZi3bp1FVaiTUpKIiIigiZNmlT52f+uuLiYCRMmsGnTJpKSktBoNAwZMgSHw1HhuEmTJvHoo4+SkpJSqQUgJiaG3r17M3v27Ar7Z8+ezejRo9FoNISFhfHXX3/x559/nrUcw4cP5/HHH6d58+au78nw4cNxOBwMGjSI3NxcVq9ezYoVKzhw4ADDhw+vcP6+ffv46quv+Pbbb1m+fDlbt269pNWFa8q1Men9eZyahdVeWOTmkgghrinlJfByvQsfV9P+fRx0piod6uvri06nw2g0EhYWVun9F154gT59+rheBwQEkJiY6Hr94osvsmjRIpYuXcpDDz10zvuMHj2aO+64A4CXX36ZN998kw0bNtCvX79KxyYkJBAQEMDq1au59dZbWbVqFY8//jgzZswAYMOGDZSXl9OlSxfXORdqogHIz8/HfHK6h1O6devGDz/8AMDQoUMrvDdr1iyCg4NJTk4mISHBtf+xxx4771IpY8eO5f7772fatGno9Xq2bNnCzp07WbJkCQAPP/wwa9asoUWLFkRHR9OpUyduuOEGRowYgV6vx8vLC7PZjIeHR4XvyYoVK9i5cyepqamuwPjpp5/SvHlzNm7cSPv27QHnCruffvopERERALz11lvceOONvP7662f9HteVa7tmZO9KPHBOvOYoLnZzYYQQ4srSrl27Cq+LioqYOHEiTZs2xc/PD7PZTEpKygVrRlq2bOn6t8lkwsfHh8zMzLMeqygK3bt3Z9WqVeTl5ZGcnMz48eOxWCzs2rWL1atX0759e4xGZ623qqp8++23Fwwj3t7ersEZp7aPPvrI9f7evXu54447iIuLw8fHh5iYGIBKz/b3z+TvBg8ejFarZdGiRYCz82yvXr1c1zOZTHz//ffs27ePKVOmYDabefzxx+nQoQMlJSXnvG5KSgpRUVEVaq6aNWuGn58fKSkprn3169d3BRFwjnh1OByV+svUtWu7ZuSXl9AVHKQUAx5l5ZTZyjB4uKf3tBDiGuNpdNZSuOO+NcRkqljDMnHiRFasWMHUqVOJj4/Hy8uLW2+9FavVev4ieXpWeK0oSqXmjzP17NmTDz74gDVr1tC6dWt8fHxcAWX16tX06NHDdeyGDRuw2WwVakrORqPREB8ff873Bw4cSHR0NB9++CH16tXD4XCQkJBQ6dn+/pn8nU6nY+TIkcyePZtbbrmFefPmuWp1ztSgQQMaNGjA2LFjeeqpp2jUqBHz589nzJgx573+leraDiMGHzw9HJRyekp4CSNCiDqhKFVuLnEnnU6H3W6v0rFr165l9OjRDBkyBHDWlBw8eLDGy9SjRw8ee+wxFixY4Oob0rNnT1auXMnatWt5/PHHXccuWbKEG2+8Ea1We9H3y8nJYffu3Xz44Yd069YNgN9+++2irzd27FgSEhJ49913sdls523WAWdfE6PRSPHJGvyzfU+aNm3KkSNHOHLkiKt2JDk5mby8PJo1a+Y67vDhwxw/fpx69ZxNhOvXr0ej0dC4ceOLfp6acG2HEb03Wk9n+vayqORb8wk1hV7gJCGEuHbExMTwxx9/cPDgQcxmMwEBAec8tmHDhixcuJCBAweiKApPP/30eWs4LlbLli3x9/dn3rx5fPfdd4AzjEycOBFFUejatavr2KVLl/LCCy9c8JqqqpKenl5pf0hICP7+/gQGBvLBBx8QHh7O4cOHmTRp0kWXv2nTpnTq1Iknn3ySe+65p8Js5M899xwlJSUMGDCA6Oho8vLyePPNNykvL3f1z4mJiXHN8RUZGYm3tze9e/emRYsWjBgxgunTp2Oz2Rg/fjw9evSo0HRkMBgYNWoUU6dOpaCggEceeYTbbrvNrf1F4FrvM6L3RePh7Fkui+UJIURlEydORKvV0qxZM4KDg8/b/2PatGn4+/vTpUsXBg4cSN++fWnTpk2Nl0lRFLp164aiKK6JzFq2bImPjw/t2rVzNZXs37+fffv2VWleq4KCAsLDwyttmZmZaDQavvzySzZv3kxCQgL/+te/eO211y7pGe69916sViv33HNPhf09evTgwIEDjBw5kiZNmtC/f3/S09P56aefXLUXQ4cOpV+/fvTq1Yvg4GC++OILFEVhyZIl+Pv70717d3r37k1cXBzz58+vcP34+HhuueUWBgwYwA033EDLli159913L+lZaoKiqtUY5+UmBQUF+Pr6kp+fj4+PT81d+IdJZM/+jKwdPvzSQqHR1DfpHd275q4vhBA4RzCkpqYSGxvrtlk9r0XTpk1j5cqVLFu2zN1FqeTFF19kwYIF7Nixo87u+dxzz7F48WLXDOo15Xw/31X9/X1t14wYfNCcaqaxQp4lz73lEUIIUWMiIyOZPHmyu4tRQVFREX/++Sdvv/02Dz/8sLuLc9m4xvuM+KA91UxjkWYaIYS4mtx2223uLkIlDz30EF988QWDBw+u1ERzLbu2a0b03mg8T/UZcXZgFUIIIWrLnDlzsFgszJ8//5JG+FyM5557rsabaGrKtR1G/tZMIzUjQgghRN27tsPImTUj0kwjhBBCuMU1HkZ80XhIzYgQQgjhTtd4GDmzzwjklZ1wc4GEEEKIa881HUY+2pjjGk2jUaGsSGpGhBBCiLp2TYeRn1NLUTxUwBlIrAX5XAFzwAkhhBBXlWs6jJi9fXGgoJxsqtGWWSmzl7m5VEIIcXWJiYlh+vTprteKorB48eJzHn/w4EEURblsh6HWhr9/RteaazqMBPkYKMLr9MRn0olVCCFqXVpaGv3796/z+37yySeutWwuRkxMDIqiVNr++9//1mApqyYrK4sHHniA+vXro9frCQsLo2/fvqxdu9Z1zIVC3+Xkmp6BNcikoxCjc66RUq1z4jNLPmEm965eKIQQVzN3rRC7ZMkSbr755ku6xgsvvMC4ceMq7PP29r7o61mtVnQ6XbXPGzp0KFarlU8++YS4uDgyMjJISkoiJyfnosviTtd2zYi3nkLVS+YaEUKIs/jggw+oV68eDoejwv5Bgwa5pjLfv38/gwYNIjQ0FLPZTPv27Vm5cuV5r/v3v9g3bNhA69atMRgMtGvXjq1bt573/LfffpuEhATX68WLF6MoCjNnznTt6927N1OmTHG9Lisr46effnKFkRMnTjBy5Ej8/f0xGo3079+fvXv3nv8DwRk8wsLCKmynVgm22+3ce++9xMbG4uXlRePGjZkxY0aF80ePHs3gwYN56aWXqFevnmsl3jPdc8893HTTTRX2lZeXExISwscff0xeXh5r1qzhf//7H7169SI6OpoOHTowefJk1/PFxMQAMGTIEBRFcb0GeO+992jQoAE6nY7GjRvz2WefVbiXoii899579O/fHy8vL+Li4vj6668v+Nlcims7jJj1lZtpZEp4IUQdUFWVkvKSOt+q00l/2LBh5OTk8Msvv7j25ebmsnz5ckaMGAE4F34bMGAASUlJbN26lX79+jFw4EAOHz5cpXsUFRVx00030axZMzZv3sxzzz3HxIkTz3tOjx49SE5OJisrC4DVq1cTFBTEqlWrAOcv7nXr1tGzZ0/XOUlJSURERNCkSRPAGQo2bdrE0qVLWbduHaqqMmDAAMrLy6v68VTicDiIjIxkwYIFJCcn88wzz/Dvf/+br776qsJxSUlJ7N69mxUrVvDdd99Vus7YsWNZvnw5aWlprn3fffcdJSUlDB8+HLPZjNlsZvHixVgslrOWZePGjQDMnj2btLQ01+tFixbx6KOP8vjjj/Pnn39y3333MWbMmArfY4Cnn36aoUOHsn37dkaMGMHtt99OSkrKRX82F3JtN9OY9RSqRsI9nT/QXhZZuVcIUTdKbaV0nNexzu/7x51/YPQ0VulYf39/+vfvz7x58/jHP/4BwNdff01QUBC9evUCIDExkcTERNc5L774IosWLWLp0qU89NBDF7zHvHnzcDgcfPzxxxgMBpo3b87Ro0d54IEHznlOQkICAQEBrF69mltvvZVVq1bx+OOPu2ohNmzYQHl5OV26dHGdc2YTzd69e1m6dClr1651HTN37lyioqJYvHgxw4YNO+e9n3zyyQo1LgA//PAD3bp1w9PTk+eff961PzY2lnXr1vHVV19VWLTPZDLx0UcfnbN5pkuXLq4aiyeeeAJwhophw4ZhNpsB5xo348aNY+bMmbRp04YePXpw++2307JlSwCCg4MB8PPzq9AsNnXqVEaPHs348eMBmDBhAuvXr2fq1Kmu7yk4g+jYsWMB5/d0xYoVvPXWW7z77rvn/GwuxTVeM3Kyz4h0YBVCiLMaMWIE33zzjesv8Llz53L77bej0Th/fRQVFTFx4kSaNm2Kn58fZrOZlJSUKteMpKSk0LJlSwwGg2tf586dz3uOoih0796dVatWkZeXR3JyMuPHj8disbBr1y5Wr15N+/btMRqdoUtVVb799ltXGElJScHDw4OOHU+HwcDAQBo3bnzBv/7/7//+j23btlXY2rVr53r/nXfeoW3btgQHB2M2m/nggw8qfRYtWrS4YD+RsWPHMnv2bAAyMjL44YcfKqzyO3ToUI4fP87SpUvp168fq1atok2bNsyZM+e8101JSaFr164V9nXt2rXSc//9e9C5c2epGaktQd56ilSvMxbLUyWMCCHqhJeHF3/c+Ydb7lsdAwcORFVVvv/+e9q3b8+aNWt44403XO9PnDiRFStWMHXqVOLj4/Hy8uLWW2/FarXWdNEr6NmzJx988AFr1qyhdevW+Pj4uALK6tWr6dGjh+vYDRs2YLPZKtSUXKygoCDi4+PP+t6XX37JxIkTef311+ncuTPe3t689tpr/PFHxe/zqT4m5zNy5EgmTZrEunXr+P3334mNjaVbt24VjjEYDPTp04c+ffrw9NNPM3bsWJ599llGjx590c/nLtd0zYi33oNijVE6sAoh6pyiKBg9jXW+KYpSrXIaDAZuueUW5s6dyxdffEHjxo1p06aN6/21a9cyevRohgwZQosWLQgLC+PgwYNVvn7Tpk3ZsWMHZWWn53hav379Bc871W9kwYIFrr4hPXv2ZOXKlaxdu7ZCf5ElS5Zw4403otVqXfe02WwVQkJOTg67d++mWbNmVS77351q9hk/fjytW7cmPj6e/fv3X9S1AgMDGTx4MLNnz2bOnDmMGTPmguc0a9aM4uJi12tPT0/sdnuFY5o2bVph+O+pcv/9uf/+PVi/fj1Nmzat7mNU2TUdRhRFQfWsuD6NhBEhhKhoxIgRfP/998yaNcvVcfWUhg0bsnDhQrZt28b27du58847K42+OZ8777wTRVEYN24cycnJLFu2jKlTp17wvJYtW+Lv78+8efMqhJFTnTrPbIpYunRphSG9DRs2ZNCgQYwbN47ffvuN7du3c9dddxEREcGgQYPOe9/CwkLS09MrbAUFBa7rbtq0iR9//JE9e/bw9NNPuzqOXoyxY8fyySefkJKSwqhRo1z7c3JyuP766/n888/ZsWMHqampLFiwgFdffbVC+WNiYkhKSiI9PZ0TJ5xrr/3f//0fc+bM4b333mPv3r1MmzaNhQsXVuo0vGDBAmbNmsWePXt49tln2bBhQ5X6AF009QqQn5+vAmp+fn6NX3vmq0+ouXeGqcmNm6izBzZVRy4bWeP3EEJc20pLS9Xk5GS1tLTU3UW5KHa7XQ0PD1cBdf/+/RXeS01NVXv16qV6eXmpUVFR6ttvv6326NFDffTRR13HREdHq2+88YbrNaAuWrTI9XrdunVqYmKiqtPp1FatWqnffPONCqhbt249b7kGDRqkenh4qIWFha5y+vv7q506dXIds2/fPlWv16tFRUUVzs3NzVXvvvtu1dfXV/Xy8lL79u2r7tmz57z3i46OPrV+SIXtvvvuU1VVVcvKytTRo0ervr6+qp+fn/rAAw+okyZNUhMTE13XGDVqlDpo0KCzXvvMz0hVVdXhcKjR0dHqgAEDKuwvKytTJ02apLZp00b19fVVjUaj2rhxY3XKlClqSUmJ67ilS5eq8fHxqoeHhxodHe3a/+6776pxcXGqp6en2qhRI/XTTz+tcH1Afeedd9Q+ffqoer1ejYmJUefPn3/Oz+V8P99V/f2tnLzxZa2goABfX1/y8/Px8fGp0Wt/+PbL3LbpTY6v92dHjMKXDzRm0aBFNXoPIcS1raysjNTUVGJjYyt01BS1b9q0aaxcuZJly5a5uyjVVlRUREREBLNnz+aWW26ps/sqisKiRYsYPHhwlY4/3893VX9/X9MdWAE8jT6nO7BapAOrEEJcTSIjI5k8ebK7i1EtDoeD7OxsXn/9dfz8/C551tgrwTUfRvQm/wpDe/MseaiqWu1OXkIIIS4/Z87vcaU4fPgwsbGxREZGMmfOHDw8rv5f1Vf/E16A0du/QgfWckc5pbbSKk8KJIQQQtSkmJiYas2UW9Pcce9rejQNgNHXH43HqXlGnPukqUYIIYSoO9d8GPH1DUB7smbEYAVUVdanEUIIIerQNR9G/AKCXM00GhX05VIzIoQQQtSlaz6MBPl6Y9F4gOIMJEZZLE8IIYSoU9d8GPHz8qRY8ZLF8oQQQgg3uebDiEajUKKYzphrBAqsBW4ulRBCCHHtuObDCECZ1nRGzYhKXlmeewskhBBXkZiYGKZPn+56rSgKixcvPufxBw8eRFEUtm3bVutlqwtz5szBz8/P3cW4rEkYAco9zK4RNV5WZDSNEELUorS0NPr371/n9/3kk0+47rrrzvrenDlzUBSl0uau6fsXLVpEp06d8PX1xdvbm+bNm/PYY4+53n/uuedo1aqVW8pWGy4qjLzzzjvExMRgMBjo2LEjGzZsOOex5eXlvPDCCzRo0ACDwUBiYiLLly+/6ALXBoenuUIzjXRgFUKI2hMWFoZer6/z+y5ZsuS8U6v7+PiQlpZWYTt06NAl3bO8vLza5yQlJTF8+HCGDh3Khg0b2Lx5My+99NJFXetKUe0wMn/+fCZMmMCzzz7Lli1bSExMpG/fvmRmZp71+ClTpvD+++/z1ltvkZyczP3338+QIUPYunXrJRe+pqgGnwodWAss0mdECCE++OAD6tWrh8PhqLB/0KBB3HPPPQDs37+fQYMGERoaitlspn379qxcufK81/17M82GDRto3bo1BoOBdu3aXfD3w9tvv01CQoLr9eLFi1EUhZkzZ7r29e7dmylTprhel5WV8dNPP503jCiKQlhYWIUtNDTU9f7y5cu57rrr8PPzIzAwkJtuuon9+/e73j/VvDR//nx69OiBwWBg7ty5Fe5x8OBBNBoNmzZtqrB/+vTpREdH43A4+Pbbb+natSv/93//R+PGjWnUqBGDBw/mnXfeAZy1OM8//zzbt2931eDMmTMHcE4lP2jQIMxmMz4+Ptx2221kZGS47nOqRuX9998nKioKo9HIbbfdRn6+e1sEqh1Gpk2bxrhx4xgzZgzNmjVj5syZGI1GZs2addbjP/vsM/79738zYMAA4uLieOCBBxgwYACvv/76JRe+pigG39NTwkvNiBCiDqiqiqOkpM636kz1PWzYMHJycvjll19c+3Jzc1m+fDkjRowAnCvLDhgwgKSkJLZu3Uq/fv0YOHAghw8frtI9ioqKuOmmm2jWrBmbN2/mueeeY+LEiec9p0ePHiQnJ5OVlQXA6tWrCQoKYtWqVYCzNmLdunX07NnTdU5SUhIRERE0adKkys//d8XFxUyYMIFNmzaRlJSERqNhyJAhlcLapEmTePTRR0lJSaFv374V3ouJiaF3797Mnj27wv7Zs2czevRoNBoNYWFh/PXXX/z5559nLcfw4cN5/PHHad68uasGZ/jw4TgcDgYNGkRubi6rV69mxYoVHDhwgOHDh1c4f9++fXz11Vd8++23LF++nK1btzJ+/PiL/lxqQrXWprFarWzevLnCCogajYbevXuzbt26s55jsVgqtbl5eXnx22+/nfM+FosFi8Xiel1QULs1FRVW7rXKyr1CiNqnlpayu03bOr9v4y2bUYxVW3vL39+f/v37M2/ePP7xj38A8PXXXxMUFESvXr0ASExMJDEx0XXOiy++yKJFi1i6dCkPPfTQBe8xb948HA4HH3/8MQaDgebNm3P06FEeeOCBc56TkJBAQEAAq1ev5tZbb2XVqlU8/vjjzJgxA3DWtJSXl9OlSxfXORdqogHIz8/HbDZX2NetWzd++OEHAIYOHVrhvVmzZhEcHExycnKFmprHHnuMW2655Zz3GTt2LPfffz/Tpk1Dr9ezZcsWdu7cyZIlSwB4+OGHWbNmDS1atCA6OppOnTpxww03MGLECPR6PV5eXpjNZjw8PAgLC3Ndd8WKFezcuZPU1FSioqIA+PTTT2nevDkbN26kffv2gLOW6NNPPyUiIgKAt956ixtvvJHXX3+9wvXqUrVqRrKzs7Hb7RWqrQBCQ0NJT08/6zl9+/Zl2rRp7N27F4fDwYoVK1i4cCFpaWnnvM8rr7yCr6+vazv1odYW3Zkr91qc84y4c5EiIYS4XIwYMYJvvvnG9Qfi3Llzuf3229FonL8+ioqKmDhxIk2bNsXPzw+z2UxKSkqVa0ZSUlJo2bJlhT9aO3fufN5zFEWhe/furFq1iry8PJKTkxk/fjwWi4Vdu3axevVq2rdvj/Fk6FJVlW+//faCYcTb25tt27ZV2D766CPX+3v37uWOO+4gLi4OHx8fYmJiACo9a7t27c57n8GDB6PValm0aBHgbHbp1auX63omk4nvv/+effv2MWXKFMxmM48//jgdOnSgpKTknNdNSUkhKiqqwu/MZs2a4efnR0pKimtf/fr1XUEEnJ+3w+Fg9+7d5y13bar1VXtnzJjBuHHjaNKkCYqi0KBBA8aMGXPOZh2AyZMnM2HCBNfrgoKCWg0kBrNvhdE0NtVGia0Ek6ep1u4phLi2KV5eNN6y2S33rY6BAweiqirff/897du3Z82aNbzxxhuu9ydOnMiKFSuYOnUq8fHxeHl5ceutt2K1Wmu66BX07NmTDz74gDVr1tC6dWt8fHxcAWX16tX06NHDdeyGDRuw2WwVakrORqPREB8ff873Bw4cSHR0NB9++KGrL01CQkKlZzWZzv+7Q6fTMXLkSGbPns0tt9zCvHnzXLU6Z2rQoAENGjRg7NixPPXUUzRq1Ij58+czZsyY817/SlStMBIUFIRWq63QGQYgIyPjnFU7wcHBLF68mLKyMnJycqhXrx6TJk0iLi7unPfR6/V12tPa5BOA42QzjancmfbzLHkSRoQQtUZRlCo3l7iTwWDglltuYe7cuezbt4/GjRvTpk0b1/tr165l9OjRDBkyBHDWlBw8eLDK12/atCmfffYZZWVlrtqR9evXX/C8Hj168Nhjj7FgwQJX35CePXuycuVK1q5dy+OPP+46dsmSJdx4441otdoql+vvcnJy2L17Nx9++CHdunUDOG93gwsZO3YsCQkJvPvuu9hstvM264Czr4nRaKS4uBhwBhq73V7hmKZNm3LkyBGOHDni+gM+OTmZvLw8mjVr5jru8OHDHD9+nHr16gHOz1uj0dC4ceOLfp5LVa1mGp1OR9u2bUlKSnLtczgcJCUlXbBazWAwEBERgc1m45tvvmHQoEEXV+JaYPY53Uxjtjp/WKUTqxBCOI0YMYLvv/+eWbNmuTquntKwYUMWLlzItm3b2L59O3feeWelDp3nc+edd6IoCuPGjSM5OZlly5YxderUC57XsmVL/P39mTdvXoUwsnjxYiwWC127dnUdu3Tp0gs20YCzOSc9Pb3S5nA48Pf3JzAwkA8++IB9+/bx888/V6jBr66mTZvSqVMnnnzySe644w68zqixeu6553jiiSdYtWoVqampbN26lXvuuYfy8nL69OkDOMNJamoq27ZtIzs7G4vFQu/evWnRogUjRoxgy5YtbNiwgZEjR9KjR48KTUcGg4FRo0axfft21qxZwyOPPMJtt93mtv4icBGjaSZMmMCHH37IJ598QkpKCg888ADFxcWuaqORI0dW6OD6xx9/sHDhQg4cOMCaNWvo168fDoeDJ554ouae4hJpvfxcHViNVudHIp1YhRDC6frrrycgIIDdu3dz5513Vnhv2rRp+Pv706VLFwYOHEjfvn0r1JxciNls5ttvv2Xnzp20bt2ap556iv/9738XPE9RFLp164aiKK6JzFq2bImPjw/t2rVzNZXs37+fffv2VRrVcjYFBQWEh4dX2jIzM9FoNHz55Zds3ryZhIQE/vWvf/Haa69V+TnP5t5778VqtbqGSZ/So0cPDhw4wMiRI2nSpAn9+/cnPT2dn376yVV7MXToUPr160evXr0IDg7miy++QFEUlixZgr+/P927d6d3797ExcUxf/78CtePj4/nlltuYcCAAdxwww20bNmSd99995Ke5ZKpF+Gtt95S69evr+p0OrVDhw7q+vXrXe/16NFDHTVqlOv1qlWr1KZNm6p6vV4NDAxU7777bvXYsWPVul9+fr4KqPn5+RdT3AvLSFaL7g9Skxs3UVdf10pNmJOgLjuwrHbuJYS45pSWlqrJyclqaWmpu4tyzXn99dfV/v37u7sYZ/XCCy+oLVq0qNN7Pvvss2piYmKNXvN8P99V/f19UR1YH3rooXMO2To1zvuUU+PBL2t6b9c8I3qLs4ZEmmmEEOLKFxkZWaG2/nJwql/N22+/zX/+8x93F+eyUOujaa4Ieh+0J5tp9GV2QJFmGiGEuArcdttt7i5CJQ899BBffPEFgwcPrtREc62ShfIAdGYUT+c/9VY7iioTnwkhhKgdc+bMwWKxMH/+/Esa4XMxnnvuuctyNWQJIwAaDTb96Ql3DFZpphFCCCHqioSRkxwGMyjOfiMGq4ymEUIIIeqKhJGTVIOPqxOr0SJhRAhR81RZZkJchWri51rCyEmK3geNh7MTqzTTCCFqkqens1Pa+dYVEeJKdern+tTP+cWQ0TQnab180Hqq2ACjReWwVWpGhBA1Q6vV4ufnR2ZmJgBGoxFFUdxcKiEujaqqlJSUkJmZiZ+f3yV1xpUwcpKnyc81JbzBCgWWAuwOO1pN3fZ0FkJcnU5NtX0qkAhxtfDz87vkqeQljJykNficnhLeAioqhdZC/Ax+7i2YEOKqoCgK4eHhhISEUF5e7u7iCFEjPD09a2R4soSRU87owOpj0wE28q35EkaEEDVKq9XW+dwSQlzupAPrKXpfVwdW73IdIJ1YhRBCiLogYeSUM9anMVmcFUYyvFcIIYSofRJGTjE4R9MAGCzOKlQJI0IIIUTtkzByit779DwjFueQO2mmEUIIIWqfhJFT9Kc7sOrLnF8ljAghhBC1T8LIKWf0GdGdDCPSTCOEEELUPgkjpxhOj6bRldkBCSNCCCFEXZAwcor+zA6sNkCaaYQQQoi6IGHkFL03Gp2zZsRksQJSMyKEEELUBQkjp3ga0Ho55xcxW62gqhJGhBBCiDog08GfQettcn5VVbwskOeZ594CCSGEENcAqRk5g8bkg6J19hsxl0GJrYRyuyxoJYQQQtQmCSNn0nujPdlvxLvUOfFZvlWaaoQQQojaJGHkTAZfVxjxKzMAkFeW58YCCSGEEFc/CSNn0vu4wohPqScgNSNCCCFEbZMwcia9N1r9yWaaEmcYkblGhBBCiNolYeRMhtM1I17Fzo9GhvcKIYQQtUvCyJnOqBnxKnHukjAihBBC1C4JI2fS+6DVOYf2Gotl5V4hhBCiLkgYOdMZQ3vNZc6vUjMihBBC1C4JI2cy+KI51YFVVu4VQggh6oSEkTOdMbTXLCv3CiGEEHVCwsiZzpyB9eTKvRJGhBBCiNolYeRMxgDXaBqz1YKiqhRYCtxcKCGEEOLqJqv2nskY6KoZca3cq81DVVUURXFz4YQQQoirk9SMnMngh0aroGhPLZYHVoeVUlupmwsmhBBCXL0kjJxJ6wFefq65Rsylzo+nwCpNNUIIIURtkTDyd8bAM9an0QPSiVUIIYSoTRJG/s4rwNVvxFgki+UJIYQQtU3CyN+dUTNiKtUCMvGZEEIIUZsuKoy88847xMTEYDAY6NixIxs2bDjv8dOnT6dx48Z4eXkRFRXFv/71L8rKyi6qwLXujBE15hIJI0IIIURtq3YYmT9/PhMmTODZZ59ly5YtJCYm0rdvXzIzM896/Lx585g0aRLPPvssKSkpfPzxx8yfP59///vfl1z4WmE83UxjLnUO55VmGiGEEKL2VDuMTJs2jXHjxjFmzBiaNWvGzJkzMRqNzJo166zH//7773Tt2pU777yTmJgYbrjhBu64444L1qa4zZkdWEudo2qkZkQIIYSoPdUKI1arlc2bN9O7d+/TF9Bo6N27N+vWrTvrOV26dGHz5s2u8HHgwAGWLVvGgAEDLqHYtejMZpqTK/dKzYgQQghRe6o1A2t2djZ2u53Q0NAK+0NDQ9m1a9dZz7nzzjvJzs7muuuuQ1VVbDYb999//3mbaSwWCxaLxfW6oKAO5/kwBrjmGZGVe4UQQojaV+ujaVatWsXLL7/Mu+++y5YtW1i4cCHff/89L7744jnPeeWVV/D19XVtUVFRtV3M086oGfG2lAMSRoQQQojaVK2akaCgILRaLRkZGRX2Z2RkEBYWdtZznn76ae6++27Gjh0LQIsWLSguLuaf//wnTz31FBpN5Tw0efJkJkyY4HpdUFBQd4HkjD4jZlm5VwghhKh11aoZ0el0tG3blqSkJNc+h8NBUlISnTt3Pus5JSUllQKHVuscMquq6lnP0ev1+Pj4VNjqzJl9Rk6u3Cs1I0IIIUTtqfaqvRMmTGDUqFG0a9eODh06MH36dIqLixkzZgwAI0eOJCIigldeeQWAgQMHMm3aNFq3bk3Hjh3Zt28fTz/9NAMHDnSFksuKwRetcxZ4NICxDPI1+ThUBxpF5ogTQgghalq1w8jw4cPJysrimWeeIT09nVatWrF8+XJXp9bDhw9XqAmZMmUKiqIwZcoUjh07RnBwMAMHDuSll16quaeoSRotitkfjYcDh02DuRSKvRwUlRfho6vDGhohhBDiGqGo52oruYwUFBTg6+tLfn5+3TTZvN2evbPysJV4MPluPfsj7SwbsowonzrsSCuEEEJc4ar6+1vaHc7GK+B0J9ZiHQD5Vuk3IoQQQtQGCSNnYwx0zTViKpGVe4UQQojaJGHkbM5cn6bE2a1GwogQQghROySMnM2Zc42UOD+i3NJcd5ZICCGEuGpJGDmbM2dhLXXWjKQVp7mzREIIIcRVS8LI2ZwRRkylCgDHi467s0RCCCHEVUvCyNmc2WekzNmR9XixhBEhhBCiNkgYOZsz+ox4l9kAqRkRQgghaouEkbM5Y2iv98nF8gqsBRRZi9xZKiGEEOKqJGHkbM5opvGxluCwGQFpqhFCCCFqg4SRs9H7ojU4/2kuL0Ox+AHSVCOEEELUBgkjZ6PRoPXzd730KvYGJIwIIYQQtUHCyDkopgA0nidH1BSaAAkjQgghRG2QMHIuZ841UuwFSJ8RIYQQojZIGDmXM+caKXYulic1I0IIIUTNkzByLhVmYXVOCS9hRAghhKh5EkbOxRiIVu+ca8Rc6vyYTlhOUFJe4s5SCSGEEFcdCSPnckbNiI/Fimp3jvWVBfOEEEKImiVh5FyMgWhO9RmxluAodw71laYaIYQQomZJGDkXY4BrfZogRxmOcj9AwogQQghR0ySMnMsZzTSBjjLUkzUjx4qPubNUQgghxFVHwsi5nDG017e81NVMk1YkfUaEEEKImiRh5FyMga5mGrOlyFUzIs00QgghRM2SMHIueh+0BufHYygrOt2BVWZhFUIIIWqUhJFzURS0fn4AeJSWgsW5WF52aTYWu8WNBRNCCCGuLhJGzkPre3rlXu8yBRx6QPqNCCGEEDVJwsh5KOag0yv3WktleK8QQghRCySMnM8ZI2r8yktwWKXfiBBCCFHTJIyczxkjaqI8ymUWViGEEKIWSBg5nzMmPovQWl3NNMeKZOIzIYQQoqZIGDkfYyAeBmcYibSdnmtEFssTQgghao6EkfMxBqLzsQEQkZ/uaqaRmhEhhBCi5kgYOR9jAHrfcgACso65akaySrIot5e7s2RCCCHEVUPCyPkYA9CfrBnxyjiKYvNCUT1RUUkvTndz4YQQQoirg4SR8zEG4mmyo2hUNFYroSUnwCbDe4UQQoiaJGHkfIyBKBpc/UbqF2RQbvEDZHivEEIIUVMkjJyPzgxanavfSFxxpnRiFUIIIWqYhJHzURQwBrr6jTQuy5bhvUIIIUQNkzByIV4B6HydYSSqMEMmPhNCCCFqmISRCzEGoPdxNtME56ahWv0AWblXCCGEqCkSRi7EFIzObEfx0OBZbiE4z/mRpZekU2Yrc3PhhBBCiCvfRYWRd955h5iYGAwGAx07dmTDhg3nPLZnz54oilJpu/HGGy+60HXKr75zRE2wCYCovCI8VDMO1cGB/ANuLpwQQghx5at2GJk/fz4TJkzg2WefZcuWLSQmJtK3b18yMzPPevzChQtJS0tzbX/++SdarZZhw4ZdcuHrREAsAHp/BYD6hRlobPUA2HNij9uKJYQQQlwtqh1Gpk2bxrhx4xgzZgzNmjVj5syZGI1GZs2addbjAwICCAsLc20rVqzAaDReOWHEPwYAnbkUgOiCDKwloYCEESGEEKImVCuMWK1WNm/eTO/evU9fQKOhd+/erFu3rkrX+Pjjj7n99tsxmUznPMZisVBQUFBhc5uTYUSvzwGcNSOlxSEA7D2x112lEkIIIa4a1Qoj2dnZ2O12QkNDK+wPDQ0lPf3Ca7Vs2LCBP//8k7Fjx573uFdeeQVfX1/XFhUVVZ1i1iyfSNB4oDc7O6tGF2XgKJOaESGEEKKm1Olomo8//pgWLVrQoUOH8x43efJk8vPzXduRI0fqqIRnofUA3yh03jbw0GKwWQnMM6CgkFuWS3ZptvvKJoQQQlwFqhVGgoKC0Gq1ZGRkVNifkZFBWFjYec8tLi7myy+/5N57773gffR6PT4+PhU2twqIRdGAPsw5+2p0QQ7+OmcnVmmqEUIIIS5NtcKITqejbdu2JCUlufY5HA6SkpLo3Lnzec9dsGABFouFu+666+JK6k6nOrEGGwHngnneirPpSJpqhBBCiEtT7WaaCRMm8OGHH/LJJ5+QkpLCAw88QHFxMWPGjAFg5MiRTJ48udJ5H3/8MYMHDyYwMPDSS13XTnVi9XMAUL8wE61dhvcKIYQQNcGjuicMHz6crKwsnnnmGdLT02nVqhXLly93dWo9fPgwGk3FjLN7925+++03fvrpp5opdV3zPznXiKkIcI6osZV2Ak9pphFCCCEuVbXDCMBDDz3EQw89dNb3Vq1aVWlf48aNUVX1Ym51eThVM+KZCeioX5hBfl4gBMP+vP3YHDY8NBf1UQohhBDXPFmbpipO9RnxyAaNBpOtDPuxcrw8vLA6rBwuOOze8gkhhBBXMAkjVWHwAWMgihZ0kc5RQ+H5GdQ3NwCk34gQQghxKSSMVNWpppp6AYBzRI2fR31AwogQQghxKSSMVNWpTqzBesDZiVVriwCkE6sQQghxKSSMVNWpfiM+NsAZRooKgwCpGRFCCCEuhYSRqjrVTOOVD0B0QTqZWb4AHC8+TqG10F0lE0IIIa5oEkaqKuBkM43mOBgMmG1l2PdnEGp0dmiVphohhBDi4kgYqaqTNSNK0VGMiS0BaJK1n0hTHCBhRAghhLhYEkaqyrseaHXgsGFMaAhAQk4qZlmjRgghhLgkEkaqSqMBv2gAjA2cHVcTcg6gWpzNNBJGhBBCiIsjYaQ6TjbVeIVpcWi1BJfmoxzWArA3b++VPeW9EEII4SYSRqrjZCdWTfFR7PFNADD9lYanxpPi8mKOFx93Z+mEEEKIK5KEkeo4WTPCiYN4t28HQNjBPcT4OEPKnlxpqhFCCCGqS8JIdZychZUTqQR26QA4+42EGZz7d2bvdFfJhBBCiCuWhJHqOKNmxNS2LQ4UIouyqF/qXDBv4d6FWOwW95VPCCGEuAJJGKkOf+doGsry0eoc5Ic5h/WGpXgSagwlpyyHZQeWubGAQgghxJVHwkh16ExgDnX+OzeV8maJAHj8uZO7m90NwJy/5uBQHe4qoRBCCHHFkTBSXWc01ZhPdmINSk1haMOhmD3NHMg/wG/HfnNf+YQQQogrjISR6nJ1Yj1I/V5dAIjKPYpaUM6tjW4F4JO/PnFX6YQQQogrjoSR6nLVjKQSHBNJhncQGlRSV69nRNMReCgebEjfwF85f7m1mEIIIcSVQsJIdZ3RTAOQXt85+dmJ9RsIM4XRN7YvILUjQgghRFVJGKmuk7OwknsQAGuzFgBodm4DYFSzUQD8dPAn0orS6rp0QgghxBVHwkh1BTjnFCH/CJTmYerQHgC/I/twlJXRNLApHcM7YlftfJ7yuRsLKoQQQlwZJIxUlzkYAuIAFY78QUyLxuTqvfGw2yjdsQOA0c1HA/D1nq/Jt+S7r6xCCCHEFUDCyMWI7ur8emgtjcK82RkUB0DOyp8B6FqvK438G1FiK2HOX3PcVEghhBDiyiBh5GKcCiMH1+Jt8GRHo44AFH35BeXHjqEoCuNbjQdgbspccsty3VVSIYQQ4rInYeRiRDvnFyFtG1iKKGnfhe1BDVCsVjJffx2A66Oup1lgM0ptpcz+c7b7yiqEEEJc5iSMXAy/+uATCQ4bHN1Ik3Bf3m8xCFVRKFj2AyVbtqAoCg+2ehCAL3d9SXZptpsLLYQQQlyeJIxcDEWBmFP9Rn7nuvggUn3rsapBZwAyXnoZ1eGgW0Q3Wga3pMxexkc7P3JjgYUQQojLl4SRi3WqqebQWtrH+mPUaXm/YR9Uo5Gyv/4if8lSFEXhoVYPAfDV7q9IL053Y4GFEEKIy5OEkYt1qhPr0U3o1XK6NAgkX+/N/r7DAciaNg1HcTGdwjvRNrQt5Y5yPtzxoRsLLIQQQlyeJIxcrMB4MIWA3QLHt9CjcQgA8yI64Vm/PrasLLI//LBC7cjCfQs5VnTMnaUWQgghLjsSRi6Wopxuqjm4lp6NggHYcLwI82MTAMidNRvLgVTahbWjU3gnbA4bM7bMcFeJhRBCiMuShJFLccbkZ1EBRuKCTdgdKlsiW2Dq1g3VaiXt3/9Gtdt5rO1jaBQNP6T+wK9Hf3VvuYUQQojLiISRS3GqZuTIBrCX07ORs6lm1Z4swl94Ho3ZTOm2beTO+YTmgc25q+ldALy4/kWKy4vdVWohhBDisiJh5FKENAODH5QXQ9oOejZ2NtWs3pOFR1gYoZOeBCBrxgwsBw7wYKsHiTBHkF6czvTN091XbiGEEOIyImHkUmg0Zwzx/Y0OsQEYPDVkFFjYlV6I79Chruaa45Mn46XR82znZwGYv3s+WzO3urHwQgghxOVBwsilcoWR3zF4aukcFwjAqt1ZKIpC+IsvoDGbKdu+g9zZs+lcrzOD4wejovLs789isVvcWHghhBDC/SSMXCpXJ9Z14LDT8+QQ31W7MwHwDAsjdPIkALLefAvLvn1MbDeRQEMgqfmpfLDjA7cUWwghhLhcSBi5VGEtQWcGSz5kJrv6jWw+dILCsnIAfG+5BVN3Z3PNsQmP42335N8d/w3ArJ2zWHd8nduKL4QQQrjbRYWRd955h5iYGAwGAx07dmTDhg3nPT4vL48HH3yQ8PBw9Ho9jRo1YtmyZRdV4MuO1gOiOjr/nbqG6EATsUEmbA6VtftyAE421/wHbVAQlj17SHvmWXrX782A2AHYVBuP/vIoO7J2uPEhhBBCCPepdhiZP38+EyZM4Nlnn2XLli0kJibSt29fMjMzz3q81WqlT58+HDx4kK+//prdu3fz4YcfEhERccmFv2zE93Z+3f4FqCo9Gp0aVXP6M/EMDSHyjWmg1VLw3XfkfT6XF7u+SKfwTpTaShmfNJ59J/a5o/RCCCGEW1U7jEybNo1x48YxZswYmjVrxsyZMzEajcyaNeusx8+aNYvc3FwWL15M165diYmJoUePHiQmJl5y4S8bibeDVg/pO+DYFnqcbKpZtTsLVVVdhxnbtyf0if8DIOPVV7Ft28mMXjNoGdSSfEs+9624T6aLF0IIcc2pVhixWq1s3ryZ3r17n76ARkPv3r1Zt+7s/R6WLl1K586defDBBwkNDSUhIYGXX34Zu91+zvtYLBYKCgoqbJc1YwAk3OL896ZZdI4LxMtTS1p+GZsOnahwqP/IkfgMGAA2G0cfewzPE0W88493aODbgMzSTP750z/JLs12w0MIIYQQ7lGtMJKdnY3dbic0NLTC/tDQUNLT0896zoEDB/j666+x2+0sW7aMp59+mtdff53//Oc/57zPK6+8gq+vr2uLioqqTjHdo909zq9/foPBVsDNifUA+GzdoQqHKYpC+H9eRN+wIfasbI499i98VD3v93mfCHMEhwsP8+jPj1JuL6/rJxBCCCHcotZH0zgcDkJCQvjggw9o27Ytw4cP56mnnmLmzJnnPGfy5Mnk5+e7tiNHjtR2MS9dZHsITQBbKWz/krs7RwPww59pZBdVnEtEYzQS+dabzunit2zh8D33ElTuDCTeOm92ZO/g9c2vu+MphBBCiDpXrTASFBSEVqslIyOjwv6MjAzCwsLOek54eDiNGjVCq9W69jVt2pT09HSsVutZz9Hr9fj4+FTYLnuKAu3GOP+9aRYJ9XxIjPKj3K7y1abKYUoXE0PU+zPR+PhQunUrB0fcRb1iHS9f9zIAc1Pm8uPBH+vyCYQQQgi3qFYY0el0tG3blqSkJNc+h8NBUlISnTt3Pus5Xbt2Zd++fTgcDte+PXv2EB4ejk6nu8hiX6ZaDnfOOZK9Bw6t5a6O9QGYu/4wdoda6XBj27ZEf/4ZHqGhWPfv5+Dtd9C5LIJ7EpxNPs/+/iwH8w/W5RMIIYQQda7azTQTJkzgww8/5JNPPiElJYUHHniA4uJixoxx1gqMHDmSyZMnu45/4IEHyM3N5dFHH2XPnj18//33vPzyyzz44IM19xSXC703tBjm/PemWQxMrIevlyfH8korDPM9k6FRI2K+/AJdgwbYMjI4OOIuxjq60ja0LcXlxUxYPYFSW2kdPoQQQghRt6odRoYPH87UqVN55plnaNWqFdu2bWP58uWuTq2HDx8mLS3NdXxUVBQ//vgjGzdupGXLljzyyCM8+uijTJo0qeae4nJyqiNr8lIMlhyGtY0E4PP1h895imd4ODFzP8erdWscBQUcG/tPXlJuIdAQyN4Te3lp/UvYHecefSSEEEJcyRT1zIkwLlMFBQX4+vqSn59/ZfQf+ag3HN0I/3iW1Kb30WvqKhQFfv2/XkQFGM95mqOsjGOP/YuiVavAw4PSJ+5lDLNxqA7CTeEMiR/CkIZDCDOdvX+OEEIIcTmp6u9vWZumNpyqHdk8m9gAA90aBqGqMG/DuWtHADQGA5FvvYnPwIFgs+H18vu8kX0DPjof0orTeHf7u/T9pi/jV45nW+a22n8OIYQQog5IGKkNzYeAVwDkHYZt8xjR0TnM96uNR7DYzt/conh6Uu9//8X/rrsACP/gO77JHs5/r3uFDmEdcKgO1hxbw9ifxkogEUIIcVWQMFIbPL2g2+POf//yMr3jvQnzMZBTbGX5n2efHO5MikZD6FP/JuihhwA48c57dFh+iI/7fsx3Q76ja72uWOwWHkx6kP15+2vzSYQQQohaJ2GktrQfC75RUHgcj00fcEcH5zDfN5P2YrU5LnCyc6bW4IceJGTSkwBkv/U2uZ9+SrRPNG/0eoOWwS0psBZw34r7SC++cMARQgghLlcSRmqLpwGun+L895o3GNPGl0CTjv1ZxXy67mCVLxM4ejRBDztrSDJefoW8hYvw8vDinevfIc43joySDO5bcR/5lvxaeAghhBCi9kkYqU0thjmniLfk47NxBk/2awLA9JV7ySwsq/JlgsaPJ2DUKADSpkyh4Kef8DP48X6f9wkxhnAg/wAPJj1Ick4yDvXCtS5CCCHE5USG9ta2vSth7lDQ6nA8uIkh846w/Wg+t7aNZOqwxCpfRlVV0qZMIf+bhSienkRMfwPvf/yDfSf2MXL5SAqthQAEeQXRtV5XukV2I8griPTidDJKMsgozqC4vJj7Wt5HlM8VsPCgEEKIK15Vf39LGKltqgqfDISDayDxDra2fYUh7/4OwMLxXWhT37/ql7LbOTbhcQp/dK5ZY+zQgeBHHuZQrIl3t7/LH2l/XHC21hZBLfis/2doNdrzHieEEEJcKgkjl5Njm+HD6wEF7v+N/1tjZ8Hmo7SM9GXx+K5oNEqVL+WwWsl8bSp5X36JWl4OgKlLZ4IeehiPxOZsydzCb0d/Y+3xtVjsFsJMYYQaQwkxhvDV7q8oKi/iyfZPclezu2rpYYUQQggnCSOXmwWj4a9FUL8LWbcu5PrXf6XQYuN/Q1swvH39al+u/Phxst//gLyFC+FkKDF27EjguHGYunZBUSoHnK92f8WL61/Ey8OLxYMWU89c71KfSgghhDgnCSOXmxOH4N3OUF4M/V/lI2sf/vN9CoEmHSsn9MDfdHErGFuPHiPn/ZnkLVoMNhsAhmbNCPznOPQNGlC6YwelO3ZSunMH5ceO8c3gEL6od5DrIq7j3X+8WyG0LE9dzid/fcLohNH0jelbE08thBDiGiZh5HK04UNYNhE8jZT/8zcGfHaUvZlF9GkWygd3tz1rbUZVlaelkTtnDie+WoBaep5+IyYjj4yxk+5t57/d/suNcTdSaivlfxv+xzd7vwFAr9Uzd8BcGgc0vujyCCGEELI2zeWo3b0Q0w3KS/D87hHeuK0lOq2GFckZfL7+0CVd2jM8nNDJk4n/OYmgBx9E6+eHYjRibN+ewLH3EjFjBl6JiVBcwgu/BKOoKv/b8D82pG3g9u9u55u936CgEO0TjcVuYeLqiZSUl9TQgwshhBDnJjUjdS03Fd7rerK55jVmlffhhe+S0XloWPpQV5qE1czzqaoKqoqiOZ03rYcOcWDwENTSUr6/KYRPWuS63gv2CuaVbq/QyL8Rt357K5klmQyMG8hL1710STU2Qgghrl1SM3K5CoiFPs87/73yWcY0g+ubhGC1OXh43lZKredfSK+qFEWpEEQAdNHRhD75BAADfjpBVJZzf7eIbnx989e0oT4sWs5rTSehVbR8e+BbFu9bXCPlEUIIIc5FakbcweFwzj1y6DeIvo6cW7+m35trySq0cGfH+rw8pEWt3VpVVY7cdx/Fv67BFl+fY9MeprstlhOzP6Hghx/AZsMjLIw/nuzH/zI/x6A18MWNXxDvH19rZRJCCHF1kg6sl7vcAyeba0qgy8OsjXuMuz7+A1WF90a0oX+L8Fq7dXlmJqkDb8aen49ndH3KDx12vafx9sZRWIjW359Px8WwRLuTWN9YZvSaQaxvbK2VSQghxNVHmmkudwFxMPBN579/f4uued9yf48GADzxzQ4O5RTX2q09Q0IIe97ZVFR+6DBotfgMGEDMggU0+OlHDM2bYz9xgrve3UOnTF9S81MZunQo72x7B4vdUmvlEkIIcW2SmhF3W/VfWPUKKFpsd3zF7UlGNh06QbNwHxaO74LBs/ambc/9fC62zEz8brsNXWSEa7+9qIij9z9AyaZNoNez+N5GzPNNAaC+d32e6vQUicGJZJVkkVWaVeFrZmkmWSVZnCg7QffI7jzS5hE8NB619gxCCCEuX9JMc6VQVVh0H+yYD3ofsm9bSt952eQUW7mjQxSv3NLSLcVylJVx9NFHKV79K2i15N/emynx28mwZlfrOj2jevJa99cweBhqqaRCCCEuVxJGriQ2C3w2BA6tBd/6/PGPBdz+xX5UFV4flsjQtpFuKZZqtZL29NPkL1kKgGezpvx4dyM+KPwBh+rA6GEk2BhMsJdzCzGGEGx0fi0uL+a/G/6LxW6hTUgb3rz+TXz1vm55DiGEEO4hYeRKU5ILH/WG3P0Q2Z63609n6s+HMHhqWPxgzc0/Ul2qqlLw/TLSX3wRR34+ik6Hz0P349WxAx45+ZSnp2NLz8BRVIjGZEbj443W2xuNtzf74rx4eOsUCssLifeL5/0+7xNiDHHLcwghhKh7EkauRDn7nav7luWhJt7JqNzR/Lo3m7ggE4vGd8XX6Om2opVnZJL29BSKf11T5XM0vr7wwgQeyJ9JVmkWYaYw7mhyB9dFXEdDv4YymZoQQlzlJIxcqfb/DJ8PBdVBca8X6f17c9Lyy2gR4ctn93bAz3hxC+rVBFVVyfv6a7LffAsVFc/QMDzCQvEMDUPj442jqBhHYSH2okKs+w9gTU0FjQb9g/fyaPjPHCw8PeV9iDGE6yKuY0j8EFqFtHLbMwkhhKg9EkauZOvfg+WTQNFweMCnDF5uILfYSvN6Pnx+b8eLXuG3LjmsVtJfeIH8r52L73n168P6UW34NWcDG9M3UmYvA0CjaHim0zMMbTTUncUVQghRCySMXMlUFZY8BNs+B4MvBwZ/y21fZ5JdZKVpuA9zx3Yk4AoIJKqqkvfll6S/9DLYbOgbNSL4kYfxvK4TW3J28PXer1lxaAUA4xPHc3/i/dJ0I4QQVxEJI1c6mwXm3ARHN0BQI/bf9DXDP99LdpGFJmHefD62I0FmvbtLWSUlmzdz9NHHsGc7hwVrAwPxvflmfG8ZwgeFP/Dhzg8BGNpwKFM6TZF5SYQQ4iohYeRqUJgBH/aCgmMQ2JCDA+Zy25dHyCy0EBdkYvaY9kQHmtxdyiopz8zkxKefkrd4iSuUAJiuu45N93Tk+X1v4VAd9IjswUvXvSTDgIUQ4iogYeRqkbXHOQdJwVHwrsfRm+Zy28ITHM8vI8Ck48OR7Wgb7e/uUlaZWl5O0ZrfyFv4DUWrVoPNhtbfn6wJt/Oo5VMsdgsmTxO3N76du5vdTaBXoLuLLIQQ4iJJGLma5B91jrDJ2gUGP3IHf87IFfDnsQL0Hhqm3daKG1vW3sJ6tcVyIJVjjz+OJcU51bx9+I0813Ifu4v2A2DQGhjaaCgdwzpyIP8A+/P2sy9vH4cLD2O1W1FRcf5PJcgriKENhzKs8TCCvILc+VhCCCFOkjBytSnJhXnDnX1IPLywDPmIBzeFsjIlE4BJ/ZtwX/e4K64DqMNqJfO1qZz47DMA9M2bc/yevrzjSOLP3L+qdpFTP8KKgofGg34x/RjRdAQJQQm1VGohhBBVIWHkamQtgQWjYO9PgIKjz4u8kN2LOeuc83fc2CKcl29pga+X+yZHu1iFP/9M2uR/Y8/PB8DQvDk5N3dmVshuMspzaODbgIZe9WlcYCI8y47H0UzsR47iOHQUx9Fj2HRafu3szZwmGZTqnYGsVXArRjcfTc+onmg11V9wMLs0m2/2fEOwMZjB8YPRKLLItRBCVIeEkauVvRy+nwBbPnW+bn03nwY8wgs/7MPmUInw82LG7a1oFxPg3nJehPKMDLLffof8pUtRLRYAPIKDMTRvjuXAAcqPHDldC3IOqtnEjl5RvN3wIPl6GwDRPtGMbDaSmxvcXKUF+44VHWP2n7NZvG8xFruzHK2CW/F8l+eJ84u7xKcUQohrh4SRq5mqOidG++kpUB0Q3ZU/r3ubBxcf4lBOCRoFHvlHQx7qFY+H9sr7a9524gR58+dzYu48bFlZFd7T+vujj49HFxuLLjoaXWwMuuhoypKTyX5vJtYDBwBQzCYOd4zm69DDbIwoxeahEGAI4LE2jzEoftBZazn25+3n450fsyx1GXbVDkArc2P2lhym2FGKp8aT+1rexz0J9+Cp9cTmsHGs6BiHCg4RagylcUDj2v9whBDiCiJh5FqwdwV8fQ9YCsA/hpKhnzNlrZ2FW48B0DE2gHdHtCHwCpmP5O9Uq5XCpCRs2TnoG8ajb9gQj8Bzj65R7XYKf/qJ7PdmYtmzx7XfbtCxs4GW1Q0srG+i0Dwskac6PkWzwGYA7M7dzfs73mfloZWgOohLg4GZEXQ86Il21wGUAD9W9g3hg6h9qBqF+t718dB4cLjwMDaHs/bFQ/FgxvUz6B7ZvXY/FCGEuIJIGLlWZO6CL4bDiYPgaYIh77HY0o4pi/+kyGIjws+Lj0e3c9uqv+6gOhwU/76OwpUrKPr5F2yZma73TngrLGurkNRGS/8Wt5JVmsWag7+QcEil0y6VLvs98SqynvW6lgYRzOhexKawYhRVJS4NOu/T0HY/5OnKeX+wFy/f8j7tw9pXOje3LJfi8mKivKNq7bmFEOJyI2HkWlKSCwtGQ+pq5+vrJrAv4VHu/Wwrh3JKMOm0vDG8FTc0D3NrMd1BdTgo++svCpOSyF+4yBVMSnXwS0sFgxXa71HxLjt9jsZkwtSlC6bu3TB17kzhipVkv/MOjqIi57ktG6A/loMmJ6/CvXK8YfrtJp4dOZsWwS0AKLeX82nyp8zaPBPVYmFM54e5t8W9tdoZttxezp68PTQLaHbFja4SQlxdJIxca+w2WPksrHvb+Tq+D3n932X8wgP8vj8HRYGJNzRmfM8G1+wvKNVqJX/ZMnJnza7QjAPOKeq9+/TGp29fjG3bougqrv1jy8kha8ab5H39NTgcAGiMRkzdu2O+rivZs2ZTfuAApTr44FYzjz88j9yyXGYkvUDTX1Lpt1lFXw4/tlHIGNaNZ/q9ho+u5n+WM0syeeTnR/gr5y9GNB3BpA6TavweQghRVRJGrlU7FsDSh8FWCv6xlN/6CS9u0vLpyeG/ber78WS/JnSMu3ZnNlVVleLf1pK/aBEaXx98+vbD2L4divbCw3/Ldu2iaPWvGJo2wdipE5qTocVeUMDhhx+i7I+NOBRYcL0On7xyrt+ucnJQj0uxHn7p6c/ASTNpEt4SgJLyEtKL08kuzabAWkC+JZ8CawHF5cX0iOzhqmk5n+S9v/PJJ48Tszufejkqn1+v5YGRb3J9/eur/yEJIUQNkDByLUvbDl/eBfmHwcMAN77O55Zu/Of7ZMrKnX/V92wczBN9m9CsnnyeNUW1Wjn8zBRKFn9bYb9nsyaE3PcAGqMXh//3Msq+gwDkeCts6xjAxggL20NLsWtP11h5l6g0O6wSl66yN8qDYaP/y4C4AZXu6bBayfnwQ45/txBd6vEK7xUZ4H/3+PLWPYsIN195M/QKIa58EkaudSW5sPCfsG+F83Xru8m87kVm/HqULzcewe5QURQY0jqCKTc2I8CkO//1RJWoqsrRd2dQ8N5HaFo1p/6Dj2Hs1MnVNKba7aQtnM/Raa/ifcLiOq/ME/bW96Ak0EjcISvBGWUVrvtjG4WQJ5/kzsRRrn3Ww4c58thjWJNTXPsyI83E9RlC+ZbtWLbvINMXvni8FW/f+pmshiyEqHO1GkbeeecdXnvtNdLT00lMTOStt96iQ4cOZz12zpw5jBkzpsI+vV5PWVnZWY8/GwkjF8nhgDWvwy8vASqEtYRBb5PqGc/Un3bz/Y40AILMOv4zOIF+CfLXc01R7fbzNvvYykrZPvctPDb+iW77HjiRX+kYfcOGeMZEU7RiJQAHQiFt0gju7fcUGcsWkzXlOTxKrRR4wefXa4jtP4xHrp+Ch8YD24kT7LvtVtQjx9kbDkdeGceDnSbU2vMKIcTZ1FoYmT9/PiNHjmTmzJl07NiR6dOns2DBAnbv3k1ISEil4+fMmcOjjz7K7t27T99UUQgNDa3xhxHnsP9n+GYslOQ4XzcbBD3/zdayUJ74egd7M52jRG5qGc7zNze/YucluVKpDgeWvXspXrcOe3Y2hsREjO3a4eHvXI258NdfOfD4Y+gKSynRwaHmgTTd6vxe7oqA+XdGcGfPR7i5wc0Vrms9eJA9w4aiLSxhQyOFBm/PpEvUdRVG8pTZytiSsYX1aetZn7YenVbHo20ePevwZCGEqK5aCyMdO3akffv2vP22c9SGw+EgKiqKhx9+mEmTKvfcnzNnDo899hh5eXnVe4IzSBipAfnHnKNtdn4NqIACLW/Dct0TzNhi4/1fD2B3qASadDzRrzFD20RekbO3Xq3K09PZPn4UpuTDrn1regQS8fgT9I0fcM4mmJLNmzkwaiRam4NtsQqFJgWTwxOTwxOdXSFPLabEU6VM52wqKjAqHA2Gpu37889+U/A1+FWrnA7Vwcb0jfyV8xfhpnBifWOp710fo6fxUh5fCHGFqpUwYrVaMRqNfP311wwePNi1f9SoUeTl5bFkyZJK58yZM4exY8cSERGBw+GgTZs2vPzyyzRv3vyc97FYLFgsp9vTCwoKiIqKkjBSEzKSYdXLkHKyk6VWB10fY2fcvUxctIfdGYUAxAaZeKx3Qwa2rIdGc20OBb7cqDYbm195Esvq39DeP5KOQ8dXaZh21tLFZD8xudr3s+gUlNj6eAWGUKqxU6xYKaSMUqMWfWIiUV170yi+IzqtjqySLJbsX8LCvQs5ln8YLwuUGEA9Wb4wUxi9onrxWJvHJJgIcQ2plTBy/PhxIiIi+P333+ncubNr/xNPPMHq1av5448/Kp2zbt069u7dS8uWLcnPz2fq1Kn8+uuv/PXXX0RGRp71Ps899xzPP/98pf0SRmrQ8a2Q9IKzCQfAPxZrv1f5JCOe91bvJ7fYOQtp41Bv/tWnEX2bh16z85NcDYrX/0HRlk2UaR2UaGwUaayUKjbCPYMIUL1QS0pxlJRgy0gn969tqKmH8bBf+Lrp/grHY70pKi8iKM9BUAEEFoBWBbtW4YS3QrbZQY63wu5IhdSuMbzQ5zXXVPxCiKvbZRNG/q68vJymTZtyxx138OKLL571GKkZqSOqCilL4YdJUHhyWGjzIRT3fJ7ZO628/+sBCsuck2QkRvoysW9jrosPklByDSizFPP5T6+xcf0ivCwQ4uFPsIcvgVofTLmleCUfJPBYMdVtyCvWw8+ttUTecx+3d3sQjaKh3FHOnhN72Jm1k2OFR7EdPIzpr4ME7c7CL6cMe99u9H1sGh5aGQ0kxJXmsmmmOZthw4bh4eHBF198UaXjpc9ILbMUwi+vwB8zQbU7m27a3UNBu0f4YEsRs9amUmJ1/pncKS6A/+vbhLbR/m4utKgL5fZytBrtWaevtxUUcGx9EpkbfsPXO5jQBi3wjKiHZ0QEWj8/7FlZlGdkYsvMwHr4CLnffI39kLPPi00D+xL8KTNoKSs6gYfVgb4corJU/Eoql+OvNgF0mDab+mGNXPvsDjurjqzi5yM/08i/EUMbDsWsM9fWRyGEuAi12oG1Q4cOvPXWW4CzA2v9+vV56KGHztqB9e/sdjvNmzdnwIABTJs2rUr3lDBSR9J2wI//hoNrnK89jdDhn2QnPsA7f+Qwd/1hrHbnpGm9Ggfzrz6NaBnp577yiiuK6nBQuGoVu999DfOfB895nEPnQVnj+qitmlJYXkzw/FVoVTgWpKH42Qfo0e0uFu1bxJe7vuR48emJ3syeZoY1GsaIpiMINVV9tJ4QovbU6tDeUaNG8f7779OhQwemT5/OV199xa5duwgNDWXkyJFERETwyiuvAPDCCy/QqVMn4uPjycvL47XXXmPx4sVs3ryZZs2q1m4sYaQOqapzwb2kF+HYJuc+vQ90vJ/jze5hxm9ZLNh8BMfJn5reTUN4rHcjEiJ83VdmccXZt/5H9n7/Jd5efoQFRhPoH4HGaMSzXjiGhATXNPsAh35bTsbjT+CdX06ZJyztrKVco2K0qPjZ9MTp6nFUzeGQZyEnzFDoraVhs+tomng9rUJbE+sbe8GFCVVV5Zcjv2DwMNAxrCNazYWXBqhp5Y5yPDWedX5fIWpTrU569vbbb7smPWvVqhVvvvkmHTt2BKBnz57ExMQwZ84cAP71r3+xcOFC0tPT8ff3p23btvznP/+hdevWNf4wogapKuxZDj//BzL+dO7T+0Ln8aTGj+SttZks3nbsjFASygM942gbHeC+MourljU7i63jR+Kz42CVz8kzwV/1FfbHeUGbBNq3v5mBDW7GU1vxF/6xomO8M/9xwlbsQFUgtak/Df4xmJsSbiXWN7ZK93I4HBw4vI3tyb+wf/9m7H5mht88iTjfuCqd/+3mzzn+6quUxYQwYOI7NAxufNbjVKuV8sxMrLk5WHOzKc/JAZuNwOv74BEcXKV7CVGXZDp4UTMcDmcn11X/hayT044bfKH13RyJuonXt+tZuiPNFUpa1/djXLc4+jYPQytDgkUNUu12Dn74NqVbt+IXEI7G7I3W24zi5YWjoBBbVha2zEyK0o/iOHIMbXnF4UAZfvBXMzMRNw3lhpseRu9hYNk3/6N09jxaHKh4bLkWUqIUMhLC0cTVRxMZgVdkffx9QtA6wLZnPx5/7sWYchjvfel45ZVWGn20uaEG24N3cWefx9Fpz77cgsVu4fWVz9HmP4uJznLuOxCmkDfxLoYPeMI1f0xGRiqb33qe0O82YCyr/J9su1bhROem1L/3fqI793Htd6gOskqyKLAWEOcb55YaH3FtkzAiapbDAcmLYfX/IGvX6f2BDcmJu5mP89ryUbLG1ackKsCLIa0j6RQbQOv6/njp5D+Cou44LBbKduygcP06cn7/FfXPXWjOCCf5Zg2lPnrCjpc6j9eAZ59emAJDyf1lBR5pOZWvCZzwBqMFvKxnv2+JyQM1wA+vY9loHM6Ouus6+9F28v9oG9+9wrFHC4/y1LJHuP2dFGIyweLrhWotx1Bqw6aBNf8IoeG4R8mY+ylNftyN6eQKGuVaKDA6t0IvBaNFJT7tjOtGeZHWKpJMCsiw51GsLafIAB7t2/C/3tMINkoNiqg7EkZE7XDYnc03O75yfrWdXmPIEt+fBcbhTP3TRF5JuWu/h0ahZaQvXRoEcc91sbIon6hzjtJS8n5dxa5FczCs34nXydoFqwfk92lHhwkvYYiqDzj7j1gPHiRj5TIyfl+FkpaJPv0EHmWnf6YtXh7kxAdT2CQCa7NYopt2JLFxDwxeztE8Zfv28dfzT2Dc6KxNLDTA2k4+7OsQjlq/Hv4Gfzbs+ZnHPs0jLh0c/j7Ez/0CjcnMtifHY17/l7PcCmhO/hc6K9SA457baH7rveg89HhoPNAqWvIt+az75XPKv1pCo81Z6M4xP8yBUPjoziCeGvQG7cLa1cbHLEQlEkZE7bMUwq7vYecC2JeEc5p5sMddz+rQUSw5Ec0fB3JJLzgdWAJNOl4YlMCNLWVRPuEe1rISfl36DpkH/qLrHROIjm55wXNUVcWel0f54cMoBi/0DeNRNBeeZSXj5x9J/c8z+B4vcO3bFwa/Nddw3V8O4tNB8fcj9rPP0MfHu+51bPF8Ml96Ga+icgrCvPF5YBxNbr3nvIsvAmQf389fn72N5kg6ZrsnJrsHOrtC6c6dUFBIvhHeuMWT/oMnMKr5qFqZM2hH1g789H7U96lf49cWVx4JI6JuZe2G395w1pioJ/80C4hDjWxHnn8im+1xTNuhIznTOZld/4Qwnh/UnBBvgxsLLUTtU202ji1dQP7Sb1E2bEdxOFzvafz8iP70EwyNGlU6z56XR+nu3ZjatbtgCLmQ8mPHOPTgg5Tv2o1NA7P7aMjp145mgc0IN4VTz1yPMFMYGkWDzWFzbTqtjkjvSAINgRcMLtml2fx3w3/58eCPaBQN/WP7c1/L+yp1AnaoDvbl7UOv1RPtE33BsjtUB/vz9rMtaxu7cnbhrfOmnrmeczPVI8I7Ar229hf3TM1PZVnqMm6Ku6lK5XYXVVUvq4kpJYwI98hNhbXTYds8sFdsWFc9TawLG8G4/V0pdnji6+XJQ73i6dYoiEYh3rIGjrjq2XJyKPhhOfnfLsWel0fkjBkYmjSpk3s7Sks5/u+nKPzhBwDnwolezmYg1+Y4uamgdUCxAdY3UUhpaiY8IJr6PvVJCEygY3hHGgc0RqNoUFWVxfsW89qm1yi0FqJBwaE6QFFcoeT2xrdzIP8A64+v54/0P8gtywUg3i+evjF96RvTl1jfWByqg2OFx9h1Yhe7cnfxZ/af7MjaQVF50Tmfy6A1cEPMDdza6FZaBbeq8V/E5fZyZv05iwW/vUenneVsbeXNpJteo1tkt4qfr+pgXso8Ptz5IY38G3Fzg5vpHd0bLw+vGi3P+Xx34Dve2PQGoxNGc3ezu+vsvucjYUS4V+kJOLoZjm50zldybLNzH2D1juJV9W4+ym4OOP/D4W/0pENsAJ3jAunfIpxQH6kxEaKmqapKzkcfkTXtDefw/Soq0cO6Jgq/JmjYFeVcANFX70uHsA7kWfLYmL4RY5nK3clB/OOPUtSSUgp8PTjqVUqut0KeyXkdrcO56fAg26yyNUZlfzioGoUo7yhyy3IpsRTR8Di03u8g7IQzGOlULX6e3nh7eHMiypfkBjq2hZRwuOw4xeXFrnI28G3ALQ1voUlAE7QaLVrFufnqfS+q2Wh71nae+/057Lv2MukrO/7FkO4Hz97twajuj3FPwj0oisLRwqM8vfZpNmVsqnC+0cPIDTE3cHODm2kT0qZWRzPtzt3Nnd/fidXh/CPwkdaPMK7luFq7X1VJGBGXF1WFvxbCT09DwTEAjgd04mOP2/g6PYR86+n2d40C3RsFc2vbSHo3DcXgKSNxhKhJpdu3U7JpM2g1zr4vGi2K9uRXDy1otShaLZZ9+8lfuhRb2unhOiVmT7bFwOZYO9tjFRwKDNqs4cYtCh4l5xhmdL6ymDzYEuNgdz1oeFyl1QEV79ILn6cxGjF26khe8yhW61JZ4thCur4MzlEzkhicyF1N7+If0f9wTS6nqirJucn8mPojWzK3oFE06DQ6PLWeqKrK78d/p9U+O/9a7MBwuv8yB0PguRFaejQZQNvQtkzbPI0SWwleHl483PphiqxFLNm/hGNFx1znBHsF0ye6D/1i+5EYnHjBifhOKbOVcajgEKn5qZTaSrkh5gZMnqYKxxRZi7j9+9s5VHCICHOE674PJD7AA4kPuLXZRsKIuDxZi2HNNPj9TVczjqrVURzQnH36ZqwsjGZWRjwlOGtGfAwe9EsIo2t8EJ0bBEofEyHqmOpwULJpE/lLl1K4/EccRRWbTOyeWtecLvqG8QTedz9erRKxZWRQnpaOLSMdW06uM+xotShaD9AoWPbspfj333EUFla6p8bHB/N112Fo2QJFp0PReqBoNajl5ZRs3kLx2rXYT5yodJ7N7EV6kJYivYqKigPn1zxPK+sbweZ4hUBzKLc1vg2rw8ry1OUcLjyMZ7lK2Ak4YYYiL1yBps8WB/f+5ECjgqlLF0ImPs7hf96HPTublCiF/wzXUO7pPLZNcGueUwahW7kO1W5HYzSSrRSxp+wImzhEUmMLZXrnsSHGEK6Pup7ukd3pEN6hQp+X9OJ01hxbw9pja9mdu5tjRcdQOf1rOsYnhmk9p9HQv6Hz+6OqPPHrEyw/uJwwUxgLblrAN3u/YfqW6QCMazGOh1s/jKIolNvLOZB/gNSCVKx2K6rq/HxOfe0R2YNAr8CL/Ek5Owkj4vKWewB+fgkO/AIlFed0cHgaSfHrycy8jnxX2AD1jLVh40PMdGkQyKBW9WhT3/+y6qglxNVOtVop2baN4jW/UbT2NyzJzqHL+qZNCXrgfrx7967SKCPX9crLKd2+naJf11D2118YmjXF3KMHXq1aoXice5Vm1eGgLCWF4t/WUrpjB9Z9+7AeOeKcD+k8irwU1jSD1S00KCq0OKiSeEih8VEVD5vzXIfRgDXMH5vZgHlHKgC+t9xC+PPPoXh6UrZrF4fuHomjsJDtjXXMGKRlSsn1NFm+G+u+fee8t8Ns5K/uUXzcJI3j+tOrQRq0BjqGdyTauz7b968l78h+AgpVAgqhxACHgxWKw3yI8W/A8eLjZJZkYtAaeKbzMwxsMJD5u+bznz/+g4fiwZyQiQQs/R2fvjewOO4EU7e8DkCHsA6csJwgNS8Vm2qrVDbF4Zyr5tlxc0kMTjzvZ1hdEkbElUFVncHk6CY4ugH2/+x8fZLFGM4Wn158V9yUb7KjKFNPz1GSEOHDqM4xDEysJ005QriBLSsLW04O+saN3f6HgaOsDOvBg1gPHMBRWsapqQZQVSypqRR8+x22zMxznq8xmXAUF1faH/zoIwTef3+F5yvZtInD945FtVhQDAbUsjLXNfxuvRXPqCgcJSU4iotxFBdTvHYt1lRnsFF0Okr6dGSfIZ+CQ/swZ5cSXKASVAC6yjnBeY6nJ7q4OJRGDfioWTpLNTsA6BfTj6TDSZTbrbyadT0xc34Gu7OWypCQwPY72vB00bwK1/L29KaBXwNMnibMeWUkrMug2e9pmPMt6BfOokHTzlX6vKtKwoi4Mqmqs9Prtnnw50Kw5J9+S6sjN6A1f9CS99MasN0WBSgEmHQMaR1Bu2h/EqP8CPc1uP0/jEKIy4tqt1P8+zryFy2iMCkJRafD2LEDps6dMXXugi42BrWsjPJjx7AeOUL50WMYmjTG2L79Wa9X+MsvHH3oYbDb8QgOJmDUSPyGD0fr7V353g4HhUlJ5Hz0EWXbd5y3nBp/PzzDw/EMDsGWdwLL3n2oJSVnHKDh2PXNeLb5LgqMoLWrTPk9jOa/OfuJGDt3omzHTlewKruuNXtuaESkbzT1TRH4e/riOHGC/MVLKPr1V1dtktbPj3qv/g9z9+6VynQpJIyIK195Kez+AfaugAOroPB4hbcL9OEst7VhUWkrNjoaY8NZrRtk1tMqypf+CeEMTKyHzqPq1cZCiKufWl4OGs0lz99SsnkztowMzL17V1hp+pz3VVVKN20i7+tvQFHwjIhwbvXq4RlRD4/Q0ErXUR0Oyo+nYdmzh/xvl1L4w3IAHCYvFnfR0Gqfg7jUUlAUQiY+TsA992DPySHrrbfJW7Dggk1Xxg4d8LvtNrz79Eajr/n5WiSMiKuLqkLOPmco2f8z7P8FbKe73Fs0XiRrGvOrpQGb7A3Z6oinCCNhPgbuuS6G2zvUx8cgy7MLIa5sJZs2kf7yy67+OgAas5mI16di7tGjwrFlu/eQNX06Zbt2oZwcIYWnB4qnDlOnTvgNG4Y+rmorU18sCSPi6mYtcQaT3d/D7uVQkl3hbQca1iqtebPsRjaqjfHWezKkTQSNQr2J9Pci0t+LCD+jLOAnhLjiqHY7+YsWkTl9BlofHyLfehN9gwbuLtZZSRgR1w6HHTJT4Mh6OLIBDq+HvEOut//SNmFGaX9WONpWGJkD0CDYRI9GIfRoHEzH2ADpCCuEuGKoJ5tgqjOCqa5JGBHXtux9sO4t2PYF2J3r4RR4BpOlCeSE3UhmuYFcuxe71PqsdrTkiBqK3kNDh9gAusYH0aVBIM3r+aKVKeqFEOKiSRgRAqAwA/6YCRs/rjAy5++OKOH8XJ7AGkdLdjjiyMQPb4MnHWMDaR/jT4sIX5pH+OLrJf1OhBCiqiSMCHEmSyGk7YCyPCjNg7J8Zz+TQ+uc85s4Kg7wz8GXv+z1+UuNYacjlq2OhqQRQHSgiRYRvrSK8qNNtD/N6/mg95CmHSGEOBsJI0JUVVkBpP4K+5Pg4FrI2Qtq5eFw6ao/Wx3xbHXEs80Rz59qLDatkeYRPsQHmzHpPTDqtJj0HvgYPLiheZgs+CeEuKZJGBHiYllLnB1i07c7a1OOb4H0P0G1VzjMjoY9jgi2OxqwX61HIUYKVSOFeHFC9eaARyyjusZzX48G0rwjhLgmSRgRoiZZSyBtm3N22KMb4dgW1+rD53JcDeBT2w0s093AyOtbc1enaBmtI4S4pkgYEaK2FaQ5a02ObYb8o87mHksBlBWg5h9GKXN2mC1VdSy0d+NbpQclXvWweQVh9jLg4+VBbJCJZvV8aF7Pl7ggEx7ay3eInhBCVJeEESHcqbwM/vwGdf17KBk7K7zlUBVy8SZL9eWIGsIBtR771XCOKhEoIY0JCg4jJshETKCRmCAT9QOMBJp0st6OEOKKI2FEiMuBqsKhtTjWz8Rx+A+0pTkof+t78nfH1ECSHTEkq9H85YjmqBpMiYcfRr8QQgN8iQky0aNRMF0aBMm6O0KIy5qEESEuRw47lORCcSYUpkHOAcjZi5q9F3vWHjwKz98PpUg1kKH6s97RjD+0bdA16kXPFrEkRvrhbfDApPfAU5p6hBCXCQkjQlyJygog40/nKJ70HZC+E7UoA0pyUP42FwqAVdWywdGEP9VY8lUzeZgo1vhg8fSlXOeLTe+HQ++HVm8iNtjMwMR6tKnvJ00+Qog6IWFEiKuJqjo7x5bkQPZe1L0rsO76EX3h4SqdblE92KNGMt/ei00+fbihdTw3t6pHbJBZprwXQtQaCSNCXO1UFXL2OydryzuMoyQXW3EuanEOlJ5AU5aH1pqPxlFe4bRiVc8Se1e+sF/PMYIw6XX4GHV4G/QYTWb8vU0EeesIMukJ9tbTur4f0YEmNz2kEOJKJmFECOEMLNZi59T3u5fj2Pgxmpw95zzcoSpk4UuaGkCaGshxNYjNjoYcDexC52Yx9G4aSpv6/lKbIoSoEgkjQojKVBUO/Q6bZqGmfItyckXjC7GqWtY7mrHC0ZatmubovLzRG4wYjV4YvUxEhgSQGOVHy0g/wn0N0idFCAFIGBFCVIXD4VyH59RmKXDOLJt/DAqOQ+5+7Ht+QnviwHkvk6uaSXZEk6zGcFQXB6HN0AbGEuAfRKivgTAfA0FmPX5GT3y9PDHqtBJYhLgGSBgRQtSc7L2wexnqrmWo6X+CoxxNFWpVClQjx9QgjqmBHFWDOaKGcFgNIU0JocgYSWy9UBKj/GgV5UdipB/+Jl0dPIwQoq5IGBFC1C5VBYcNykshZx+k78R2fCelR7ehy92Dvjz/gpc4rgawzxHBXjWSvWoEOV5xlPo3IiAgiAh/LyL8vPA36vDx8sDb4ImPwYNAs14WHhTiCiFhRAjhXpYi55o9+Uch/zCcOISadwhHbirKiUNoyk6c89SjahC7HFHsUaPIU02UYKBU1VOCnnxMFOtD0AXWp15QANGBJhqGmGka7k1MoKzvI8TlRMKIEOLyVnoCsvZA1i7I2k15ejJqZgq6kvQqXyJXNZOmBrJHjeQvRwx7NLFYghKoFxZOPT8D4b5ehPs6v9YPNGLWe9TiAwkh/k7CiBDiylSSC5nJkJEM2XvAUgjlxc7mIGsJjuJs1IJjaMuLz3mJNDWADNWPrFMbfhxRg8kxRKMExhMUEkaUvxGT3gOjTouXTotR50E9PwPxIWb0Hto6fGAhrl4SRoQQVy9VhbJ8ZxNQ3mHI+As1bTu249vxLLjwrLQnVDOH1NCTocWfTNWfDNWfVDWM3UoMEcEBNA33oWGIGV+jDrNei0nngVnvQaS/kagALxkNJEQVSBgRQlybSvOcM9MWZUBROhRmQGEatpxUHNn70BUfP+/pdlVhnxrBn2osyY76FGKkTNVhQUcZOtLUAIq8G9CpQTCd4gJpHxuAWe+Bigon/2tq1HtIk5AQSBgRQoizs5ZA7gE4kQqF6Se3NCg4jpqZglJ04T4rJ1QzGx2N+cPRhK2OhtjRYFQsmCnFRBll6MgyxWMIbkBciA9xwSbCfZ1zrQSa9QSadXjrPaR2RVz1JIwIIcTFKEiDtG1wfBtk73aGF1uZcysvQc3Zj1JeUqVLFakGUtT6pDiiSVMDycWbE6qZXNWbPI0fJYZwTCbTycngdET6e9EgxEyDYBPxwWaCvfUSWMQVrVbDyDvvvMNrr71Geno6iYmJvPXWW3To0OGC53355ZfccccdDBo0iMWLF1f5fhJGhBCXDXs5pG2Hg785p9ZP2w5aT9CZQGcGnQlbaR6arBQ0dusFL5eu+nNUDeaoGsQhNZSDjjBS1XBS1TBUgx/N6/mSEOFDQoQvzev5EhtkkrWBxBWj1sLI/PnzGTlyJDNnzqRjx45Mnz6dBQsWsHv3bkJCQs553sGDB7nuuuuIi4sjICBAwogQ4upmt0HOXkjfCRl/QXEWlORASQ6O4hwoSkdzgRqWHNWbFEd9ktWYk1+jOaqpR7CfD1EBRqICjIT7GFCBcrsDq82B1e7ArPcgKsBIdICR6EATId56NBJghBvUWhjp2LEj7du35+233wbA4XAQFRXFww8/zKRJk856jt1up3v37txzzz2sWbOGvLw8CSNCiGubqjrnWsk75BwRdOKgsy9Lzn7nVnjujrbZqg9pagDpaiBZqi8KKjrFho5yPLFThBcHHOHsV8M5oNYjTRuOv4+ZYLOeEG8Dwd56ogK8SKjnS/MIX5nRVtSaqv7+rlZ3b6vVyubNm5k8ebJrn0ajoXfv3qxbt+6c573wwguEhIRw7733smbNmgvex2KxYLGcXveioKCgOsUUQojLn6KAMcC51Wtd+X1rsXOelfQ/nbUr6TtRM/5EsRQQpDi3Fhw89/XPmCrFriocKgplb2Eke49HsNcRwRI1kmlqOGXoiQk0khDhbAKq5+ecKC7Cz4sAkw4VcKjOkUIqEGjSySy3osZVK4xkZ2djt9sJDQ2tsD80NJRdu3ad9ZzffvuNjz/+mG3btlX5Pq+88grPP/98dYomhBBXF53JGVLOCCrKqdoU18rKR6E4GzRa0OpObp7OieNy9kH2XtScvWgthcQp6cSRTl82ua7nQOGII5i9BRHsy4/gmBrEbtWfdDWAdDWAPMzO+6KinBy3rNV50SY6gPYxAbSL8ad1lD9eOpkkTlyaWh0IX1hYyN13382HH35IUFBQlc+bPHkyEyZMcL0uKCggKiqqNooohBBXjjNrU8JaVO0UVXXOuZK1++TU+7sgcxdkpaApPUG0JpNoMunN1ipd75gayLqDzVm7vzlzHc3JIABvvQcBZh3+Rh2BJh1xwSbaRvvTJtqfEG/DpTyxuEZUK4wEBQWh1WrJyMiosD8jI4OwsLBKx+/fv5+DBw8ycOBA1z6Hw+G8sYcHu3fvpkGDBpXO0+v16PX66hRNCCHE2SgKeIc5t7gep/erqrNWJWuXcwhz1h5njUthmnN4c1E6qI5Kl4tQcrhV+yu3an8FnIsaFqgmSgt1lBboKEVP6r5wvlibwL8cjQkOCKBFpC+eGgW7CnaHA7tDxUOrwVvvgenkBHE+Xp60ivIjMdJXmoGuQdUKIzqdjrZt25KUlMTgwYMBZ7hISkrioYceqnR8kyZN2LlzZ4V9U6ZMobCwkBkzZkhthxBCuIuigDnYucV2q/y+w+5cF0jROI9FAYcNjm+BA6shdTXq8W1EKtmgZFc6/Z98j1XVsqWoERuSG2NVPdHiQKvY0eLAjgaLqqMMT3LQcVg1ME+NI1Nfn85xQXRrGER8iDclVhuFZTYKLTZKLDZ8vDwJ8dYT6mMgxFtPgPRhuSpUu5lmwoQJjBo1inbt2tGhQwemT59OcXExY8aMAWDkyJFERETwyiuvYDAYSEhIqHC+n58fQKX9QgghLiMaLXj5Vd7f4HrnBiilJ5xNPuUlzoUMy0vBWgTHNsOBVejyj9BJSaGTJqXKt01TA1i7N4HfdiXwlVoPH6UYH0rwVYoxU8pezKSpAaSpgRxXAylDj85Dg+nkYodGnZa4YBNt6jubiVpE+GLwlD4tl7tqh5Hhw4eTlZXFM888Q3p6Oq1atWL58uWuTq2HDx9Go5GUKoQQVz0vf4juXHl/uzHOZqDcA3BglXNiOACNhzPkKFpQ7SdntS0DWykU56Ae20S4PbdCM9CFnFDNHFGDOVoezBFrMEfUEDKz/fgx2Ze5+JKv+BIeHMT/t3evMXGUbxvArz3vwrK7HMouFCj08AZ7DBaLtP7jh5JYbTzHxAYNHqKp0giaqI1N9YNBSExM1NdoNLEmf6vEJm3VRl/TQK2SUE5CFdvSNqCllOVYYBcoW5j7/TDt1rWt0kJ3usv1SybbzjyBu1cauDMzz/MkxVnhijGph80Mm9kAo14Ho0EPk0GHGLMRy1Id+B93HBeV0wCXgycioptDYAzoPKQ+Bmr/EfD3qndnrE7A6lJnGI0PXphJ1KXehZmGc2LCMGIxLLEYRiyGxI5BcaAHLvRKPPrEhW5JwEmZD505FivTXMjJcGHhPDvsFgPsFhNiLQbEWU1IjDXDaTNxEblp4t40REQUvUSAiRFgqFNdNG7o1KUF5Pw9gL8XMto37X2EAEARHf6UZByVBTiqZKBDUtAnLvTChT5xwg8bAB2Meh0SYs1IslvgdliQFh+DtHhb8DPGbIDJoIfRoIPJoEec1YgY89zcxZnNCBERUWBUXYp/fAg4N6R+jp9VZxL5vZd2bh7uVJuYfzAOM/xixbhYMAYrxmHBsMTizIV3WLqhvsfSJy4MShzOIg4K1NcWUp1WLEq2Y0lyHBYn27E01YFbUuJgMUb3+yw3ZAVWIiKiiGKOVY/4aYwd7b+wl1CruvLtcKfaqPh7gIAfNgRg0wWAaT6hUUSHs7CjT1w4PZaE0x3zcLp9Hn6SefivuNGpT0WmJxEr01xYmBSLiUkFvnOT8E+ch//cJBLtFqxMc6qr4ybGRvWjId4ZISIi+jcTfvUOS2BUnT108XNs4NJquBffZRntU+++/AtFdDiDRLQrKTgtSTBAYNJNwoRJmDCFAXGgTdJwXNLRZcpESkoaPE51SnOyw4J5F6Y4pzjVJfxvxllDvDNCREQ0Wyx29ZiuqUn1ZdvRPnUhueB7LeqmiDJwEvpzw0hDP9IMl6/TciX93Q50nUlSHwlJAn6XJByQePTDgQFxYNKaCJszGUnOGLVhibMi2WFBqtOGJW470uJjrjpTaHJKgV6n0+zuC5sRIiKi2WYwAvZk9XAvu+yy7uIKuAMngP4T6uMgg/HSHkN6AzByBug9Cuk9At3ZP4IbJK5C+5W/pwBTZ3Xwnk3AaZkXPJoUD45IJroM85E5z4mF82IRmFQwOBrA4GgAA6MBDI+fx/+V/gfZHm2ePrAZISIiCre/roC7YO0/DwXUx0IDJ9VHQcOnLzwWOn1h1lC/OnNobAAGnWA+BjBfN4A8hG5gOyEmHBtIR1tfOiahh00XUN+DwQSs5gDGzvwv4Lntxv2b/wGbESIiopudORZIWaUef3NhsX51Cf/R/kvTnM/+oX72HYf0tMIS8GOVrh2r9Fe+szKVePleROHCZoSIiCga6A1AnFs90kPvcOgUBTjboc4U6j2m7jlksl04YgCTDYakxRoVzmaEiIgo+un1QOIi9Vh6v9bVXIabyBAREZGm2IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkabYjBAREZGmImLXXhEBAIyMjGhcCREREU3Xxd/bF3+PX01ENCM+nw8AkJ6ernElREREdK18Ph+cTudVr+vk39qVm4CiKDhz5gzi4uKg0+lm7euOjIwgPT0dnZ2dcDgcs/Z16XLMOnyYdXgx7/Bh1uEzW1mLCHw+H1JTU6HXX/3NkIi4M6LX65GWlnbDvr7D4eB/7DBh1uHDrMOLeYcPsw6f2cj6n+6IXMQXWImIiEhTbEaIiIhIU3O6GbFYLHjjjTdgsVi0LiXqMevwYdbhxbzDh1mHT7izjogXWImIiCh6zek7I0RERKQ9NiNERESkKTYjREREpCk2I0RERKSpOd2MfPDBB8jMzITVakVeXh7q6+u1LinilZeX47bbbkNcXBySk5PxwAMPoK2tLWTMuXPnUFxcjMTERNjtdjz88MPo6enRqOLoUFFRAZ1Oh9LS0uA55jy7urq68NhjjyExMRE2mw0rVqxAY2Nj8LqI4PXXX0dKSgpsNhsKCgpw4sQJDSuOTFNTU9i+fTuysrJgs9mwaNEivPnmmyF7mzDr6/PTTz/h3nvvRWpqKnQ6Hfbu3RtyfTq5Dg4OorCwEA6HAy6XC08//TT8fv/Mi5M5qrKyUsxms3z66afy+++/yzPPPCMul0t6enq0Li2i3XXXXbJjxw5pbW2VlpYWueeeeyQjI0P8fn9wzObNmyU9PV2qqqqksbFRbr/9dlm7dq2GVUe2+vp6yczMlJUrV0pJSUnwPHOePYODg7JgwQJ54oknpK6uTtrb2+WHH36QkydPBsdUVFSI0+mUvXv3yuHDh+W+++6TrKwsGR8f17DyyFNWViaJiYmyb98+6ejokF27dondbpd33303OIZZX5/vvvtOtm3bJrt37xYAsmfPnpDr08l1w4YNsmrVKjl06JD8/PPPsnjxYtm0adOMa5uzzciaNWukuLg4+PepqSlJTU2V8vJyDauKPr29vQJADh48KCIiQ0NDYjKZZNeuXcExR48eFQBSW1urVZkRy+fzyZIlS2T//v1y5513BpsR5jy7Xn31Vbnjjjuuel1RFPF4PPL2228Hzw0NDYnFYpEvv/wyHCVGjY0bN8pTTz0Vcu6hhx6SwsJCEWHWs+Xvzch0cj1y5IgAkIaGhuCY77//XnQ6nXR1dc2onjn5mCYQCKCpqQkFBQXBc3q9HgUFBaitrdWwsugzPDwMAEhISAAANDU14fz58yHZZ2dnIyMjg9lfh+LiYmzcuDEkT4A5z7ZvvvkGubm5eOSRR5CcnIycnBx88sknwesdHR3wer0heTudTuTl5THva7R27VpUVVXh+PHjAIDDhw+jpqYGd999NwBmfaNMJ9fa2lq4XC7k5uYGxxQUFECv16Ourm5G3z8iNsqbbf39/ZiamoLb7Q4573a7cezYMY2qij6KoqC0tBTr1q3D8uXLAQBerxdmsxkulytkrNvthtfr1aDKyFVZWYlffvkFDQ0Nl11jzrOrvb0dH374IV566SW89tpraGhowAsvvACz2YyioqJgplf6mcK8r83WrVsxMjKC7OxsGAwGTE1NoaysDIWFhQDArG+Q6eTq9XqRnJwcct1oNCIhIWHG2c/JZoTCo7i4GK2traipqdG6lKjT2dmJkpIS7N+/H1arVetyop6iKMjNzcVbb70FAMjJyUFrays++ugjFBUVaVxddPnqq6+wc+dOfPHFF1i2bBlaWlpQWlqK1NRUZh3F5uRjmqSkJBgMhstmFvT09MDj8WhUVXTZsmUL9u3bhwMHDiAtLS143uPxIBAIYGhoKGQ8s782TU1N6O3txa233gqj0Qij0YiDBw/ivffeg9FohNvtZs6zKCUlBUuXLg05d8stt+DUqVMAEMyUP1Nm7uWXX8bWrVvx6KOPYsWKFXj88cfx4osvory8HACzvlGmk6vH40Fvb2/I9cnJSQwODs44+znZjJjNZqxevRpVVVXBc4qioKqqCvn5+RpWFvlEBFu2bMGePXtQXV2NrKyskOurV6+GyWQKyb6trQ2nTp1i9tdg/fr1+O2339DS0hI8cnNzUVhYGPwzc54969atu2yK+vHjx7FgwQIAQFZWFjweT0jeIyMjqKurY97XaGxsDHp96K8mg8EARVEAMOsbZTq55ufnY2hoCE1NTcEx1dXVUBQFeXl5MytgRq+/RrDKykqxWCzy2WefyZEjR+TZZ58Vl8slXq9X69Ii2nPPPSdOp1N+/PFH6e7uDh5jY2PBMZs3b5aMjAyprq6WxsZGyc/Pl/z8fA2rjg5/nU0jwpxnU319vRiNRikrK5MTJ07Izp07JSYmRj7//PPgmIqKCnG5XPL111/Lr7/+Kvfffz+nm16HoqIimT9/fnBq7+7duyUpKUleeeWV4BhmfX18Pp80NzdLc3OzAJB33nlHmpub5c8//xSR6eW6YcMGycnJkbq6OqmpqZElS5Zwau9Mvf/++5KRkSFms1nWrFkjhw4d0rqkiAfgiseOHTuCY8bHx+X555+X+Ph4iYmJkQcffFC6u7u1KzpK/L0ZYc6z69tvv5Xly5eLxWKR7Oxs+fjjj0OuK4oi27dvF7fbLRaLRdavXy9tbW0aVRu5RkZGpKSkRDIyMsRqtcrChQtl27ZtMjExERzDrK/PgQMHrvjzuaioSESml+vAwIBs2rRJ7Ha7OBwOefLJJ8Xn8824Np3IX5a1IyIiIgqzOfnOCBEREd082IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkabYjBAREZGm2IwQERGRptiMEBERkab+H0A9UKb9dYVlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train w/o EarlyStop\")\n",
    "plt.plot(history_es.history[\"loss\"], label=\"train w/ EarlyStop\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"valid w/o EarlyStop\")\n",
    "plt.plot(history_es.history[\"val_loss\"], label=\"valid w/ EarlyStop\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c674524",
   "metadata": {},
   "source": [
    "Stage2 의 데이터에 대해서는 early stop을 사용하였을 때, r2-score 가 더 높은 것을 확인할 수 있습니다.\n",
    "\n",
    "다만, 이번에도 로그를 확인해보면 두 경우 모두 100 epoch 전부 학습이 완료되었기 때문에 Early stop이 큰 영향을 미쳤다고 보기는 어렵습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed4aba",
   "metadata": {},
   "source": [
    "## 3. 가중치 규제\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 가중치 규제를 모델에 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b5eb9",
   "metadata": {},
   "source": [
    "### 3.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c4a7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L1 regularizer을 적용해봅니다.\n",
    "MLP_model_reg = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(\n",
    "            128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f95dd",
   "metadata": {},
   "source": [
    "### 3.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53707be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f198bc",
   "metadata": {},
   "source": [
    "### 3.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c40e11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1507 - val_loss: 1.0349 - 596ms/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0744 - val_loss: 0.9810 - 170ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0332 - val_loss: 0.9454 - 176ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0035 - val_loss: 0.9184 - 171ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9804 - val_loss: 0.8975 - 181ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9617 - val_loss: 0.8800 - 174ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9463 - val_loss: 0.8665 - 221ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9335 - val_loss: 0.8546 - 218ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9221 - val_loss: 0.8442 - 256ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9117 - val_loss: 0.8359 - 246ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9025 - val_loss: 0.8293 - 255ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.8938 - val_loss: 0.8221 - 200ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8860 - val_loss: 0.8147 - 178ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8781 - val_loss: 0.8081 - 166ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8709 - val_loss: 0.8033 - 159ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8636 - val_loss: 0.7962 - 154ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8568 - val_loss: 0.7910 - 173ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8501 - val_loss: 0.7852 - 173ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8433 - val_loss: 0.7799 - 164ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8368 - val_loss: 0.7752 - 173ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8309 - val_loss: 0.7710 - 227ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8241 - val_loss: 0.7660 - 267ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8187 - val_loss: 0.7620 - 263ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8126 - val_loss: 0.7595 - 222ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8068 - val_loss: 0.7544 - 189ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8015 - val_loss: 0.7515 - 234ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.7956 - val_loss: 0.7466 - 202ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7898 - val_loss: 0.7443 - 158ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7838 - val_loss: 0.7408 - 167ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7780 - val_loss: 0.7376 - 169ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7730 - val_loss: 0.7332 - 168ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7671 - val_loss: 0.7300 - 159ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7612 - val_loss: 0.7282 - 173ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7557 - val_loss: 0.7265 - 169ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7501 - val_loss: 0.7220 - 171ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7442 - val_loss: 0.7210 - 174ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7390 - val_loss: 0.7169 - 199ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7333 - val_loss: 0.7144 - 220ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7281 - val_loss: 0.7128 - 219ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7226 - val_loss: 0.7114 - 199ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7169 - val_loss: 0.7083 - 249ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7112 - val_loss: 0.7064 - 233ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7052 - val_loss: 0.7061 - 239ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7012 - val_loss: 0.7045 - 238ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.6954 - val_loss: 0.7024 - 235ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6908 - val_loss: 0.6994 - 224ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6837 - val_loss: 0.6992 - 233ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6793 - val_loss: 0.6990 - 221ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6735 - val_loss: 0.6940 - 223ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6667 - val_loss: 0.6940 - 215ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6623 - val_loss: 0.6921 - 227ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6566 - val_loss: 0.6908 - 238ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6489 - val_loss: 0.6947 - 238ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6447 - val_loss: 0.6873 - 262ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6373 - val_loss: 0.6955 - 234ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6824 - 218ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6264 - val_loss: 0.6835 - 179ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6179 - val_loss: 0.7058 - 257ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6849 - 297ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6065 - val_loss: 0.6803 - 241ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5997 - val_loss: 0.6778 - 229ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5953 - val_loss: 0.6779 - 249ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5846 - val_loss: 0.6756 - 238ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5794 - val_loss: 0.6761 - 245ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5773 - val_loss: 0.6747 - 228ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5649 - val_loss: 0.6711 - 232ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5615 - val_loss: 0.6712 - 241ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5507 - val_loss: 0.6682 - 244ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5469 - val_loss: 0.6835 - 254ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5426 - val_loss: 0.6781 - 228ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5331 - val_loss: 0.6650 - 217ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5207 - val_loss: 0.6628 - 226ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5208 - val_loss: 0.6608 - 216ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5140 - val_loss: 0.6577 - 232ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5053 - val_loss: 0.6560 - 222ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.4951 - val_loss: 0.6518 - 233ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.4899 - val_loss: 0.6540 - 215ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.4842 - val_loss: 0.6492 - 228ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.4802 - val_loss: 0.6471 - 244ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4698 - val_loss: 0.6463 - 240ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4631 - val_loss: 0.6449 - 221ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4602 - val_loss: 0.6467 - 252ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4511 - val_loss: 0.6469 - 235ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4501 - val_loss: 0.6387 - 240ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4442 - val_loss: 0.6517 - 239ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4396 - val_loss: 0.6345 - 208ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4279 - val_loss: 0.6387 - 210ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4237 - val_loss: 0.6357 - 223ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.6284 - 227ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4154 - val_loss: 0.6281 - 240ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.6486 - 226ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4052 - val_loss: 0.6222 - 234ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3979 - val_loss: 0.6224 - 245ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3995 - val_loss: 0.6162 - 217ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3877 - val_loss: 0.6151 - 239ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3863 - val_loss: 0.6377 - 258ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.6254 - 273ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3773 - val_loss: 0.6236 - 219ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3755 - val_loss: 0.6526 - 258ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3725 - val_loss: 0.6185 - 262ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = MLP_model.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d80dfc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.3714 - val_loss: 1.2456 - 857ms/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.2840 - val_loss: 1.1974 - 235ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.2425 - val_loss: 1.1618 - 219ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.2095 - val_loss: 1.1317 - 297ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 1.1813 - val_loss: 1.1056 - 240ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 1.1576 - val_loss: 1.0843 - 260ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 1.1388 - val_loss: 1.0677 - 239ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 1.1243 - val_loss: 1.0544 - 253ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 1.1125 - val_loss: 1.0432 - 251ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 1.1023 - val_loss: 1.0342 - 239ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 1.0931 - val_loss: 1.0274 - 229ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 1.0848 - val_loss: 1.0198 - 226ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 1.0767 - val_loss: 1.0127 - 236ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 1.0688 - val_loss: 1.0054 - 255ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 1.0611 - val_loss: 1.0004 - 235ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 1.0539 - val_loss: 0.9933 - 229ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 1.0468 - val_loss: 0.9883 - 223ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 1.0399 - val_loss: 0.9822 - 233ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 1.0335 - val_loss: 0.9770 - 253ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 1.0267 - val_loss: 0.9724 - 235ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 1.0208 - val_loss: 0.9678 - 261ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 1.0142 - val_loss: 0.9629 - 232ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 1.0080 - val_loss: 0.9584 - 292ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 1.0019 - val_loss: 0.9558 - 248ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.9958 - val_loss: 0.9510 - 247ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.9897 - val_loss: 0.9467 - 256ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.9842 - val_loss: 0.9425 - 259ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.9776 - val_loss: 0.9393 - 260ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.9725 - val_loss: 0.9356 - 263ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.9660 - val_loss: 0.9323 - 251ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.9613 - val_loss: 0.9297 - 263ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.9551 - val_loss: 0.9259 - 239ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.9501 - val_loss: 0.9247 - 247ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.9440 - val_loss: 0.9244 - 256ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.9387 - val_loss: 0.9190 - 244ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.9332 - val_loss: 0.9165 - 234ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.9286 - val_loss: 0.9144 - 233ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.9228 - val_loss: 0.9105 - 239ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.9178 - val_loss: 0.9112 - 238ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.9137 - val_loss: 0.9081 - 251ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.9076 - val_loss: 0.9051 - 254ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.9033 - val_loss: 0.9052 - 235ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.8974 - val_loss: 0.9025 - 242ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.8944 - val_loss: 0.9023 - 229ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.8893 - val_loss: 0.9001 - 237ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.8842 - val_loss: 0.8970 - 236ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.8792 - val_loss: 0.8964 - 236ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.8756 - val_loss: 0.8984 - 247ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.8712 - val_loss: 0.8932 - 250ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.8644 - val_loss: 0.8915 - 247ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.8609 - val_loss: 0.8913 - 252ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.8574 - val_loss: 0.8910 - 248ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.8497 - val_loss: 0.8972 - 263ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.8466 - val_loss: 0.8883 - 243ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.8402 - val_loss: 0.8951 - 236ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.8375 - val_loss: 0.8833 - 191ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.8315 - val_loss: 0.8868 - 235ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.8248 - val_loss: 0.9137 - 247ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.8227 - val_loss: 0.8886 - 293ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.8149 - val_loss: 0.8835 - 227ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.8105 - val_loss: 0.8833 - 221ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.8073 - val_loss: 0.8833 - 250ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.7985 - val_loss: 0.8801 - 236ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.7949 - val_loss: 0.8789 - 251ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.7931 - val_loss: 0.8846 - 238ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.7831 - val_loss: 0.8757 - 256ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.7802 - val_loss: 0.8763 - 269ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.7735 - val_loss: 0.8730 - 221ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.7697 - val_loss: 0.8848 - 242ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.7637 - val_loss: 0.9063 - 260ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.7595 - val_loss: 0.8710 - 241ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.7445 - val_loss: 0.8646 - 234ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.7473 - val_loss: 0.8593 - 219ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.7393 - val_loss: 0.8635 - 227ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.7329 - val_loss: 0.8548 - 259ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.7245 - val_loss: 0.8543 - 227ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.7180 - val_loss: 0.8549 - 234ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.7153 - val_loss: 0.8488 - 267ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.7091 - val_loss: 0.8458 - 233ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.7003 - val_loss: 0.8473 - 246ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.6927 - val_loss: 0.8399 - 225ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.6909 - val_loss: 0.8359 - 239ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.6798 - val_loss: 0.8558 - 239ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.6794 - val_loss: 0.8317 - 247ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.6731 - val_loss: 0.8524 - 276ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.6674 - val_loss: 0.8313 - 276ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.6545 - val_loss: 0.8263 - 239ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.6502 - val_loss: 0.8219 - 299ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.6397 - val_loss: 0.8193 - 280ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.6426 - val_loss: 0.8154 - 237ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.6356 - val_loss: 0.8623 - 266ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.6300 - val_loss: 0.8163 - 255ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.6185 - val_loss: 0.8076 - 250ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.6234 - val_loss: 0.8026 - 291ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.6079 - val_loss: 0.8000 - 268ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.6041 - val_loss: 0.8511 - 294ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.6009 - val_loss: 0.8062 - 271ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.5908 - val_loss: 0.7975 - 260ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.5894 - val_loss: 0.8487 - 262ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.5822 - val_loss: 0.7938 - 228ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history_reg = MLP_model_reg.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8363318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bdaa9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.360375\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dabfeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_reg.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e0571b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.354616\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cdc5c",
   "metadata": {},
   "source": [
    "가중치 규제를 사용한 모델에서 성능이 더 좋았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02e508",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 가중치규제를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2740b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L1 regularizer을 적용해봅니다.\n",
    "MLP_model_reg = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(\n",
    "            128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7517d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fa0f901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9541 - val_loss: 1.0259 - 761ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8548 - val_loss: 0.9025 - 222ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7624 - val_loss: 0.7810 - 230ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6853 - val_loss: 0.7091 - 232ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6595 - 212ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.6022 - val_loss: 0.6400 - 206ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5806 - val_loss: 0.6226 - 225ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5656 - val_loss: 0.6089 - 240ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5534 - val_loss: 0.5993 - 246ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5418 - val_loss: 0.5877 - 236ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5330 - val_loss: 0.5843 - 289ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5254 - val_loss: 0.5745 - 295ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5190 - val_loss: 0.5719 - 263ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5117 - val_loss: 0.5729 - 281ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5069 - val_loss: 0.5590 - 284ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.5010 - val_loss: 0.5655 - 185ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4965 - val_loss: 0.5537 - 158ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4918 - val_loss: 0.5482 - 168ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4874 - val_loss: 0.5491 - 176ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4834 - val_loss: 0.5500 - 201ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4812 - val_loss: 0.5419 - 173ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4754 - val_loss: 0.5394 - 184ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4732 - val_loss: 0.5315 - 217ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4699 - val_loss: 0.5272 - 177ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4676 - val_loss: 0.5287 - 156ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4638 - val_loss: 0.5288 - 168ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4620 - val_loss: 0.5250 - 177ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4579 - val_loss: 0.5210 - 206ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4568 - val_loss: 0.5156 - 182ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4544 - val_loss: 0.5200 - 168ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4521 - val_loss: 0.5242 - 160ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4503 - val_loss: 0.5184 - 173ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4484 - val_loss: 0.5198 - 168ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4479 - val_loss: 0.5104 - 166ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4432 - val_loss: 0.5157 - 160ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4426 - val_loss: 0.5088 - 160ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4409 - val_loss: 0.5098 - 162ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4397 - val_loss: 0.5104 - 179ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4385 - val_loss: 0.5023 - 201ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4358 - val_loss: 0.5064 - 208ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4353 - val_loss: 0.5138 - 193ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4348 - val_loss: 0.5018 - 213ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4317 - val_loss: 0.5010 - 202ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4311 - val_loss: 0.5034 - 170ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4303 - val_loss: 0.4977 - 165ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4276 - val_loss: 0.4989 - 164ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4270 - val_loss: 0.4971 - 168ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4252 - val_loss: 0.5006 - 168ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4242 - val_loss: 0.4993 - 169ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4236 - val_loss: 0.4929 - 152ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4217 - val_loss: 0.4948 - 147ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4206 - val_loss: 0.4955 - 155ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4201 - val_loss: 0.4895 - 163ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4189 - val_loss: 0.4933 - 167ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4173 - val_loss: 0.4892 - 185ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4163 - val_loss: 0.4872 - 193ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4150 - val_loss: 0.4830 - 163ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.4888 - 163ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4130 - val_loss: 0.4855 - 165ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4126 - val_loss: 0.4847 - 162ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.4853 - 178ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4104 - val_loss: 0.4876 - 167ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4090 - val_loss: 0.4820 - 169ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4082 - val_loss: 0.4813 - 165ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4076 - val_loss: 0.4881 - 186ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4062 - val_loss: 0.4823 - 164ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4045 - val_loss: 0.4860 - 162ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4033 - val_loss: 0.4862 - 170ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4035 - val_loss: 0.4833 - 166ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4023 - val_loss: 0.4845 - 176ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4014 - val_loss: 0.4777 - 167ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3997 - val_loss: 0.4766 - 166ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3986 - val_loss: 0.4768 - 165ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3987 - val_loss: 0.4755 - 175ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4732 - 159ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3959 - val_loss: 0.4789 - 161ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3939 - val_loss: 0.4745 - 175ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3940 - val_loss: 0.4768 - 175ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3935 - val_loss: 0.4739 - 169ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3911 - val_loss: 0.4755 - 188ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3916 - val_loss: 0.4775 - 229ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3908 - val_loss: 0.4764 - 243ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3904 - val_loss: 0.4729 - 169ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3884 - val_loss: 0.4728 - 167ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3878 - val_loss: 0.4690 - 170ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4720 - 169ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3857 - val_loss: 0.4718 - 165ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3852 - val_loss: 0.4774 - 168ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3844 - val_loss: 0.4702 - 173ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3833 - val_loss: 0.4763 - 176ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3831 - val_loss: 0.4730 - 159ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3817 - val_loss: 0.4700 - 173ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3798 - val_loss: 0.4674 - 161ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3803 - val_loss: 0.4700 - 163ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3785 - val_loss: 0.4714 - 168ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3777 - val_loss: 0.4646 - 180ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3767 - val_loss: 0.4763 - 193ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3758 - val_loss: 0.4676 - 165ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3744 - val_loss: 0.4692 - 169ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3751 - val_loss: 0.4693 - 168ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 가중치규제를 사용하지 않는 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b73f4c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1552 - val_loss: 1.1960 - 710ms/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.9997 - val_loss: 1.0291 - 191ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.8856 - val_loss: 0.9057 - 166ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.8194 - val_loss: 0.8516 - 163ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.7827 - val_loss: 0.8144 - 212ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.7607 - val_loss: 0.7982 - 222ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.7441 - val_loss: 0.7849 - 210ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.7306 - val_loss: 0.7739 - 257ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.7201 - val_loss: 0.7655 - 258ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.7090 - val_loss: 0.7569 - 236ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.7007 - val_loss: 0.7472 - 261ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.6932 - val_loss: 0.7418 - 240ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.6861 - val_loss: 0.7375 - 265ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.6789 - val_loss: 0.7391 - 238ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.6740 - val_loss: 0.7261 - 287ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.6683 - val_loss: 0.7294 - 284ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.6635 - val_loss: 0.7211 - 223ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.6587 - val_loss: 0.7143 - 249ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.6554 - val_loss: 0.7148 - 280ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.6509 - val_loss: 0.7145 - 262ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.6489 - val_loss: 0.7071 - 234ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.6434 - val_loss: 0.7031 - 230ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.6412 - val_loss: 0.6966 - 276ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.6378 - val_loss: 0.6927 - 242ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.6352 - val_loss: 0.6940 - 264ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.6322 - val_loss: 0.6945 - 273ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.6301 - val_loss: 0.6902 - 251ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.6258 - val_loss: 0.6874 - 229ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.6251 - val_loss: 0.6831 - 254ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.6223 - val_loss: 0.6851 - 242ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.6202 - val_loss: 0.6876 - 238ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.6183 - val_loss: 0.6825 - 233ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.6163 - val_loss: 0.6841 - 231ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.6155 - val_loss: 0.6772 - 208ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.6115 - val_loss: 0.6808 - 239ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.6106 - val_loss: 0.6758 - 278ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.6089 - val_loss: 0.6733 - 271ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.6070 - val_loss: 0.6751 - 254ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.6062 - val_loss: 0.6681 - 252ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.6035 - val_loss: 0.6738 - 253ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.6027 - val_loss: 0.6756 - 241ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.6018 - val_loss: 0.6668 - 241ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.5982 - val_loss: 0.6662 - 238ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.5980 - val_loss: 0.6655 - 266ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.5969 - val_loss: 0.6641 - 235ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.5940 - val_loss: 0.6629 - 225ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.5936 - val_loss: 0.6607 - 246ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.5917 - val_loss: 0.6621 - 253ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.5906 - val_loss: 0.6608 - 218ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.5893 - val_loss: 0.6566 - 238ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.5877 - val_loss: 0.6562 - 252ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.5861 - val_loss: 0.6584 - 285ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.5855 - val_loss: 0.6520 - 283ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.5844 - val_loss: 0.6518 - 222ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.5826 - val_loss: 0.6508 - 193ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.5816 - val_loss: 0.6484 - 170ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.5801 - val_loss: 0.6456 - 186ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.5791 - val_loss: 0.6490 - 161ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.5772 - val_loss: 0.6467 - 168ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.5766 - val_loss: 0.6455 - 170ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5746 - val_loss: 0.6470 - 158ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5746 - val_loss: 0.6477 - 191ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5729 - val_loss: 0.6431 - 165ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5721 - val_loss: 0.6396 - 162ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5708 - val_loss: 0.6473 - 158ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5696 - val_loss: 0.6424 - 168ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5679 - val_loss: 0.6460 - 182ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5665 - val_loss: 0.6472 - 191ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5668 - val_loss: 0.6428 - 181ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5651 - val_loss: 0.6424 - 193ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5639 - val_loss: 0.6360 - 181ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5622 - val_loss: 0.6347 - 160ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5612 - val_loss: 0.6347 - 169ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5612 - val_loss: 0.6324 - 165ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5588 - val_loss: 0.6291 - 169ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.5583 - val_loss: 0.6334 - 171ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.5560 - val_loss: 0.6324 - 175ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.5559 - val_loss: 0.6319 - 163ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.5554 - val_loss: 0.6293 - 171ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.5533 - val_loss: 0.6311 - 166ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.5533 - val_loss: 0.6311 - 199ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.5523 - val_loss: 0.6285 - 183ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.5511 - val_loss: 0.6282 - 178ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.5502 - val_loss: 0.6271 - 169ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.5494 - val_loss: 0.6239 - 163ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.5480 - val_loss: 0.6267 - 173ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.5466 - val_loss: 0.6243 - 159ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.5458 - val_loss: 0.6320 - 198ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.5452 - val_loss: 0.6242 - 259ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.5442 - val_loss: 0.6262 - 250ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.5432 - val_loss: 0.6258 - 214ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.5422 - val_loss: 0.6221 - 208ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.5405 - val_loss: 0.6218 - 177ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.5404 - val_loss: 0.6237 - 170ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.5391 - val_loss: 0.6208 - 174ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.5379 - val_loss: 0.6167 - 166ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.5373 - val_loss: 0.6229 - 167ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.5360 - val_loss: 0.6186 - 172ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.5339 - val_loss: 0.6194 - 196ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.5343 - val_loss: 0.6224 - 169ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 다음으로, 가중치규제를 사용하는 모델을 학습합니다.\n",
    "history_reg = MLP_model_reg.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9664c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score: 0.517047\n"
     ]
    }
   ],
   "source": [
    "# 가중치 규제를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcc394ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score: 0.526078\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_reg.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59739ab",
   "metadata": {},
   "source": [
    "## 4. 앙상블 모델\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 앙상블 모델을 학습해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0937e",
   "metadata": {},
   "source": [
    "### 4.1 Weak 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb88e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "n_estimators = 10\n",
    "models = []\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "        ]\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a48c6",
   "metadata": {},
   "source": [
    "### 4.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5c76ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23466d",
   "metadata": {},
   "source": [
    "### 4.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a90a5091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9907 - 547ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.8617 - 190ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.8131 - 191ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.7860 - 179ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7647 - 176ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.7446 - 183ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.7284 - 180ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.7172 - 179ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.7057 - 192ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.6959 - 185ms/epoch - 1ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.8878 - 556ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7062 - 220ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.6524 - 232ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.6262 - 218ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.6044 - 203ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.5875 - 245ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.5759 - 234ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.5634 - 307ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.5542 - 265ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.5470 - 214ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0597 - 537ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.9034 - 197ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.8326 - 168ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.7956 - 189ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7716 - 187ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.7505 - 193ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.7344 - 182ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.7186 - 190ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.7066 - 186ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.6956 - 198ms/epoch - 1ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0555 - 545ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.8581 - 234ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.7842 - 215ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.7430 - 186ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7127 - 191ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.6891 - 235ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.6697 - 198ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.6530 - 188ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.6410 - 187ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.6316 - 183ms/epoch - 1ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9130 - 592ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7594 - 278ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.7031 - 285ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.6730 - 271ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.6476 - 387ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.6252 - 348ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.6029 - 312ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.5865 - 372ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.5741 - 314ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.5631 - 290ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0899 - 667ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.9310 - 284ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.8623 - 286ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.8198 - 310ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7928 - 327ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.7729 - 313ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.7576 - 339ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.7453 - 358ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.7333 - 314ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.7257 - 299ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0352 - 667ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.9089 - 272ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.8621 - 284ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.8252 - 284ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7956 - 279ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.7728 - 272ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.7553 - 284ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.7395 - 308ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.7236 - 272ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.7104 - 287ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9596 - 688ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7875 - 382ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.7289 - 385ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.6959 - 299ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.6733 - 252ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.6557 - 287ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.6389 - 297ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.6268 - 286ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.6147 - 297ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.6071 - 282ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0108 - 664ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7888 - 255ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.7070 - 268ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.6624 - 286ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.6316 - 263ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.6091 - 278ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.5924 - 286ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.5799 - 274ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.5694 - 332ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.5598 - 280ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0177 - 707ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.8266 - 360ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.7627 - 291ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.7336 - 266ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.7096 - 277ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.6922 - 360ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.6741 - 293ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.6582 - 212ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.6424 - 231ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.6299 - 328ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "len_training_data = len(stage1[\"train_X\"])\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories = []\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = stage1[\"train_X\"][idxs][:len_subset]\n",
    "    train_y = stage1[\"train_y\"][idxs][:len_subset]\n",
    "    history = model.fit(train_X, train_y, epochs=10, batch_size=16, verbose=2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719d4d5",
   "metadata": {},
   "source": [
    "### 4.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d26500fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "1 번째 weak model - R2 score: 0.364301\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "2 번째 weak model - R2 score: 0.352849\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "3 번째 weak model - R2 score: 0.352064\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "4 번째 weak model - R2 score: 0.356870\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "5 번째 weak model - R2 score: 0.373838\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "6 번째 weak model - R2 score: 0.359003\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "7 번째 weak model - R2 score: 0.354602\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "8 번째 weak model - R2 score: 0.337947\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "9 번째 weak model - R2 score: 0.365411\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "10 번째 weak model - R2 score: 0.355624\n",
      "앙상블 모델 R2 score: 0.384129\n"
     ]
    }
   ],
   "source": [
    "preds = 0\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage1[\"test_X\"])\n",
    "    r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\" % (i + 1, r2))\n",
    "    preds += pred\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4a8a7",
   "metadata": {},
   "source": [
    "앙상블 모델이 각각의 약한 모델보다 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7bb2ed",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 앙상블을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99f7a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# Weak 모델 정의\n",
    "n_estimators = 10\n",
    "models = []\n",
    "# Stage1 에 사용했던 앙상블 모델을 그대로 사용해봅시다.\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "        ]\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efd8905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "860bce5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.8963 - 730ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6301 - 271ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5504 - 293ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5187 - 284ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.5032 - 289ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4926 - 267ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4813 - 287ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4741 - 264ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4684 - 276ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4601 - 346ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9700 - 730ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6853 - 296ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.6060 - 285ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5701 - 340ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.5492 - 327ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.5341 - 283ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.5223 - 292ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.5111 - 282ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4988 - 320ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4880 - 320ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9859 - 708ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6581 - 267ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5396 - 298ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5009 - 314ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.4753 - 276ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4599 - 273ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4485 - 298ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4400 - 309ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4325 - 281ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4278 - 272ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9609 - 656ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6683 - 267ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5547 - 335ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5158 - 351ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.4941 - 347ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4715 - 367ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4526 - 287ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4396 - 301ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4288 - 392ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4204 - 238ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9606 - 655ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7100 - 330ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5950 - 303ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5566 - 343ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.5363 - 262ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.5225 - 316ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.5083 - 312ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4965 - 300ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4881 - 335ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4784 - 309ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9882 - 552ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6709 - 174ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5845 - 197ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5368 - 173ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.5080 - 189ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4866 - 180ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4704 - 178ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4590 - 182ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4520 - 177ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4468 - 177ms/epoch - 1ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.8824 - 529ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6330 - 181ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5167 - 199ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.4752 - 187ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.4546 - 181ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4407 - 250ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4324 - 209ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4223 - 272ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4164 - 257ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4080 - 373ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.9791 - 620ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6623 - 296ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5661 - 346ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5302 - 334ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.5066 - 311ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4868 - 329ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4723 - 221ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4599 - 213ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4503 - 235ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4456 - 276ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 1.0724 - 1s/epoch - 9ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.7736 - 262ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5910 - 273ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.5246 - 268ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.4931 - 350ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4769 - 386ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4606 - 305ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4467 - 290ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4357 - 291ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4256 - 316ms/epoch - 2ms/step\n",
      "Epoch 1/10\n",
      "141/141 - 1s - loss: 0.8569 - 703ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "141/141 - 0s - loss: 0.6198 - 277ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "141/141 - 0s - loss: 0.5348 - 273ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "141/141 - 0s - loss: 0.4861 - 319ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "141/141 - 0s - loss: 0.4623 - 277ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "141/141 - 0s - loss: 0.4473 - 308ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "141/141 - 0s - loss: 0.4375 - 294ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "141/141 - 0s - loss: 0.4297 - 293ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "141/141 - 0s - loss: 0.4217 - 310ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "141/141 - 0s - loss: 0.4156 - 284ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "len_training_data = len(stage2[\"train_X\"])\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories = []\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = stage2[\"train_X\"][idxs][:len_subset]\n",
    "    train_y = stage2[\"train_y\"][idxs][:len_subset]\n",
    "    history = model.fit(train_X, train_y, epochs=10, batch_size=16, verbose=2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b804f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "1 번째 weak model - R2 score: 0.528430\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "2 번째 weak model - R2 score: 0.547278\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "3 번째 weak model - R2 score: 0.541820\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "4 번째 weak model - R2 score: 0.533642\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "5 번째 weak model - R2 score: 0.537208\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "6 번째 weak model - R2 score: 0.537491\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "7 번째 weak model - R2 score: 0.542404\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "8 번째 weak model - R2 score: 0.517011\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "9 번째 weak model - R2 score: 0.556370\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "10 번째 weak model - R2 score: 0.518245\n",
      "앙상블 모델 R2 score: 0.565864\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측 및 평가\n",
    "preds = 0\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage2[\"test_X\"])\n",
    "    r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\" % (i + 1, r2))\n",
    "    preds += pred\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4b73d",
   "metadata": {},
   "source": [
    "## 5. Dropout\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 Dropout 을 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d9e45",
   "metadata": {},
   "source": [
    "### 5.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98e30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c5503",
   "metadata": {},
   "source": [
    "### 5.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15fd0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09459be7",
   "metadata": {},
   "source": [
    "### 5.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5660181b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1507 - val_loss: 1.0349 - 743ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0744 - val_loss: 0.9810 - 245ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0332 - val_loss: 0.9454 - 211ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0035 - val_loss: 0.9184 - 175ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9804 - val_loss: 0.8975 - 212ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9617 - val_loss: 0.8800 - 245ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9463 - val_loss: 0.8665 - 267ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9335 - val_loss: 0.8546 - 288ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9221 - val_loss: 0.8442 - 237ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9117 - val_loss: 0.8359 - 231ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9025 - val_loss: 0.8293 - 240ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.8938 - val_loss: 0.8221 - 238ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8860 - val_loss: 0.8147 - 217ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8781 - val_loss: 0.8081 - 268ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8709 - val_loss: 0.8033 - 240ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8636 - val_loss: 0.7962 - 237ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8568 - val_loss: 0.7910 - 207ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8501 - val_loss: 0.7852 - 237ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8433 - val_loss: 0.7799 - 238ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8368 - val_loss: 0.7752 - 227ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8309 - val_loss: 0.7710 - 246ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8241 - val_loss: 0.7660 - 234ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8187 - val_loss: 0.7620 - 233ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8126 - val_loss: 0.7595 - 209ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8068 - val_loss: 0.7544 - 224ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8015 - val_loss: 0.7515 - 211ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.7956 - val_loss: 0.7466 - 218ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7898 - val_loss: 0.7443 - 215ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7838 - val_loss: 0.7408 - 225ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7780 - val_loss: 0.7376 - 228ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7730 - val_loss: 0.7332 - 260ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7671 - val_loss: 0.7300 - 225ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7612 - val_loss: 0.7282 - 250ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7557 - val_loss: 0.7265 - 245ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7501 - val_loss: 0.7220 - 261ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7442 - val_loss: 0.7210 - 241ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7390 - val_loss: 0.7169 - 237ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7333 - val_loss: 0.7144 - 232ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7281 - val_loss: 0.7128 - 237ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7226 - val_loss: 0.7114 - 270ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7169 - val_loss: 0.7083 - 238ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7112 - val_loss: 0.7064 - 225ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7052 - val_loss: 0.7061 - 236ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7012 - val_loss: 0.7045 - 247ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.6954 - val_loss: 0.7024 - 227ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6908 - val_loss: 0.6994 - 280ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6837 - val_loss: 0.6992 - 260ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6793 - val_loss: 0.6990 - 240ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6735 - val_loss: 0.6940 - 229ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6667 - val_loss: 0.6940 - 221ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6623 - val_loss: 0.6921 - 208ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6566 - val_loss: 0.6908 - 234ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6489 - val_loss: 0.6947 - 263ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6447 - val_loss: 0.6873 - 231ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6373 - val_loss: 0.6955 - 237ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6824 - 238ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6264 - val_loss: 0.6835 - 243ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6179 - val_loss: 0.7058 - 256ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6849 - 235ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6065 - val_loss: 0.6803 - 236ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5997 - val_loss: 0.6778 - 224ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5953 - val_loss: 0.6779 - 244ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5846 - val_loss: 0.6756 - 218ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5794 - val_loss: 0.6761 - 229ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5773 - val_loss: 0.6747 - 233ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5649 - val_loss: 0.6711 - 230ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5615 - val_loss: 0.6712 - 228ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5507 - val_loss: 0.6682 - 259ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5469 - val_loss: 0.6835 - 298ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5426 - val_loss: 0.6781 - 240ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5331 - val_loss: 0.6650 - 208ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5207 - val_loss: 0.6628 - 219ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5208 - val_loss: 0.6608 - 216ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5140 - val_loss: 0.6577 - 284ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5053 - val_loss: 0.6560 - 226ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.4951 - val_loss: 0.6518 - 235ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.4899 - val_loss: 0.6540 - 250ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.4842 - val_loss: 0.6492 - 258ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.4802 - val_loss: 0.6471 - 225ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4698 - val_loss: 0.6463 - 233ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4631 - val_loss: 0.6449 - 237ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4602 - val_loss: 0.6467 - 243ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4511 - val_loss: 0.6469 - 229ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4501 - val_loss: 0.6387 - 239ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4442 - val_loss: 0.6517 - 257ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4396 - val_loss: 0.6345 - 222ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4279 - val_loss: 0.6387 - 250ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4237 - val_loss: 0.6357 - 240ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.6284 - 229ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4154 - val_loss: 0.6281 - 260ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.6486 - 268ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4052 - val_loss: 0.6222 - 250ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3979 - val_loss: 0.6224 - 261ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3995 - val_loss: 0.6162 - 278ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3877 - val_loss: 0.6151 - 267ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3863 - val_loss: 0.6377 - 247ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.6254 - 231ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3773 - val_loss: 0.6236 - 260ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3755 - val_loss: 0.6526 - 231ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3725 - val_loss: 0.6185 - 251ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = MLP_model.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5342e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.2691 - val_loss: 1.0541 - 841ms/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.1532 - val_loss: 1.0243 - 253ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.1186 - val_loss: 1.0033 - 233ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.1001 - val_loss: 0.9865 - 216ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 1.0785 - val_loss: 0.9683 - 256ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 1.0645 - val_loss: 0.9537 - 260ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 1.0512 - val_loss: 0.9388 - 246ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 1.0465 - val_loss: 0.9281 - 245ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 1.0303 - val_loss: 0.9179 - 239ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 1.0198 - val_loss: 0.9079 - 247ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 1.0142 - val_loss: 0.9012 - 257ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 1.0181 - val_loss: 0.8957 - 222ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 1.0030 - val_loss: 0.8902 - 274ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.9997 - val_loss: 0.8860 - 292ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.9991 - val_loss: 0.8835 - 252ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.9935 - val_loss: 0.8808 - 299ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.9929 - val_loss: 0.8769 - 353ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.9920 - val_loss: 0.8732 - 249ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.9815 - val_loss: 0.8709 - 253ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.9770 - val_loss: 0.8664 - 219ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.9764 - val_loss: 0.8638 - 227ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.9717 - val_loss: 0.8607 - 245ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.9700 - val_loss: 0.8587 - 219ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.9686 - val_loss: 0.8566 - 270ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.9563 - val_loss: 0.8529 - 294ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.9606 - val_loss: 0.8509 - 282ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.9538 - val_loss: 0.8464 - 226ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.9588 - val_loss: 0.8432 - 255ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.9516 - val_loss: 0.8397 - 236ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.9565 - val_loss: 0.8371 - 219ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.9449 - val_loss: 0.8340 - 259ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.9456 - val_loss: 0.8311 - 252ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.9486 - val_loss: 0.8263 - 237ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.9333 - val_loss: 0.8223 - 202ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.9255 - val_loss: 0.8194 - 253ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.9268 - val_loss: 0.8174 - 282ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.9153 - val_loss: 0.8140 - 250ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.9294 - val_loss: 0.8113 - 280ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.9156 - val_loss: 0.8078 - 272ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.9156 - val_loss: 0.8063 - 278ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.9091 - val_loss: 0.8042 - 205ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.9073 - val_loss: 0.8012 - 242ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.9016 - val_loss: 0.7993 - 249ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.8966 - val_loss: 0.7982 - 258ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.9010 - val_loss: 0.7955 - 284ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.8932 - val_loss: 0.7924 - 263ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.8990 - val_loss: 0.7887 - 255ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.8845 - val_loss: 0.7859 - 240ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.8778 - val_loss: 0.7833 - 230ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.8783 - val_loss: 0.7806 - 233ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.8623 - val_loss: 0.7794 - 219ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.8726 - val_loss: 0.7778 - 232ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.8918 - val_loss: 0.7754 - 279ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.8669 - val_loss: 0.7721 - 245ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.8697 - val_loss: 0.7714 - 233ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.8634 - val_loss: 0.7717 - 255ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.8680 - val_loss: 0.7682 - 239ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.8453 - val_loss: 0.7655 - 269ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.8651 - val_loss: 0.7642 - 247ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.8470 - val_loss: 0.7625 - 230ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.8437 - val_loss: 0.7590 - 238ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.8520 - val_loss: 0.7578 - 232ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.8447 - val_loss: 0.7617 - 245ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.8118 - val_loss: 0.7596 - 235ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.8451 - val_loss: 0.7550 - 246ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.8074 - val_loss: 0.7509 - 230ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.8076 - val_loss: 0.7497 - 242ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.8071 - val_loss: 0.7479 - 213ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.8070 - val_loss: 0.7463 - 219ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.8281 - val_loss: 0.7450 - 248ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.7973 - val_loss: 0.7451 - 243ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.8102 - val_loss: 0.7517 - 244ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.7958 - val_loss: 0.7488 - 259ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.7767 - val_loss: 0.7462 - 248ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.7904 - val_loss: 0.7506 - 247ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.7801 - val_loss: 0.7416 - 211ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.7586 - val_loss: 0.7384 - 258ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.7912 - val_loss: 0.7367 - 225ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.7784 - val_loss: 0.7402 - 274ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.7636 - val_loss: 0.7383 - 250ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.7492 - val_loss: 0.7364 - 242ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.7792 - val_loss: 0.7369 - 251ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.7646 - val_loss: 0.7328 - 277ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.7431 - val_loss: 0.7342 - 214ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.7309 - val_loss: 0.7316 - 244ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.7836 - val_loss: 0.7343 - 250ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.7370 - val_loss: 0.7313 - 229ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.7788 - val_loss: 0.7373 - 242ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.7655 - val_loss: 0.7337 - 233ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.7492 - val_loss: 0.7285 - 221ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.7471 - val_loss: 0.7308 - 283ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.7014 - val_loss: 0.7240 - 278ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.7201 - val_loss: 0.7213 - 238ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.7437 - val_loss: 0.7181 - 230ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.7217 - val_loss: 0.7182 - 233ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.7078 - val_loss: 0.7199 - 234ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.6935 - val_loss: 0.7236 - 224ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.7219 - val_loss: 0.7207 - 252ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.6784 - val_loss: 0.7214 - 240ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.7272 - val_loss: 0.7209 - 289ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history_dropout = MLP_model_dropout.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4b889",
   "metadata": {},
   "source": [
    "### 5.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5f3be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1433d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.360375\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1f9388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_dropout.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65948a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.295015\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef86c1",
   "metadata": {},
   "source": [
    "Dropout 을 사용한 모델이 더 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14d063",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Dropout을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7359c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate = 0.2),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate = 0.2),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(rate = 0.2),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfe4c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1782f6b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9541 - val_loss: 1.0259 - 726ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8548 - val_loss: 0.9025 - 238ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7624 - val_loss: 0.7810 - 225ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6853 - val_loss: 0.7091 - 199ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6595 - 246ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.6022 - val_loss: 0.6400 - 226ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5806 - val_loss: 0.6226 - 262ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5656 - val_loss: 0.6089 - 234ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5534 - val_loss: 0.5993 - 234ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5418 - val_loss: 0.5877 - 267ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5330 - val_loss: 0.5843 - 247ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5254 - val_loss: 0.5745 - 294ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5190 - val_loss: 0.5719 - 256ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5117 - val_loss: 0.5729 - 276ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5069 - val_loss: 0.5590 - 199ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.5010 - val_loss: 0.5655 - 169ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4965 - val_loss: 0.5537 - 171ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4918 - val_loss: 0.5482 - 164ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4874 - val_loss: 0.5491 - 196ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4834 - val_loss: 0.5500 - 197ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4812 - val_loss: 0.5419 - 171ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4754 - val_loss: 0.5394 - 164ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4732 - val_loss: 0.5315 - 159ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4699 - val_loss: 0.5272 - 220ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4676 - val_loss: 0.5287 - 200ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4638 - val_loss: 0.5288 - 194ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4620 - val_loss: 0.5250 - 170ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4579 - val_loss: 0.5210 - 161ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4568 - val_loss: 0.5156 - 171ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4544 - val_loss: 0.5200 - 214ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4521 - val_loss: 0.5242 - 168ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4503 - val_loss: 0.5184 - 164ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4484 - val_loss: 0.5198 - 175ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4479 - val_loss: 0.5104 - 181ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4432 - val_loss: 0.5157 - 169ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4426 - val_loss: 0.5088 - 170ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4409 - val_loss: 0.5098 - 164ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4397 - val_loss: 0.5104 - 168ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4385 - val_loss: 0.5023 - 181ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4358 - val_loss: 0.5064 - 223ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4353 - val_loss: 0.5138 - 202ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4348 - val_loss: 0.5018 - 208ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4317 - val_loss: 0.5010 - 175ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4311 - val_loss: 0.5034 - 182ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4303 - val_loss: 0.4977 - 163ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4276 - val_loss: 0.4989 - 173ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4270 - val_loss: 0.4971 - 188ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4252 - val_loss: 0.5006 - 170ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4242 - val_loss: 0.4993 - 208ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4236 - val_loss: 0.4929 - 205ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4217 - val_loss: 0.4948 - 160ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4206 - val_loss: 0.4955 - 163ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4201 - val_loss: 0.4895 - 166ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4189 - val_loss: 0.4933 - 201ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4173 - val_loss: 0.4892 - 173ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4163 - val_loss: 0.4872 - 192ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4150 - val_loss: 0.4830 - 162ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.4888 - 175ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4130 - val_loss: 0.4855 - 175ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4126 - val_loss: 0.4847 - 180ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.4853 - 164ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4104 - val_loss: 0.4876 - 171ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4090 - val_loss: 0.4820 - 174ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4082 - val_loss: 0.4813 - 216ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4076 - val_loss: 0.4881 - 166ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4062 - val_loss: 0.4823 - 165ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4045 - val_loss: 0.4860 - 168ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4033 - val_loss: 0.4862 - 174ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4035 - val_loss: 0.4833 - 182ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4023 - val_loss: 0.4845 - 198ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4014 - val_loss: 0.4777 - 191ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3997 - val_loss: 0.4766 - 165ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3986 - val_loss: 0.4768 - 178ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3987 - val_loss: 0.4755 - 215ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4732 - 210ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3959 - val_loss: 0.4789 - 199ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3939 - val_loss: 0.4745 - 161ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3940 - val_loss: 0.4768 - 163ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3935 - val_loss: 0.4739 - 168ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3911 - val_loss: 0.4755 - 166ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3916 - val_loss: 0.4775 - 170ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3908 - val_loss: 0.4764 - 169ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3904 - val_loss: 0.4729 - 162ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3884 - val_loss: 0.4728 - 168ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3878 - val_loss: 0.4690 - 165ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4720 - 161ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3857 - val_loss: 0.4718 - 165ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3852 - val_loss: 0.4774 - 173ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3844 - val_loss: 0.4702 - 219ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3833 - val_loss: 0.4763 - 162ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3831 - val_loss: 0.4730 - 178ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3817 - val_loss: 0.4700 - 196ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3798 - val_loss: 0.4674 - 219ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3803 - val_loss: 0.4700 - 197ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3785 - val_loss: 0.4714 - 165ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3777 - val_loss: 0.4646 - 172ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3767 - val_loss: 0.4763 - 175ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3758 - val_loss: 0.4676 - 172ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3744 - val_loss: 0.4692 - 178ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3751 - val_loss: 0.4693 - 171ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Dropout 을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8095a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.0571 - val_loss: 1.0479 - 703ms/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.9253 - val_loss: 0.9201 - 196ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.8375 - val_loss: 0.7954 - 178ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.7723 - val_loss: 0.7307 - 175ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.7677 - val_loss: 0.6979 - 170ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.7113 - val_loss: 0.6634 - 172ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.6964 - val_loss: 0.6442 - 199ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.6817 - val_loss: 0.6447 - 168ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.7123 - val_loss: 0.6271 - 172ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.6562 - val_loss: 0.6302 - 179ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.6453 - val_loss: 0.6196 - 169ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.6427 - val_loss: 0.6090 - 171ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.6183 - val_loss: 0.6008 - 185ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.6188 - val_loss: 0.6022 - 173ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.6324 - val_loss: 0.5965 - 179ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.6410 - val_loss: 0.5927 - 190ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.6124 - val_loss: 0.5896 - 175ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.6197 - val_loss: 0.5745 - 228ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.6165 - val_loss: 0.5928 - 202ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.6041 - val_loss: 0.5764 - 185ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.6230 - val_loss: 0.5659 - 247ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.5916 - val_loss: 0.5938 - 179ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.5764 - val_loss: 0.5581 - 169ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.5727 - val_loss: 0.5511 - 190ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.5985 - val_loss: 0.5475 - 204ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.5848 - val_loss: 0.5604 - 180ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.5865 - val_loss: 0.5460 - 175ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.5784 - val_loss: 0.5688 - 175ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.5935 - val_loss: 0.5451 - 186ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.5739 - val_loss: 0.5395 - 176ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.5777 - val_loss: 0.5570 - 184ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.5562 - val_loss: 0.5495 - 174ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.5772 - val_loss: 0.5744 - 172ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.5640 - val_loss: 0.5518 - 186ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.5609 - val_loss: 0.5638 - 204ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.5531 - val_loss: 0.5593 - 226ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.5622 - val_loss: 0.5363 - 260ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.5554 - val_loss: 0.5305 - 226ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.5298 - val_loss: 0.5306 - 265ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.5501 - val_loss: 0.5317 - 192ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.5476 - val_loss: 0.5394 - 224ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.5365 - val_loss: 0.5459 - 170ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.5579 - val_loss: 0.5363 - 217ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.5390 - val_loss: 0.5374 - 177ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.5442 - val_loss: 0.5258 - 168ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.5357 - val_loss: 0.5453 - 172ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.5498 - val_loss: 0.5206 - 186ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.5579 - val_loss: 0.5323 - 256ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.5607 - val_loss: 0.5291 - 228ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.5405 - val_loss: 0.5196 - 174ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.5418 - val_loss: 0.5109 - 211ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.5373 - val_loss: 0.5272 - 174ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.5432 - val_loss: 0.5297 - 171ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.5385 - val_loss: 0.5225 - 170ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.5333 - val_loss: 0.5217 - 250ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.5402 - val_loss: 0.5100 - 223ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.5439 - val_loss: 0.5166 - 171ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.5348 - val_loss: 0.5394 - 180ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.5196 - val_loss: 0.5305 - 171ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.5146 - val_loss: 0.5343 - 170ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5233 - val_loss: 0.5134 - 171ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5382 - val_loss: 0.5114 - 172ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5168 - val_loss: 0.5250 - 171ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5284 - val_loss: 0.5259 - 168ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5257 - val_loss: 0.5385 - 173ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5321 - val_loss: 0.5077 - 171ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5267 - val_loss: 0.5083 - 173ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5059 - val_loss: 0.5117 - 177ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5275 - val_loss: 0.5018 - 174ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5104 - val_loss: 0.5019 - 177ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5086 - val_loss: 0.5014 - 202ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.4937 - val_loss: 0.4945 - 197ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5096 - val_loss: 0.5082 - 194ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5158 - val_loss: 0.4953 - 254ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5227 - val_loss: 0.5139 - 244ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.5348 - val_loss: 0.5009 - 212ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.5083 - val_loss: 0.4952 - 242ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.5385 - val_loss: 0.5048 - 180ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.5038 - val_loss: 0.4943 - 181ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4849 - val_loss: 0.5063 - 191ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.5056 - val_loss: 0.5178 - 174ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.5109 - val_loss: 0.5215 - 170ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.5087 - val_loss: 0.5141 - 172ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.5027 - val_loss: 0.5130 - 175ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.5096 - val_loss: 0.5039 - 174ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4938 - val_loss: 0.4896 - 177ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4913 - val_loss: 0.5088 - 175ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.5006 - val_loss: 0.5189 - 185ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4957 - val_loss: 0.5144 - 254ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4981 - val_loss: 0.5085 - 243ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.5017 - val_loss: 0.5101 - 179ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4953 - val_loss: 0.4953 - 172ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.5100 - val_loss: 0.4869 - 174ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.4973 - val_loss: 0.5287 - 169ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.4992 - val_loss: 0.4918 - 166ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.5019 - val_loss: 0.5007 - 178ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.4986 - val_loss: 0.4908 - 225ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.4851 - val_loss: 0.4893 - 257ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.5001 - val_loss: 0.4919 - 178ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.5082 - val_loss: 0.5273 - 177ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Dropout 을 사용할 모델을 학습합니다.\n",
    "history_dropout = MLP_model_dropout.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0be32ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n",
      "R2 score: 0.517047\n"
     ]
    }
   ],
   "source": [
    "# Dropout 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0d351e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score: 0.506981\n"
     ]
    }
   ],
   "source": [
    "# Dropout 을 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_dropout.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e777fc5",
   "metadata": {},
   "source": [
    "## 6. 정규화\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca7fd7",
   "metadata": {},
   "source": [
    "### 6.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32f99f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다. Dropout에서 학습한 모델과 같은 구조를 사용하겠습니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e9eef",
   "metadata": {},
   "source": [
    "### 6.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfb1c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84fb78",
   "metadata": {},
   "source": [
    "### 6.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec30397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.0026 - val_loss: 0.8207 - 791ms/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8671 - val_loss: 0.7642 - 270ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.8085 - val_loss: 0.7243 - 276ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.7641 - val_loss: 0.6964 - 278ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.7281 - val_loss: 0.6798 - 243ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.6981 - val_loss: 0.6755 - 244ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.6700 - val_loss: 0.6651 - 248ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.6433 - val_loss: 0.6903 - 225ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.6124 - val_loss: 0.6514 - 186ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5860 - val_loss: 0.6652 - 177ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5625 - val_loss: 0.6388 - 211ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5269 - val_loss: 0.6420 - 244ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.4822 - val_loss: 0.6377 - 259ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.4793 - val_loss: 0.6534 - 244ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.4502 - val_loss: 0.6469 - 247ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.4091 - val_loss: 0.6233 - 259ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.3739 - val_loss: 0.6130 - 270ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.3520 - val_loss: 0.6212 - 278ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.3344 - val_loss: 0.6076 - 245ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.3181 - val_loss: 0.6134 - 256ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.3052 - val_loss: 0.6080 - 223ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.2855 - val_loss: 0.6197 - 256ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.2791 - val_loss: 0.6140 - 272ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.2688 - val_loss: 0.6002 - 279ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.2596 - val_loss: 0.6177 - 250ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.2544 - val_loss: 0.6098 - 340ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.2437 - val_loss: 0.6072 - 267ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.2396 - val_loss: 0.6198 - 203ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.2307 - val_loss: 0.5937 - 176ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.2235 - val_loss: 0.6120 - 173ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.2220 - val_loss: 0.6086 - 192ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.2153 - val_loss: 0.6162 - 178ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.2082 - val_loss: 0.5905 - 187ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.2011 - val_loss: 0.6232 - 189ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.2002 - val_loss: 0.5934 - 182ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.1972 - val_loss: 0.6234 - 185ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.1907 - val_loss: 0.6107 - 184ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.1916 - val_loss: 0.6278 - 201ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.1826 - val_loss: 0.6061 - 190ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.1820 - val_loss: 0.6438 - 225ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.1709 - val_loss: 0.6045 - 204ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.1686 - val_loss: 0.6383 - 268ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.1643 - val_loss: 0.6024 - 174ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.1627 - val_loss: 0.6602 - 186ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.1590 - val_loss: 0.6111 - 184ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.1611 - val_loss: 0.6407 - 180ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.1504 - val_loss: 0.6138 - 195ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.1499 - val_loss: 0.6382 - 185ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.1452 - val_loss: 0.6325 - 198ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.1525 - val_loss: 0.6665 - 200ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.1495 - val_loss: 0.6239 - 188ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.1370 - val_loss: 0.6267 - 183ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.1290 - val_loss: 0.6436 - 191ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.1223 - val_loss: 0.6244 - 194ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.1190 - val_loss: 0.6387 - 186ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.1126 - val_loss: 0.6193 - 180ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.1141 - val_loss: 0.6409 - 214ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.1103 - val_loss: 0.6246 - 198ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.1135 - val_loss: 0.6422 - 173ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.1105 - val_loss: 0.6458 - 192ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.1151 - val_loss: 0.6468 - 177ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.1083 - val_loss: 0.6372 - 178ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.0981 - val_loss: 0.6442 - 188ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.0975 - val_loss: 0.6669 - 232ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.1295 - val_loss: 0.6421 - 242ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.1096 - val_loss: 0.6955 - 264ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.1425 - val_loss: 0.6358 - 256ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.1060 - val_loss: 0.6630 - 223ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.0893 - val_loss: 0.6582 - 209ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.0850 - val_loss: 0.6549 - 183ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.0867 - val_loss: 0.6796 - 195ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.0816 - val_loss: 0.6503 - 174ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.0795 - val_loss: 0.6726 - 222ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.0767 - val_loss: 0.6387 - 191ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.0752 - val_loss: 0.6739 - 236ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.0741 - val_loss: 0.6291 - 193ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.0721 - val_loss: 0.6761 - 181ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.0680 - val_loss: 0.6282 - 181ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.0697 - val_loss: 0.6715 - 209ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.0692 - val_loss: 0.6320 - 272ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.0663 - val_loss: 0.6474 - 368ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.0651 - val_loss: 0.6595 - 346ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.0606 - val_loss: 0.6487 - 239ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.0625 - val_loss: 0.6472 - 241ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.0601 - val_loss: 0.6635 - 258ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.0620 - val_loss: 0.6377 - 350ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.0617 - val_loss: 0.6663 - 322ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.0642 - val_loss: 0.6443 - 256ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.0626 - val_loss: 0.6623 - 260ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.0596 - val_loss: 0.6683 - 256ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.0594 - val_loss: 0.6689 - 247ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.0575 - val_loss: 0.6404 - 255ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.0548 - val_loss: 0.6799 - 275ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.0518 - val_loss: 0.6516 - 281ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.0517 - val_loss: 0.6588 - 310ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.0540 - val_loss: 0.6500 - 246ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.0507 - val_loss: 0.6667 - 277ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.0484 - val_loss: 0.6478 - 275ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.0490 - val_loss: 0.6448 - 255ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.0569 - val_loss: 0.7131 - 266ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cd7f514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 2s - loss: 1.3490 - val_loss: 0.9326 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.9775 - val_loss: 0.8393 - 336ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.9066 - val_loss: 0.7981 - 366ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.8669 - val_loss: 0.7666 - 289ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.8362 - val_loss: 0.7518 - 339ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.8161 - val_loss: 0.7261 - 305ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.7996 - val_loss: 0.7120 - 312ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.7898 - val_loss: 0.7135 - 332ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.7781 - val_loss: 0.7019 - 343ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.7579 - val_loss: 0.7080 - 332ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.7634 - val_loss: 0.7135 - 342ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.7379 - val_loss: 0.6892 - 362ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.7148 - val_loss: 0.7015 - 367ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.7023 - val_loss: 0.7018 - 291ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.7071 - val_loss: 0.6719 - 295ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.6917 - val_loss: 0.6797 - 289ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.6878 - val_loss: 0.6665 - 309ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.6502 - val_loss: 0.6725 - 312ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.6632 - val_loss: 0.6522 - 320ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.6464 - val_loss: 0.6544 - 328ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.6409 - val_loss: 0.7002 - 372ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.6097 - val_loss: 0.7277 - 313ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.6146 - val_loss: 0.6643 - 305ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.6503 - val_loss: 0.6486 - 289ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.6197 - val_loss: 0.6560 - 294ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.5756 - val_loss: 0.6232 - 313ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.5840 - val_loss: 0.6385 - 315ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.5506 - val_loss: 0.6249 - 296ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.5592 - val_loss: 0.6666 - 281ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.5381 - val_loss: 0.6549 - 319ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.5316 - val_loss: 0.6491 - 322ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.5229 - val_loss: 0.6203 - 303ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.5321 - val_loss: 0.6338 - 298ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.5182 - val_loss: 0.7017 - 317ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.5336 - val_loss: 0.6812 - 294ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4845 - val_loss: 0.6636 - 287ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4880 - val_loss: 0.7236 - 323ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.5026 - val_loss: 0.6416 - 357ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4782 - val_loss: 0.6071 - 344ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4991 - val_loss: 0.7212 - 308ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4558 - val_loss: 0.6129 - 324ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4618 - val_loss: 0.6653 - 341ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4789 - val_loss: 0.6401 - 348ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.5421 - val_loss: 0.6847 - 324ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4454 - val_loss: 0.6305 - 238ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4420 - val_loss: 0.6527 - 241ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4352 - val_loss: 0.6881 - 224ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4755 - val_loss: 0.6720 - 255ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4470 - val_loss: 0.6452 - 329ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4387 - val_loss: 0.6538 - 361ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4151 - val_loss: 0.6417 - 377ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4200 - val_loss: 0.6275 - 390ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4142 - val_loss: 0.6302 - 309ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4025 - val_loss: 0.5930 - 308ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.3972 - val_loss: 0.6024 - 311ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.3992 - val_loss: 0.6300 - 291ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4016 - val_loss: 0.6816 - 273ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4296 - val_loss: 0.6429 - 223ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.3996 - val_loss: 0.6453 - 231ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.3987 - val_loss: 0.6227 - 220ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.3687 - val_loss: 0.5701 - 219ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.3660 - val_loss: 0.5914 - 225ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.3798 - val_loss: 0.6376 - 219ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4056 - val_loss: 0.6372 - 225ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4030 - val_loss: 0.6426 - 256ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.3719 - val_loss: 0.6065 - 307ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.3455 - val_loss: 0.6174 - 295ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.3504 - val_loss: 0.5913 - 329ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.3733 - val_loss: 0.6516 - 303ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.3846 - val_loss: 0.6142 - 267ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4122 - val_loss: 0.6377 - 268ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3599 - val_loss: 0.6128 - 290ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3805 - val_loss: 0.6458 - 333ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3725 - val_loss: 0.6757 - 278ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3549 - val_loss: 0.6228 - 289ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3514 - val_loss: 0.6286 - 277ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3668 - val_loss: 0.6732 - 310ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3502 - val_loss: 0.6534 - 317ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3652 - val_loss: 0.6440 - 307ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3651 - val_loss: 0.6081 - 305ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3386 - val_loss: 0.6117 - 342ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3601 - val_loss: 0.6626 - 323ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3711 - val_loss: 0.6111 - 309ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3303 - val_loss: 0.6121 - 346ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3587 - val_loss: 0.6322 - 336ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3693 - val_loss: 0.6338 - 345ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3394 - val_loss: 0.6125 - 308ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3606 - val_loss: 0.6768 - 303ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3217 - val_loss: 0.6259 - 282ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3417 - val_loss: 0.5708 - 315ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3806 - val_loss: 0.6382 - 347ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3404 - val_loss: 0.6065 - 345ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3422 - val_loss: 0.6232 - 299ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3539 - val_loss: 0.6672 - 317ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3287 - val_loss: 0.6244 - 338ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3309 - val_loss: 0.6689 - 346ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3213 - val_loss: 0.6594 - 375ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3450 - val_loss: 0.7351 - 318ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3732 - val_loss: 0.7093 - 329ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3654 - val_loss: 0.6950 - 307ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history_ln = MLP_model_ln.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a839d6",
   "metadata": {},
   "source": [
    "### 6.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe9b3a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8ba1848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.309611\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "116c6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_ln.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8786905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.338477\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789232cc",
   "metadata": {},
   "source": [
    "정규화를 사용한 모델에서 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f15a3a",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 정규화를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e660975",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7722105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4c33cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.8080 - val_loss: 0.6800 - 897ms/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.5605 - val_loss: 0.5885 - 247ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.4972 - val_loss: 0.5283 - 255ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.4688 - val_loss: 0.5413 - 242ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.4509 - val_loss: 0.5163 - 270ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.4410 - val_loss: 0.5096 - 250ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.4274 - val_loss: 0.5003 - 292ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.4155 - val_loss: 0.4880 - 300ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.4056 - val_loss: 0.4687 - 298ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.3981 - val_loss: 0.4767 - 261ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.3824 - val_loss: 0.4713 - 303ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.3960 - val_loss: 0.4639 - 292ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.3716 - val_loss: 0.4414 - 255ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.3577 - val_loss: 0.4576 - 250ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.3533 - val_loss: 0.4451 - 260ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.3492 - val_loss: 0.4333 - 249ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.3409 - val_loss: 0.4293 - 288ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.3337 - val_loss: 0.4212 - 272ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.3286 - val_loss: 0.4321 - 253ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.3327 - val_loss: 0.4560 - 287ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.3252 - val_loss: 0.4428 - 274ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.3249 - val_loss: 0.4321 - 273ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.3204 - val_loss: 0.4174 - 258ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.3103 - val_loss: 0.4071 - 252ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.3104 - val_loss: 0.4267 - 261ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.2993 - val_loss: 0.4218 - 262ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.3013 - val_loss: 0.4179 - 324ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.2961 - val_loss: 0.4273 - 265ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.3019 - val_loss: 0.4154 - 249ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.2908 - val_loss: 0.4294 - 264ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.2924 - val_loss: 0.4297 - 255ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.2906 - val_loss: 0.4209 - 273ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.2886 - val_loss: 0.4311 - 289ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.2876 - val_loss: 0.4245 - 255ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.2801 - val_loss: 0.4260 - 255ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.2769 - val_loss: 0.4323 - 248ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.2825 - val_loss: 0.4216 - 314ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.2731 - val_loss: 0.4258 - 315ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.2717 - val_loss: 0.4205 - 275ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.2732 - val_loss: 0.4416 - 287ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.2680 - val_loss: 0.4436 - 253ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.2638 - val_loss: 0.4213 - 236ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.2638 - val_loss: 0.4416 - 247ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.2599 - val_loss: 0.4333 - 280ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.2577 - val_loss: 0.4594 - 303ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.2623 - val_loss: 0.4404 - 249ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.2578 - val_loss: 0.4602 - 285ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.2538 - val_loss: 0.4343 - 308ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.2511 - val_loss: 0.4347 - 235ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.2507 - val_loss: 0.4562 - 271ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.2463 - val_loss: 0.4519 - 235ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.2442 - val_loss: 0.4600 - 237ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.2417 - val_loss: 0.4288 - 264ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.2391 - val_loss: 0.4623 - 230ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.2453 - val_loss: 0.4382 - 240ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.2392 - val_loss: 0.4394 - 255ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.2388 - val_loss: 0.4431 - 260ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.2347 - val_loss: 0.4467 - 255ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.2364 - val_loss: 0.4351 - 292ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.2332 - val_loss: 0.4492 - 289ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.2296 - val_loss: 0.4583 - 285ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.2286 - val_loss: 0.4554 - 303ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.2260 - val_loss: 0.4497 - 278ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.2232 - val_loss: 0.4422 - 252ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.2191 - val_loss: 0.4803 - 254ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.2227 - val_loss: 0.4571 - 264ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.2296 - val_loss: 0.4574 - 272ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.2245 - val_loss: 0.4814 - 244ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.2279 - val_loss: 0.4724 - 247ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.2277 - val_loss: 0.4842 - 259ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.2174 - val_loss: 0.4589 - 276ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.2133 - val_loss: 0.4577 - 240ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.2120 - val_loss: 0.4627 - 313ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.2091 - val_loss: 0.4728 - 274ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.2094 - val_loss: 0.4577 - 296ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.2120 - val_loss: 0.4637 - 255ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.2128 - val_loss: 0.4745 - 293ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.2046 - val_loss: 0.4638 - 343ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.2010 - val_loss: 0.4661 - 342ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.2000 - val_loss: 0.4684 - 258ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.2018 - val_loss: 0.4855 - 259ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.2028 - val_loss: 0.4769 - 311ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.1985 - val_loss: 0.4784 - 284ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.1976 - val_loss: 0.4846 - 288ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.2001 - val_loss: 0.4766 - 266ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.2012 - val_loss: 0.4835 - 254ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.1942 - val_loss: 0.5030 - 283ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.1952 - val_loss: 0.5035 - 285ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.1964 - val_loss: 0.5041 - 266ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.1945 - val_loss: 0.4956 - 283ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.1921 - val_loss: 0.5082 - 303ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.1922 - val_loss: 0.4965 - 342ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.1876 - val_loss: 0.4920 - 277ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.1904 - val_loss: 0.4881 - 292ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.1861 - val_loss: 0.4901 - 293ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.1846 - val_loss: 0.5064 - 267ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.1834 - val_loss: 0.5007 - 274ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.1822 - val_loss: 0.4906 - 290ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.1811 - val_loss: 0.4958 - 262ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.1805 - val_loss: 0.5008 - 270ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e4e9f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 2s - loss: 1.0140 - val_loss: 0.7898 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.6853 - val_loss: 0.6487 - 307ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.6264 - val_loss: 0.6382 - 329ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6032 - val_loss: 0.6633 - 316ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.5592 - val_loss: 0.6587 - 341ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.5753 - val_loss: 0.5802 - 316ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5413 - val_loss: 0.6276 - 336ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5144 - val_loss: 0.6186 - 313ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5035 - val_loss: 0.6507 - 292ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.4922 - val_loss: 0.6024 - 379ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5011 - val_loss: 0.7008 - 366ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.4966 - val_loss: 0.7715 - 346ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.4927 - val_loss: 0.6618 - 348ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.4668 - val_loss: 0.6477 - 330ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.4659 - val_loss: 0.5993 - 344ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.4827 - val_loss: 0.5643 - 329ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4698 - val_loss: 0.5340 - 294ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4584 - val_loss: 0.5329 - 305ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4504 - val_loss: 0.5416 - 287ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4528 - val_loss: 0.5733 - 298ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4287 - val_loss: 0.6051 - 297ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4424 - val_loss: 0.5824 - 297ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4467 - val_loss: 0.5805 - 314ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4337 - val_loss: 0.6221 - 318ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4279 - val_loss: 0.5279 - 322ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4182 - val_loss: 0.5092 - 290ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4253 - val_loss: 0.5024 - 317ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4018 - val_loss: 0.6547 - 288ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4153 - val_loss: 0.4937 - 300ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4013 - val_loss: 0.5166 - 300ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.3976 - val_loss: 0.5304 - 325ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4011 - val_loss: 0.5395 - 282ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4133 - val_loss: 0.4978 - 315ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4013 - val_loss: 0.4929 - 313ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.4728 - 295ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4014 - val_loss: 0.5009 - 320ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4069 - val_loss: 0.5223 - 282ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.3862 - val_loss: 0.4905 - 306ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.3838 - val_loss: 0.4797 - 291ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4000 - val_loss: 0.5107 - 359ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.3772 - val_loss: 0.4849 - 322ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.3907 - val_loss: 0.5921 - 296ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4026 - val_loss: 0.5328 - 316ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.3814 - val_loss: 0.4780 - 349ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.3726 - val_loss: 0.4704 - 281ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.3701 - val_loss: 0.4754 - 286ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.3671 - val_loss: 0.4829 - 314ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.3768 - val_loss: 0.5090 - 290ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.3665 - val_loss: 0.4851 - 274ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.3707 - val_loss: 0.4885 - 319ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.3571 - val_loss: 0.4839 - 364ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.3603 - val_loss: 0.4904 - 307ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.3652 - val_loss: 0.4754 - 314ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.3592 - val_loss: 0.4730 - 335ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.3643 - val_loss: 0.4670 - 323ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.3551 - val_loss: 0.4848 - 335ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.3474 - val_loss: 0.4324 - 391ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.3394 - val_loss: 0.4379 - 364ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.3580 - val_loss: 0.4423 - 346ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.3495 - val_loss: 0.4807 - 356ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.3493 - val_loss: 0.4963 - 283ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.3512 - val_loss: 0.4588 - 320ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.3574 - val_loss: 0.4602 - 290ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.3402 - val_loss: 0.4379 - 303ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.3534 - val_loss: 0.4772 - 315ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.3445 - val_loss: 0.4506 - 341ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.3445 - val_loss: 0.4601 - 337ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.3425 - val_loss: 0.4717 - 367ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.3522 - val_loss: 0.4751 - 330ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.3559 - val_loss: 0.4701 - 311ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.3270 - val_loss: 0.4625 - 368ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3323 - val_loss: 0.4651 - 331ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3415 - val_loss: 0.4559 - 323ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3393 - val_loss: 0.4496 - 320ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3355 - val_loss: 0.4484 - 349ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3463 - val_loss: 0.4547 - 383ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3477 - val_loss: 0.4460 - 339ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3226 - val_loss: 0.4487 - 310ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3310 - val_loss: 0.4675 - 306ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3312 - val_loss: 0.4630 - 285ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3459 - val_loss: 0.4358 - 316ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3366 - val_loss: 0.4625 - 321ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3344 - val_loss: 0.4597 - 331ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3340 - val_loss: 0.4526 - 296ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3284 - val_loss: 0.4582 - 312ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3249 - val_loss: 0.4526 - 341ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3226 - val_loss: 0.4553 - 326ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3322 - val_loss: 0.5014 - 307ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3366 - val_loss: 0.4639 - 338ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3242 - val_loss: 0.4478 - 311ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3195 - val_loss: 0.4634 - 314ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3293 - val_loss: 0.4907 - 320ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3253 - val_loss: 0.4473 - 320ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3262 - val_loss: 0.4550 - 339ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3236 - val_loss: 0.4738 - 298ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3353 - val_loss: 0.4612 - 329ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3325 - val_loss: 0.4832 - 335ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3141 - val_loss: 0.4596 - 296ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3209 - val_loss: 0.4471 - 331ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3152 - val_loss: 0.4588 - 338ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history = MLP_model_ln.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8dcbf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score: 0.511533\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d708d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score: 0.558006\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_ln.predict(stage2[\"test_X\"])\n",
    "r2 = sklearn.metrics.r2_score(stage2[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60828ad4",
   "metadata": {},
   "source": [
    "## 7. 데이터 증강 기법\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ed740",
   "metadata": {},
   "source": [
    "### 7.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a9a61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 임의의 가우시안 노이즈를 추가해보겠습니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_aug = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage1[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.GaussianNoise(stddev=0.1),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage1[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6b876",
   "metadata": {},
   "source": [
    "### 7.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ea81467",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa155c",
   "metadata": {},
   "source": [
    "### 7.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9775758b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1507 - val_loss: 1.0349 - 772ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0744 - val_loss: 0.9810 - 246ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0332 - val_loss: 0.9454 - 235ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0035 - val_loss: 0.9184 - 255ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9804 - val_loss: 0.8975 - 237ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9617 - val_loss: 0.8800 - 232ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9463 - val_loss: 0.8665 - 223ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9335 - val_loss: 0.8546 - 225ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9221 - val_loss: 0.8442 - 225ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9117 - val_loss: 0.8359 - 262ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9025 - val_loss: 0.8293 - 215ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.8938 - val_loss: 0.8221 - 230ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8860 - val_loss: 0.8147 - 226ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8781 - val_loss: 0.8081 - 248ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8709 - val_loss: 0.8033 - 229ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8636 - val_loss: 0.7962 - 225ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8568 - val_loss: 0.7910 - 238ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8501 - val_loss: 0.7852 - 244ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8433 - val_loss: 0.7799 - 243ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8368 - val_loss: 0.7752 - 225ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8309 - val_loss: 0.7710 - 220ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8241 - val_loss: 0.7660 - 223ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8187 - val_loss: 0.7620 - 290ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8126 - val_loss: 0.7595 - 320ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8068 - val_loss: 0.7544 - 211ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8015 - val_loss: 0.7515 - 225ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.7956 - val_loss: 0.7466 - 241ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7898 - val_loss: 0.7443 - 231ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7838 - val_loss: 0.7408 - 279ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7780 - val_loss: 0.7376 - 260ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7730 - val_loss: 0.7332 - 233ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7671 - val_loss: 0.7300 - 208ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7612 - val_loss: 0.7282 - 232ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7557 - val_loss: 0.7265 - 250ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7501 - val_loss: 0.7220 - 243ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7442 - val_loss: 0.7210 - 216ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7390 - val_loss: 0.7169 - 236ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7333 - val_loss: 0.7144 - 237ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7281 - val_loss: 0.7128 - 271ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7226 - val_loss: 0.7114 - 230ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7169 - val_loss: 0.7083 - 301ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7112 - val_loss: 0.7064 - 307ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7052 - val_loss: 0.7061 - 231ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7012 - val_loss: 0.7045 - 238ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.6954 - val_loss: 0.7024 - 233ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6908 - val_loss: 0.6994 - 225ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6837 - val_loss: 0.6992 - 224ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6793 - val_loss: 0.6990 - 223ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6735 - val_loss: 0.6940 - 234ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6667 - val_loss: 0.6940 - 227ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6623 - val_loss: 0.6921 - 213ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6566 - val_loss: 0.6908 - 217ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6489 - val_loss: 0.6947 - 244ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6447 - val_loss: 0.6873 - 238ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6373 - val_loss: 0.6955 - 242ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6824 - 232ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6264 - val_loss: 0.6835 - 226ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6179 - val_loss: 0.7058 - 240ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6849 - 265ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6065 - val_loss: 0.6803 - 247ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.5997 - val_loss: 0.6778 - 227ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.5953 - val_loss: 0.6779 - 244ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5846 - val_loss: 0.6756 - 241ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5794 - val_loss: 0.6761 - 224ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5773 - val_loss: 0.6747 - 233ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5649 - val_loss: 0.6711 - 239ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5615 - val_loss: 0.6712 - 250ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5507 - val_loss: 0.6682 - 247ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5469 - val_loss: 0.6835 - 232ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5426 - val_loss: 0.6781 - 230ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5331 - val_loss: 0.6650 - 234ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5207 - val_loss: 0.6628 - 225ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5208 - val_loss: 0.6608 - 264ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5140 - val_loss: 0.6577 - 235ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5053 - val_loss: 0.6560 - 229ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.4951 - val_loss: 0.6518 - 228ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.4899 - val_loss: 0.6540 - 224ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.4842 - val_loss: 0.6492 - 219ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.4802 - val_loss: 0.6471 - 237ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4698 - val_loss: 0.6463 - 220ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4631 - val_loss: 0.6449 - 273ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4602 - val_loss: 0.6467 - 228ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4511 - val_loss: 0.6469 - 220ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4501 - val_loss: 0.6387 - 229ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4442 - val_loss: 0.6517 - 249ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4396 - val_loss: 0.6345 - 233ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4279 - val_loss: 0.6387 - 253ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4237 - val_loss: 0.6357 - 230ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.6284 - 252ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4154 - val_loss: 0.6281 - 232ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.6486 - 220ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4052 - val_loss: 0.6222 - 276ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3979 - val_loss: 0.6224 - 222ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3995 - val_loss: 0.6162 - 244ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3877 - val_loss: 0.6151 - 241ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3863 - val_loss: 0.6377 - 204ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.6254 - 263ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3773 - val_loss: 0.6236 - 269ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3755 - val_loss: 0.6526 - 243ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3725 - val_loss: 0.6185 - 255ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6cc7a507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 1.1511 - val_loss: 1.0337 - 831ms/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 1.0743 - val_loss: 0.9798 - 228ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 1.0340 - val_loss: 0.9448 - 239ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 1.0039 - val_loss: 0.9182 - 238ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.9818 - val_loss: 0.8976 - 266ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.9631 - val_loss: 0.8806 - 251ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.9486 - val_loss: 0.8669 - 261ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.9343 - val_loss: 0.8543 - 228ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.9230 - val_loss: 0.8441 - 228ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.9127 - val_loss: 0.8357 - 298ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.9029 - val_loss: 0.8292 - 206ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.8949 - val_loss: 0.8217 - 216ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.8874 - val_loss: 0.8144 - 230ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.8788 - val_loss: 0.8074 - 226ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.8712 - val_loss: 0.8024 - 253ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.8658 - val_loss: 0.7958 - 230ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.8584 - val_loss: 0.7904 - 226ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.8513 - val_loss: 0.7851 - 238ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.8449 - val_loss: 0.7798 - 266ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.8378 - val_loss: 0.7751 - 238ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.8329 - val_loss: 0.7711 - 241ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.8265 - val_loss: 0.7660 - 232ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.8205 - val_loss: 0.7621 - 228ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.8155 - val_loss: 0.7602 - 262ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.8100 - val_loss: 0.7545 - 253ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.8046 - val_loss: 0.7511 - 237ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.7986 - val_loss: 0.7460 - 235ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.7937 - val_loss: 0.7441 - 229ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.7871 - val_loss: 0.7405 - 245ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.7815 - val_loss: 0.7370 - 241ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.7771 - val_loss: 0.7328 - 253ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.7714 - val_loss: 0.7299 - 267ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.7654 - val_loss: 0.7272 - 271ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.7606 - val_loss: 0.7260 - 222ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.7559 - val_loss: 0.7216 - 235ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.7484 - val_loss: 0.7202 - 258ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.7441 - val_loss: 0.7165 - 232ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.7421 - val_loss: 0.7139 - 254ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.7352 - val_loss: 0.7125 - 233ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.7305 - val_loss: 0.7103 - 255ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.7225 - val_loss: 0.7074 - 275ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.7179 - val_loss: 0.7057 - 238ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.7137 - val_loss: 0.7047 - 315ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.7075 - val_loss: 0.7039 - 244ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.7033 - val_loss: 0.7015 - 208ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.6977 - val_loss: 0.6987 - 230ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.6911 - val_loss: 0.6977 - 278ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.6901 - val_loss: 0.6980 - 294ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.6779 - val_loss: 0.6926 - 232ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.6741 - val_loss: 0.6926 - 293ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.6719 - val_loss: 0.6906 - 249ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.6670 - val_loss: 0.6902 - 259ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.6572 - val_loss: 0.6957 - 239ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.6520 - val_loss: 0.6864 - 229ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.6503 - val_loss: 0.6991 - 230ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.6460 - val_loss: 0.6831 - 236ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.6387 - val_loss: 0.6839 - 237ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.6345 - val_loss: 0.7017 - 224ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.6281 - val_loss: 0.6854 - 215ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6823 - 183ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.6138 - val_loss: 0.6787 - 162ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.6147 - val_loss: 0.6794 - 181ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.5971 - val_loss: 0.6758 - 167ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.5921 - val_loss: 0.6785 - 189ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.5909 - val_loss: 0.6768 - 180ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.5789 - val_loss: 0.6729 - 187ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.5793 - val_loss: 0.6746 - 175ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.5749 - val_loss: 0.6698 - 184ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.5611 - val_loss: 0.6845 - 165ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.5588 - val_loss: 0.6827 - 184ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.5575 - val_loss: 0.6673 - 172ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.5417 - val_loss: 0.6675 - 179ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.5435 - val_loss: 0.6628 - 183ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.5360 - val_loss: 0.6604 - 174ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.5374 - val_loss: 0.6570 - 175ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.5220 - val_loss: 0.6552 - 193ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.5188 - val_loss: 0.6552 - 175ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.5082 - val_loss: 0.6530 - 162ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.5063 - val_loss: 0.6509 - 160ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.4933 - val_loss: 0.6490 - 165ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.4941 - val_loss: 0.6515 - 202ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.4895 - val_loss: 0.6531 - 159ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.4714 - val_loss: 0.6531 - 176ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.4854 - val_loss: 0.6444 - 177ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.4623 - val_loss: 0.6493 - 173ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.4594 - val_loss: 0.6419 - 166ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.4527 - val_loss: 0.6458 - 178ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.4383 - val_loss: 0.6469 - 192ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.4445 - val_loss: 0.6323 - 186ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.4502 - val_loss: 0.6382 - 186ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.4363 - val_loss: 0.6855 - 177ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.4362 - val_loss: 0.6340 - 161ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.4116 - val_loss: 0.6309 - 173ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.4222 - val_loss: 0.6243 - 169ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.4255 - val_loss: 0.6204 - 166ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.4091 - val_loss: 0.6583 - 174ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.4066 - val_loss: 0.6361 - 216ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.4004 - val_loss: 0.6283 - 265ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.4041 - val_loss: 0.6458 - 274ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3948 - val_loss: 0.6170 - 264ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history = MLP_model_aug.fit(\n",
    "    stage1[\"train_X\"][:1000],\n",
    "    stage1[\"train_y\"][:1000],\n",
    "    validation_data=(stage1[\"valid_X\"], stage1[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a809f",
   "metadata": {},
   "source": [
    "### 7.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ac942d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e01d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.360375\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e6d7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model_aug.predict(stage1[\"test_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4aaf9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.364908\n"
     ]
    }
   ],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1[\"test_y\"], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772425d6",
   "metadata": {},
   "source": [
    "데이터 증강 기법을 사용한 모델이 성능이 더 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679b8df",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 데이터 증강기법을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "119575a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(shape=stage2[\"train_X\"].shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 Stage1에서 추가했던 가우시안 노이즈를 추가해보겠습니다.\n",
    "MLP_model_aug = tf.keras.Sequential(\n",
    "    [ Input(shape = stage2['train_X'].shape[1]),\n",
    "         tf.keras.layers.GaussianNoise(stddev=0.1),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(stage2[\"train_y\"].shape[1]),\n",
    "     \n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53f6480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4da99894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9541 - val_loss: 1.0259 - 878ms/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8548 - val_loss: 0.9025 - 237ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7624 - val_loss: 0.7810 - 235ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6853 - val_loss: 0.7091 - 255ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6333 - val_loss: 0.6595 - 231ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.6022 - val_loss: 0.6400 - 234ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5806 - val_loss: 0.6226 - 225ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5656 - val_loss: 0.6089 - 225ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5534 - val_loss: 0.5993 - 242ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5418 - val_loss: 0.5877 - 231ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5330 - val_loss: 0.5843 - 236ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5254 - val_loss: 0.5745 - 247ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5190 - val_loss: 0.5719 - 240ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5117 - val_loss: 0.5729 - 248ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5069 - val_loss: 0.5590 - 245ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.5010 - val_loss: 0.5655 - 218ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4965 - val_loss: 0.5537 - 236ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4918 - val_loss: 0.5482 - 246ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4874 - val_loss: 0.5491 - 210ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4834 - val_loss: 0.5500 - 199ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4812 - val_loss: 0.5419 - 220ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4754 - val_loss: 0.5394 - 247ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4732 - val_loss: 0.5315 - 228ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4699 - val_loss: 0.5272 - 242ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4676 - val_loss: 0.5287 - 239ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4638 - val_loss: 0.5288 - 256ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4620 - val_loss: 0.5250 - 247ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4579 - val_loss: 0.5210 - 246ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4568 - val_loss: 0.5156 - 244ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4544 - val_loss: 0.5200 - 243ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4521 - val_loss: 0.5242 - 232ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4503 - val_loss: 0.5184 - 282ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4484 - val_loss: 0.5198 - 297ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4479 - val_loss: 0.5104 - 323ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4432 - val_loss: 0.5157 - 253ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4426 - val_loss: 0.5088 - 232ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4409 - val_loss: 0.5098 - 230ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4397 - val_loss: 0.5104 - 235ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4385 - val_loss: 0.5023 - 222ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4358 - val_loss: 0.5064 - 218ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4353 - val_loss: 0.5138 - 224ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4348 - val_loss: 0.5018 - 245ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4317 - val_loss: 0.5010 - 246ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4311 - val_loss: 0.5034 - 223ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4303 - val_loss: 0.4977 - 229ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4276 - val_loss: 0.4989 - 214ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4270 - val_loss: 0.4971 - 234ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4252 - val_loss: 0.5006 - 229ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4242 - val_loss: 0.4993 - 264ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4236 - val_loss: 0.4929 - 271ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4217 - val_loss: 0.4948 - 228ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4206 - val_loss: 0.4955 - 268ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4201 - val_loss: 0.4895 - 259ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4189 - val_loss: 0.4933 - 241ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4173 - val_loss: 0.4892 - 230ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4163 - val_loss: 0.4872 - 277ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4150 - val_loss: 0.4830 - 263ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4146 - val_loss: 0.4888 - 319ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4130 - val_loss: 0.4855 - 270ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4126 - val_loss: 0.4847 - 251ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4103 - val_loss: 0.4853 - 272ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4104 - val_loss: 0.4876 - 296ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4090 - val_loss: 0.4820 - 269ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4082 - val_loss: 0.4813 - 231ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4076 - val_loss: 0.4881 - 232ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4062 - val_loss: 0.4823 - 227ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4045 - val_loss: 0.4860 - 252ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4033 - val_loss: 0.4862 - 227ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4035 - val_loss: 0.4833 - 295ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4023 - val_loss: 0.4845 - 274ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4014 - val_loss: 0.4777 - 269ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.3997 - val_loss: 0.4766 - 275ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.3986 - val_loss: 0.4768 - 271ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.3987 - val_loss: 0.4755 - 251ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.3966 - val_loss: 0.4732 - 248ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3959 - val_loss: 0.4789 - 244ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3939 - val_loss: 0.4745 - 256ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3940 - val_loss: 0.4768 - 256ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3935 - val_loss: 0.4739 - 234ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3911 - val_loss: 0.4755 - 217ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3916 - val_loss: 0.4775 - 229ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3908 - val_loss: 0.4764 - 236ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3904 - val_loss: 0.4729 - 269ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3884 - val_loss: 0.4728 - 228ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3878 - val_loss: 0.4690 - 238ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4720 - 229ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3857 - val_loss: 0.4718 - 270ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3852 - val_loss: 0.4774 - 237ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3844 - val_loss: 0.4702 - 254ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3833 - val_loss: 0.4763 - 230ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3831 - val_loss: 0.4730 - 225ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3817 - val_loss: 0.4700 - 219ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3798 - val_loss: 0.4674 - 237ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3803 - val_loss: 0.4700 - 219ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3785 - val_loss: 0.4714 - 222ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3777 - val_loss: 0.4646 - 248ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3767 - val_loss: 0.4763 - 276ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3758 - val_loss: 0.4676 - 246ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3744 - val_loss: 0.4692 - 240ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3751 - val_loss: 0.4693 - 260ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fce8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 1s - loss: 0.9802 - val_loss: 1.0199 - 883ms/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 0s - loss: 0.8250 - val_loss: 0.8531 - 241ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 0s - loss: 0.7121 - val_loss: 0.7299 - 249ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 0s - loss: 0.6455 - val_loss: 0.6760 - 247ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 0s - loss: 0.6094 - val_loss: 0.6384 - 266ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 0s - loss: 0.5861 - val_loss: 0.6226 - 316ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 0s - loss: 0.5693 - val_loss: 0.6092 - 269ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 0s - loss: 0.5578 - val_loss: 0.5984 - 223ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 0s - loss: 0.5445 - val_loss: 0.5900 - 220ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 0s - loss: 0.5342 - val_loss: 0.5819 - 232ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 0s - loss: 0.5267 - val_loss: 0.5720 - 212ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 0s - loss: 0.5205 - val_loss: 0.5674 - 238ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 0s - loss: 0.5125 - val_loss: 0.5626 - 258ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 0s - loss: 0.5057 - val_loss: 0.5651 - 265ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 0s - loss: 0.5014 - val_loss: 0.5525 - 291ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 0s - loss: 0.4961 - val_loss: 0.5564 - 270ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 0s - loss: 0.4915 - val_loss: 0.5485 - 241ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 0s - loss: 0.4876 - val_loss: 0.5414 - 237ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 0s - loss: 0.4831 - val_loss: 0.5426 - 298ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 0s - loss: 0.4804 - val_loss: 0.5422 - 231ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 0s - loss: 0.4786 - val_loss: 0.5356 - 266ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 0s - loss: 0.4738 - val_loss: 0.5331 - 244ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 0s - loss: 0.4715 - val_loss: 0.5270 - 234ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 0s - loss: 0.4697 - val_loss: 0.5226 - 232ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 0s - loss: 0.4673 - val_loss: 0.5241 - 231ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 0s - loss: 0.4645 - val_loss: 0.5251 - 244ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 0s - loss: 0.4612 - val_loss: 0.5208 - 228ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 0s - loss: 0.4567 - val_loss: 0.5178 - 225ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 0s - loss: 0.4578 - val_loss: 0.5140 - 210ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 0s - loss: 0.4555 - val_loss: 0.5165 - 222ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 0s - loss: 0.4530 - val_loss: 0.5185 - 234ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 0s - loss: 0.4506 - val_loss: 0.5140 - 242ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 0s - loss: 0.4474 - val_loss: 0.5156 - 220ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 0s - loss: 0.4492 - val_loss: 0.5098 - 264ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 0s - loss: 0.4456 - val_loss: 0.5136 - 256ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 0s - loss: 0.4439 - val_loss: 0.5084 - 272ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 0s - loss: 0.4434 - val_loss: 0.5061 - 266ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 0s - loss: 0.4410 - val_loss: 0.5086 - 257ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 0s - loss: 0.4421 - val_loss: 0.5016 - 293ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 0s - loss: 0.4375 - val_loss: 0.5079 - 241ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 0s - loss: 0.4374 - val_loss: 0.5098 - 260ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 0s - loss: 0.4356 - val_loss: 0.4997 - 253ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 0s - loss: 0.4330 - val_loss: 0.5003 - 255ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 0s - loss: 0.4326 - val_loss: 0.4994 - 269ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 0s - loss: 0.4314 - val_loss: 0.4986 - 268ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 0s - loss: 0.4285 - val_loss: 0.4975 - 238ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 0s - loss: 0.4297 - val_loss: 0.4961 - 246ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 0s - loss: 0.4288 - val_loss: 0.4976 - 222ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 0s - loss: 0.4264 - val_loss: 0.4946 - 214ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 0s - loss: 0.4247 - val_loss: 0.4919 - 228ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 0s - loss: 0.4263 - val_loss: 0.4930 - 304ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 0s - loss: 0.4223 - val_loss: 0.4956 - 268ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 0s - loss: 0.4222 - val_loss: 0.4879 - 221ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 0s - loss: 0.4217 - val_loss: 0.4886 - 225ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 0s - loss: 0.4187 - val_loss: 0.4873 - 240ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 0s - loss: 0.4194 - val_loss: 0.4859 - 226ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 0s - loss: 0.4184 - val_loss: 0.4821 - 235ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 0s - loss: 0.4177 - val_loss: 0.4872 - 224ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 0s - loss: 0.4136 - val_loss: 0.4843 - 237ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 0s - loss: 0.4148 - val_loss: 0.4840 - 249ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 0s - loss: 0.4143 - val_loss: 0.4867 - 226ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 0s - loss: 0.4148 - val_loss: 0.4864 - 224ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 0s - loss: 0.4110 - val_loss: 0.4806 - 226ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 0s - loss: 0.4105 - val_loss: 0.4776 - 220ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 0s - loss: 0.4109 - val_loss: 0.4874 - 232ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 0s - loss: 0.4086 - val_loss: 0.4817 - 226ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 0s - loss: 0.4069 - val_loss: 0.4858 - 223ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 0s - loss: 0.4078 - val_loss: 0.4881 - 228ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 0s - loss: 0.4075 - val_loss: 0.4831 - 248ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 0s - loss: 0.4038 - val_loss: 0.4833 - 232ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 0s - loss: 0.4031 - val_loss: 0.4752 - 255ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 0s - loss: 0.4038 - val_loss: 0.4747 - 240ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 0s - loss: 0.4037 - val_loss: 0.4750 - 265ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 0s - loss: 0.4032 - val_loss: 0.4713 - 299ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 0s - loss: 0.4000 - val_loss: 0.4697 - 252ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 0s - loss: 0.3981 - val_loss: 0.4737 - 278ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 0s - loss: 0.3977 - val_loss: 0.4737 - 323ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 0s - loss: 0.3984 - val_loss: 0.4737 - 296ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 0s - loss: 0.3961 - val_loss: 0.4705 - 264ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 0s - loss: 0.3933 - val_loss: 0.4737 - 244ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 0s - loss: 0.3941 - val_loss: 0.4741 - 245ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 0s - loss: 0.3949 - val_loss: 0.4711 - 256ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 0s - loss: 0.3948 - val_loss: 0.4690 - 257ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 0s - loss: 0.3906 - val_loss: 0.4701 - 259ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 0s - loss: 0.3929 - val_loss: 0.4663 - 260ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 0s - loss: 0.3920 - val_loss: 0.4682 - 257ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 0s - loss: 0.3896 - val_loss: 0.4677 - 216ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 0s - loss: 0.3876 - val_loss: 0.4757 - 232ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 0s - loss: 0.3893 - val_loss: 0.4670 - 238ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 0s - loss: 0.3848 - val_loss: 0.4706 - 279ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 0s - loss: 0.3855 - val_loss: 0.4707 - 271ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 0s - loss: 0.3856 - val_loss: 0.4661 - 238ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 0s - loss: 0.3835 - val_loss: 0.4669 - 276ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 0s - loss: 0.3838 - val_loss: 0.4698 - 244ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 0s - loss: 0.3831 - val_loss: 0.4669 - 226ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 0s - loss: 0.3842 - val_loss: 0.4622 - 210ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 0s - loss: 0.3816 - val_loss: 0.4688 - 238ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 0s - loss: 0.3778 - val_loss: 0.4627 - 220ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 0s - loss: 0.3778 - val_loss: 0.4635 - 298ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "63/63 - 0s - loss: 0.3788 - val_loss: 0.4651 - 242ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history_aug = MLP_model_aug.fit(\n",
    "    stage2[\"train_X\"][:1000],\n",
    "    stage2[\"train_y\"][:1000],\n",
    "    validation_data=(stage2[\"valid_X\"], stage2[\"valid_y\"]),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f639b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score: 0.517047\n"
     ]
    }
   ],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6341f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n",
      "R2 score: 0.531843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = MLP_model_aug.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee919c",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
